% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{fontspec}
\defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase,Ligatures=TeX}
\setmainfont{Lato}[
Path = Fonts/,
Extension= .ttf,
UprightFont = *-Regular,
BoldFont       = *-Bold,
ItalicFont     = *-Italic,
BoldItalicFont = *-BoldItalic,
]

% next from https://bookdown.org/yihui/bookdown/yaml-options.html
\usepackage{longtable}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
  \fi
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={OES Standard Operating Procedures for The Design and Statistical Analysis of Experiments.},
  pdfauthor={Jake Bowers, Ryan T. Moore, Lula Chen, Paul Testa, Nate Higgins},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{OES Standard Operating Procedures for The Design and Statistical
Analysis of Experiments.}
\author{Jake Bowers, Ryan T. Moore, Lula Chen, Paul Testa, Nate Higgins}
\date{April 07, 2023}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\frontmatter
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\listoffigures
\listoftables
\mainmatter
\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Libraries are now managed by the renv system}
\FunctionTok{library}\NormalTok{(bfe) }\CommentTok{\# for another approach to block randomized trials}
\FunctionTok{library}\NormalTok{(blockTools)}
\FunctionTok{library}\NormalTok{(coin) }\CommentTok{\# for easier randomization inference}
\FunctionTok{library}\NormalTok{(DeclareDesign)}
\FunctionTok{library}\NormalTok{(devtools)}
\FunctionTok{library}\NormalTok{(estimatr)}
\FunctionTok{library}\NormalTok{(fabricatr)}
\FunctionTok{library}\NormalTok{(foreach)}
\FunctionTok{library}\NormalTok{(future)}
\FunctionTok{library}\NormalTok{(future.apply)}
\FunctionTok{library}\NormalTok{(here)}
\FunctionTok{library}\NormalTok{(kableExtra)}
\FunctionTok{library}\NormalTok{(lmtest)}
\FunctionTok{library}\NormalTok{(multcomp)}
\FunctionTok{library}\NormalTok{(quickblock)}
\FunctionTok{library}\NormalTok{(randomizr)}
\FunctionTok{library}\NormalTok{(ri2)}
\FunctionTok{library}\NormalTok{(sandwich)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(RItools)}

\FunctionTok{options}\NormalTok{(}
  \AttributeTok{htmltools.dir.version =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{formatR.indent =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{width =} \DecValTok{100}\NormalTok{, }\AttributeTok{digits =} \DecValTok{4}\NormalTok{, }\AttributeTok{warnPartialMatchAttr =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{warnPartialMatchDollar =} \ConstantTok{FALSE}
\NormalTok{)}

\FunctionTok{local}\NormalTok{(\{}
\NormalTok{  r }\OtherTok{\textless{}{-}} \FunctionTok{getOption}\NormalTok{(}\StringTok{"repos"}\NormalTok{)}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{length}\NormalTok{(r) }\SpecialCharTok{||} \FunctionTok{identical}\NormalTok{(}\FunctionTok{unname}\NormalTok{(r[}\StringTok{"CRAN"}\NormalTok{]), }\StringTok{"@CRAN@"}\NormalTok{)) \{}
\NormalTok{    r[}\StringTok{"CRAN"}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"https://cran.rstudio.com"}
\NormalTok{  \}}
  \FunctionTok{options}\NormalTok{(}\AttributeTok{repos =}\NormalTok{ r)}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\newcommand{\var}{\mathrm{Var}}
\newcommand{\sd}{\mathrm{sd}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\cor}{\mathrm{Cor}}
\newcommand{\pr}{\text{Pr}}
\newcommand{\rank}{\text{rank}}
\newcommand{\Dt}{\Delta t}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bmu}{\boldsymbol{\mu}}

\%m \newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\btau}{\boldsymbol{\tau}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}

\hypertarget{overview}{%
\chapter*{Overview}\label{overview}}
\addcontentsline{toc}{chapter}{Overview}

This document explains \textbf{how} our team, the
\href{https://oes.gsa.gov/}{Office of Evaluation Sciences in the General
Services Administration} (the OES), tends to do statistical analysis and
it also explains \textbf{why} we do what we do. \footnote{We call this
  document a standard operating procedure (SOP) because we are inspired
  by the \href{https://github.com/acoppock/Green-Lab-SOP}{Green, Lin and
  Coppock SOP}.} The research integrity process of the OES is already
documented the \href{https://oes.gsa.gov/methods/}{OES Methods Web
Page}. For example, on that page we provide templates for our research
design and analysis pre-registration process. Here, we get into the
nitty gritty of our statistical work.

\hypertarget{purposes-of-this-document}{%
\section*{Purposes of this document}\label{purposes-of-this-document}}
\addcontentsline{toc}{section}{Purposes of this document}

First, this document educates new team members about the decisions past
team members have made regarding the design and analysis of the studies
fielded so far. This educative role also offers us a place to record
decisions for
\href{http://dx.doi.org/10.4067/S0718-090X2016000300011}{our own future
selves} but also to help us harness the power that arises from our
disciplinary diversity. That is, we have decided, as a team, how to do
certain statistical analysis and these decisions may differ from those
that are common in any given academic discipline. This document, thus,
helps explain why we have landed on those decisions (for now), and how
to implement those practices.

Second, this document records decisions that we have made in the absence
of pre-analysis plans, or in the context of circumstances unforeseen by
our pre-analysis planning. And it should guide our future experimental
design and analysis.

Third, this document should help us write better analysis plans and
speed our practice of re-analysis. (Our team insists on a blind
re-analysis of every study as a quality control for our results before
they are reported to our agency partners.)

Fourth, this document should help other teams working to learn about the
causal impacts of policy interventions. We hope this contributes to the
federal government's own work pursuing evidence-based public policy, but
also helps other teams in other places doing work that is similar to our
own.

\hypertarget{nature-and-limitations-of-this-document}{%
\section*{Nature and limitations of this
document}\label{nature-and-limitations-of-this-document}}
\addcontentsline{toc}{section}{Nature and limitations of this document}

\hypertarget{we-mostly-focus-on-randomized-field-experiments.}{%
\subsection*{We (mostly) focus on randomized field
experiments.}\label{we-mostly-focus-on-randomized-field-experiments.}}
\addcontentsline{toc}{subsection}{We (mostly) focus on randomized field
experiments.}

This document focuses on design and analysis of randomized field
experiments. Although we include some discussion about non-randomized
studies, often known as observational studies, until now, our team has
focused primarily on randomized field experiments.

\hypertarget{we-present-examples-using-r}{%
\subsection*{We present examples using
R}\label{we-present-examples-using-r}}
\addcontentsline{toc}{subsection}{We present examples using R}

As public servants and social and behavioral scientists, we use the
\href{http://r-project.org}{R} statistical analysis language because it
is (a) one of the two industry standards in the field of data science
(along with Python), (b) free, open source, and multiplatform, and (c)
the standard for advanced methodological work in the statistical
sciences as applied to the social and behavioral sciences (the latest
new statistical techniques for social and behavioral scientists tend to
be developed in R).

Many members of our team use Stata or SAS or SPSS or Python. We welcome
additions to this document using those languages as well.

\hypertarget{structure-of-the-document}{%
\subsection*{Structure of the
document}\label{structure-of-the-document}}
\addcontentsline{toc}{subsection}{Structure of the document}

Each section of this document will include, if applicable:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A description of our approach
\item
  A description of how we implement our approach, including functions in
  R, including key arguments that must be entered into the function and
  key values that are outputs from the function.\footnote{We use R and
    R+markdown for our work and in general prefer open source tools in
    order to best serve the public.}
\item
  A general example using simulated data (perhaps including some
  evaluation of the tool as compared to other possible choices).
\item
  A discussion of a specific example from OES (if applicable) in which
  we implemented the given procedure.
\end{enumerate}

Throughout the document, we include links to the
\protect\hyperlink{glossary}{Glossary} and
\protect\hyperlink{appendix}{Appendix}, to clarify terms or explain
tools and procedures in more depth.

\hypertarget{help-us-improve-our-work}{%
\section*{Help us improve our work!}\label{help-us-improve-our-work}}
\addcontentsline{toc}{section}{Help us improve our work!}

Since we hope to improve our analytic workflow with every project, this
document should be seen as provisional --- as a record and a guide for
our continuous learning and improvement. We invite comments in the
\href{https://github.com/gsa-oes/sop/issues}{Issues} and
\href{https://help.github.com/articles/creating-a-pull-request/}{pull
requests} for direct contributions.

\hypertarget{about-this-document}{%
\section*{About this document}\label{about-this-document}}
\addcontentsline{toc}{section}{About this document}

This book was written in \href{http://bookdown.org/}{bookdown}. The
complete source is available from
\href{https://github.com/gsa-oes/sop}{GitHub}. This version of the book
was built with R version 4.2.1 (2022-06-23) and the following packages.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1522}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.0870}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.7609}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
package
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
version
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
source
\end{minipage} \\
\midrule()
\endhead
bfe & 2.0 & Github
(gibbonscharlie/bfe@4eaebc00d12bc427a9c75aec3280c43a0034b416) \\
blockTools & 0.6.4 & CRAN (R 4.2.1) \\
bookdown & 0.7 & CRAN (R 4.2.1) \\
coin & 1.4-2 & CRAN (R 4.2.1) \\
DeclareDesign & 1.0.2 & CRAN (R 4.2.1) \\
devtools & 2.4.4 & CRAN (R 4.2.1) \\
estimatr & 1.0.0 & CRAN (R 4.2.1) \\
future & 1.27.0 & CRAN (R 4.2.1) \\
future.apply & 1.9.0 & CRAN (R 4.2.1) \\
here & 1.0.1 & CRAN (R 4.2.1) \\
ICC & 2.4.0 & CRAN (R 4.2.1) \\
kableExtra & 1.3.4 & CRAN (R 4.2.1) \\
lmtest & 0.9-40 & CRAN (R 4.2.1) \\
multcomp & 1.4-22 & CRAN (R 4.2.1) \\
nbpMatching & 1.5.1 & CRAN (R 4.2.1) \\
quickblock & 0.2.0 & CRAN (R 4.2.1) \\
randomizr & 0.24.0 & CRAN (R 4.2.1) \\
remotes & 2.4.2 & CRAN (R 4.2.1) \\
ri2 & 0.4.0 & CRAN (R 4.2.1) \\
RItools & 0.3-2 & CRAN (R 4.2.1) \\
sandwich & 3.0-2 & CRAN (R 4.2.1) \\
tidyverse & 1.3.2 & CRAN (R 4.2.1) \\
withr & 2.5.0 & CRAN (R 4.2.1) \\
\bottomrule()
\end{longtable}

\hypertarget{statistical-and-causal-inference-for-policy-change}{%
\chapter{Statistical and causal inference for policy
change}\label{statistical-and-causal-inference-for-policy-change}}

Most of this this document dives into the details of our statistical
decision making and assumes that the reader has heard of a hypothesis
test and a statistical estimator. However, here we explain in very broad
terms how tests and estimators help us do our job in helping the US
federal government improve public policy.

Recall that ``evidence-based public policy'' can refer to \emph{both}
``evidence-as-insight'' (the use of previous scientific literature as
input to the design of new policies) and ``evidence-as-evaluation'' (the
careful design of studies to learn about how and whether a new policy
worked) \citep{bowers2019better}. Our team aims to help government
agencies \textbf{design} new policies and also to \textbf{learn} about
how those new ideas work. \textbf{This document focuses on the learning
part of our work.}

How would we know whether and how a new policy worked? In an ideal and
unrealistic case, we would know that a new policy improved the life of a
single person, Jake, if we could compare Jake's decisions \emph{both}
under the new policy \emph{and} under the status quo \emph{at the same
moment in time}. If we saw that Jake's decisions were better under the
new policy than under the status quo, we would say that the new policy
caused Jake to make better decisions. Since no one can observe Jake in
both situations --- say, making health decisions both with and without a
new procedure for visiting the doctor --- researchers try to find at
least one other person (if not more) who represents how Jake would have
acted if he had not been exposed to the new policy.
\citet{holland:1986a} calls this problem the ``fundamental problem of
causal inference'' and explains more formally about when we might
believe that other people are a good example of how Jake would have
acted without the new policy, for example, when we have randomized
access to the new policy, we can claim that that the two groups are good
counterfactuals for each other. That is, our team tends to think about
the \emph{causal effects} of a policy in \emph{counterfactual} terms.

What do statistics have to do with learning about the causal effect of a
new policy idea? We use randomized experiments to create groups of
people who represent \emph{both} the decisions made under the new policy
and the status quo. In medical experiments to assess the effectiveness
of new treatments, these two groups tend to be called the ``treatment
group'' and the ``control group'' and we sometimes use that same
language even if we are not really providing a new treatment, but are,
instead, offering a new communication or structure for a decision. If we
pilot the new policy with people chosen at random, we can claim that the
people chosen and the people not chosen represent each other. In a
randomized study, we can use what we see from one group to learn about
what would have happened had the other group instead received the
treatment or new policy intervention.

Now, if our study has, say, 1000 people in it, we don't know for sure
and exactly how the other group would have behaved. For example, if we
pulled 500 names from a hat, to divide the 1000 people into two groups,
we would have one set of 500 people. If we were to do the experiment
again, to pull another 500 names at random, this second experiment will
also be a randomized experiment, but the second 500 people will be
different from the first 500 people. This means that, a single
experiment offers us some information about the effect of the treatment,
but we need to ask a question like, ``How much would our best guess
differ just because we could have pulled a different 500 people from the
hat?'' We also need to answer questions like, ``What do you mean by
`best guess'? How do I know that this really is a good guess rather than
a bad guess?''

Our team uses statistical theory to produce ``best guesses'' or
``estimates'' about the causal effect of the new policy and we also use
statistical theory to answer questions about information like ``Could
the effect really have been zero?'' or ``How many people do we need to
observe in order to distinguish a positive effect from a zero effect?''

The rest of this document presents decisions we have made about the
particulars of estimators and tests, as well as other tricky decisions
that we have had to confront --- like what to do when some of data are
missing.

For more on the basics of how statistics helps us answer questions about
causal effects, we recommend chapters 1--3 of \citet{gerber_field_2012}
(which focuses on randomized experiments) and the first part of
\citet{rosenbaum2017} (which focuses on both experiments and research
designs without randomization).

\hypertarget{basics-of-experimental-design-and-analysis}{%
\chapter{Basics of Experimental Design and
Analysis}\label{basics-of-experimental-design-and-analysis}}

Here we very briefly define and describe some of the general
characteristics of statistical procedures that guide our decision making
in the rest of this guide. Briefly, we want to create research designs
that have enough statistical power to tell us something meaningful about
the new policy interventions that we are piloting, and we want to use
statistical tests that will rarely mislead us --- will rarely give a
false positive result, and we want to use estimators without systematic
error. These operating characteristics of our procedures depend on both
the design of the study and the choices of computational procedures that
we use. So, we descibe them more in-depth in the
\protect\hyperlink{poweranalysis}{Power Analysis} section that comes
after both our sections on randomization and the design of experiments
and the section on analysis choices.

\hypertarget{statistical-power-designing-studies-that-effectively-distinguish-signal-from-noise}{%
\section{Statistical Power: Designing Studies that effectively
distinguish signal from
noise}\label{statistical-power-designing-studies-that-effectively-distinguish-signal-from-noise}}

The research designs we use in the OES aim to enhance our ability to
distinguish signal from noise: studies with very few observations cannot
tell us much about the treatment effect, while studies with very many
observations provide a lot of information about the treatment effect. A
study which effectively distinguishes signal from noise has excellent
``statistical power'' and a study which cannot do this has low
statistical power. The Evidence in Governance and Politics (EGAP)
Methods Guide
\href{https://egap.org/methods-guides/10-things-you-need-know-about-statistical-power}{10
Things You Need to Know about Statistical Power} describes more about
what statistical power is and how to assess it.

Before we field a research design, we assess its statistical power. If
we anticipate that the intervention will only make a small change in
peoples' behavior, then we will need a relatively large number of people
in the study: too few people will result in a report saying something
like, ``The new policy might have improved the lives of the people in
the study, but we can't argue strongly that this is so because the study
was too small.''

\hypertarget{error-rates-of-tests}{%
\section{Error Rates of Tests}\label{error-rates-of-tests}}

A good statistical test rarely rejects a true hypothesis and often
rejects false hypotheses. The EGAP Methods Guide
\href{https://egap.org/methods-guides/10-things-know-about-hypothesis-testing}{10
Things to Know about Hypothesis Testing} describes the basics of
hypothesis tests and explains more about how one might know that a given
\(p\)-value arises from a test with good properties in a given research
design. Our team tries to follow these practices of choosing testing
procedures that are not likely to mislead analysts, when we make our
analysis plans and complete our analyses and re-analyses.

\hypertarget{bias-in-estimators}{%
\section{Bias in Estimators}\label{bias-in-estimators}}

A good estimator is not systematically different from the truth, and an
even better estimator tends to produce estimates that are close to the
truth across different experiments. Because the difference of means
between treatment and control groups is well known as an unbiased
estimator of the average treatment effect within a given experimental
pool, this is a primary quantity of interest to report by our team.
Similarly, since we know that the coefficient in a logistic regression
of a binary outcome on a treatment indicator and a covariate is a biased
estimator of the underlying causal difference in log-odds we use other
approaches when we want to talk about the causal effect of a treatment
on log-odds \citep{freedman2008randomization}.

\hypertarget{design-based-principles-of-statistical-inference}{%
\chapter{Design-Based Principles of Statistical
Inference}\label{design-based-principles-of-statistical-inference}}

Most policy evaluations using administrative data or surveys report the
results of their studies using estimators and tests. Although we can
never know the true causal effect of a new policy on our beneficiaries,
we can provide a best guess (``The average amount saved for retirement
by people in the treatment group was \$1000 more than the average amount
in the control group: our estimate of the average treatment effect is
\$1000.'') and we can provide a test of a hunch or hypothesis (``We can
reject the null hypothesis at the 5\% significance level with
\(p=.02\).''). Confidence intervals, by the way, summarize hypothesis
tests, so we think of them as tests rather than estimators.

Now, when we are asked \emph{why} we used this or that method for
calculating an average treatment effect or a \(p\)-value or a confidence
interval, our team has tended to say that our statistical analyses
depend on the \textbf{design} of our studies. When applied to randomized
experiments, this principle can be written simply as: \textbf{analyze as
you randomize.} We provide an example of this principle in practice
\protect\hyperlink{randinfex}{below}. This idea, often known as
``randomization based'' or ``design based'' inference, was proposed by
two of the founders of modern statistics. Jerzy Neyman's 1923 paper
showed how to use randomization to learn about what we would currently
call ``average treatment effects'' (\citet{neyman_application_1923}) and
Ronald A. Fisher's 1935 book showed how to use randomization to test
hypotheses about what we would currently call ``treatment effects''
(\citet{fisher_design_1935}). We mention this commitment here because it
guides our choices of statistical tools in general.

We use a design based approach because we often know how a study was
designed --- after all, we and our agency collaborators tend to be the
ones deciding on the sample size, the experimental arms, and the outcome
data to be extracted from administrative databases. There are other ways
to justify statistical procedures, and we do not exclude any reasonable
approach in our work --- such as approaches based on theoretical
probability models. However, referring to what we know we did in a given
study has served us well so far, and it thus forms the basis of our
decisions in general.

\hypertarget{randinfex}{%
\section{An example using simulated data}\label{randinfex}}

Imagine we have a simple randomized experiment where the relationship
between outcomes and treatment is shown in Figure \ref{fig:boxplot1}.
Notice that, in this simulated experiment, the treatment changes the
variability in the outcome in the treated group --- this is a common
pattern when the control group is status quo.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Read in data for the fake experiment}
\NormalTok{dat1 }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"dat1.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# y0 and y1 are the true underlying potential outcomes.}
\FunctionTok{with}\NormalTok{(dat1, \{}
  \FunctionTok{boxplot}\NormalTok{(}\FunctionTok{list}\NormalTok{(y0, y1), }\AttributeTok{names =} \FunctionTok{c}\NormalTok{(}\StringTok{"Control"}\NormalTok{, }\StringTok{"Treatment"}\NormalTok{), }\AttributeTok{ylab =} \StringTok{"Outcomes"}\NormalTok{)}
  \FunctionTok{stripchart}\NormalTok{(}\FunctionTok{list}\NormalTok{(y0, y1), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{vertical =} \ConstantTok{TRUE}\NormalTok{)}
  \FunctionTok{stripchart}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\FunctionTok{mean}\NormalTok{(y0), }\FunctionTok{mean}\NormalTok{(y1)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{vertical =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{, }\AttributeTok{cex =} \DecValTok{2}\NormalTok{)}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/boxplot1-1}

In this simulated data, we know the true average treatment effect (ATE)
because we know both of the underlying true potential outcomes (written
in code as \texttt{y0} for \(y_{i,Z_i=0}\) or ``the response person
\(i\) would provide if he/she were in the status quo or control group''
and \texttt{y1} for \(y_{i,Z_i = 1}\) for ``the response person \(i\)
would provide if he/she were in the new policy or treatment group''. We
use \(Z_i\) to refer to the experimental arm. In this case \(Z_i=0\) for
people in the status quo and \(Z_i=1\) for people in the new policy.
(You can click to SHOW the code.)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trueATE }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{mean}\NormalTok{(y1) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y0))}
\NormalTok{trueATE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5.453
\end{verbatim}

Now, we have one experiment (defined by randomly assigning half of the
people to treatment and half to control). We know that the observed
difference of means of the outcome, \(Y\), between treated and control
groups is an unbiased estimator of the true ATE. And we can calculate
this number in a few ways: Notice that we can just calculate the
difference of means or we can use the fact that the ordinary least
squares linear model also calculates the same number if we have a binary
treatment on the right hand side.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Y is the observed outcome.}
\NormalTok{estATE1 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{mean}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]))}
\NormalTok{estATE2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}\SpecialCharTok{$}\NormalTok{coef[[}\StringTok{"Z"}\NormalTok{]]}
\FunctionTok{c}\NormalTok{(}\AttributeTok{estimatedATEv1 =}\NormalTok{ estATE1, }\AttributeTok{estimatedATEv2 =}\NormalTok{ estATE2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
estimatedATEv1 estimatedATEv2 
         4.637          4.637 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(estATE1, estATE2))}
\end{Highlighting}
\end{Shaded}

\textbf{The design-based perspective causes differences in our approach
when we think about how to calculate standard errors (and thus
\(p\)-values and confidence intervals).}

\hypertarget{how-do-we-calculate-randomization-based-standard-errors}{%
\subsection{How do we calculate randomization-based standard
errors?}\label{how-do-we-calculate-randomization-based-standard-errors}}

How would an estimate of the average treatment effect vary if we
repeated the experiment on the same group of people? The standard error
of an estimate of the average treatment effect is one answer to this
question. Below, we simulate a simple, individual-level experiment to
develop intuition about what a standard error is.\footnote{See
  \url{http://egap.org/methods-guides/10-types-treatment-effect-you-should-know-about}
  for a demonstration that the difference of means in the observed
  treatment and control groups is an unbiased estimator of the average
  treatment effect itself and what it means to be unbiased.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simEstAte }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(Z, y1, y0) \{}
  \DocumentationTok{\#\# A function to re{-}assign treatment and recalculate the difference of means}
  \DocumentationTok{\#\# Treatment was assigned without blocking or other structure, so we}
  \DocumentationTok{\#\# just permute or shuffle the existing treatment assignment vector}
\NormalTok{  Znew }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(Z)}
\NormalTok{  Y }\OtherTok{\textless{}{-}}\NormalTok{ Znew }\SpecialCharTok{*}\NormalTok{ y1 }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Znew) }\SpecialCharTok{*}\NormalTok{ y0}
\NormalTok{  estate }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Y[Znew }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y[Znew }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
  \FunctionTok{return}\NormalTok{(estate)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims }\OtherTok{\textless{}{-}} \DecValTok{10000}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{simpleResults }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{replicate}\NormalTok{(sims, }\FunctionTok{simEstAte}\NormalTok{(}\AttributeTok{Z =}\NormalTok{ Z, }\AttributeTok{y1 =}\NormalTok{ y1, }\AttributeTok{y0 =}\NormalTok{ y0)))}
\DocumentationTok{\#\# The standard error of the estimate of the ATE.}
\NormalTok{seEstATEsim }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(simpleResults)}
\NormalTok{seEstATEsim}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9256
\end{verbatim}

Although this preceding standard error is intuitive (it is merely the
standard deviation of the distribution arising from repeating the
experiment), more statistics-savvy readers will recognize closed-form
expressions for the standard error like the following (See
\citet{gerber_field_2012} and \citet{dunning_natural_2012} for easy to
read explanations and derivations of the design-based standard error of
the simple estimator of the average treatment effect.) If we write \(T\)
as the set of all \(m\) treated units and \(C\) as the set of all
\(n-m\) non-treated units, we might write

\begin{equation}
\widehat{Var}(\hat{T})  =  s^2(Y_{i,i \in T})/m + s^2(Y_{i,i \in C})/(n-m)
\end{equation}

where \(s^2(x)\) is the sample variance such that
\(s^2(x) = (1/(n-1))\sum^n_{i = 1}(x_i-\bar{x})^2\). Here we compare the
results of the simulation to this most common standard error as well as
to the true version: We know what the true variance of the estimated ATE
would be because we know the algebra of variances and covariances and
because, in this example, we know the actual underlying counterfactual
outcomes. We show this here to show that ``standard deviation of the
estimated ATE after repeating the experiment'' is the same as what
textbooks teach.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# True SE (Dunning Chap 6, Gerber and Green Chap 3 and Freedman, Pisani and Purves A{-}32)}
\DocumentationTok{\#\# including the covariance between the potential outcomes}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(dat1)}
\NormalTok{V }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{y0, dat1}\SpecialCharTok{$}\NormalTok{y1))}
\NormalTok{varc }\OtherTok{\textless{}{-}}\NormalTok{ V[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\NormalTok{vart }\OtherTok{\textless{}{-}}\NormalTok{ V[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\NormalTok{covtc }\OtherTok{\textless{}{-}}\NormalTok{ V[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\NormalTok{nt }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Z)}
\NormalTok{nc }\OtherTok{\textless{}{-}}\NormalTok{ N }\SpecialCharTok{{-}}\NormalTok{ nt}

\NormalTok{varestATE }\OtherTok{\textless{}{-}}\NormalTok{ ((N }\SpecialCharTok{{-}}\NormalTok{ nt) }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ (vart }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{{-}}\NormalTok{ nt)) }\SpecialCharTok{+}\NormalTok{ ((N }\SpecialCharTok{{-}}\NormalTok{ nc) }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ (varc }\SpecialCharTok{/}\NormalTok{ nc) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ covtc}
\NormalTok{seEstATETrue }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(varestATE)}
\end{Highlighting}
\end{Shaded}

And the finite sample \emph{feasible} version (where we do not observe
all the potential outcomes) and so we do not have the covariance. This
is what we calculate --- notice that it is not what OLS calculates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varYc }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{var}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]))}
\NormalTok{varYt }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{var}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]))}
\NormalTok{fvarestATE }\OtherTok{\textless{}{-}}\NormalTok{ (N }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ ((varYt }\SpecialCharTok{/}\NormalTok{ nt) }\SpecialCharTok{+}\NormalTok{ (varYc }\SpecialCharTok{/}\NormalTok{ nc))}
\NormalTok{estSEEstATE }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(fvarestATE)}
\end{Highlighting}
\end{Shaded}

Here we use the HC2 standard error --- which (\citet{lin_agnostic_2013})
shows is the randomization-justified SE for OLS. Following our
design-based approach, we use this standard error. And below we compare
the true standard error, the feasible standard error, the HC2 SE (which
is the same as the feasible standard error), the standard error arising
from direct repetition of the experiment, and the OLS standard error.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}

\DocumentationTok{\#\# The OLS SE}
\NormalTok{iidSE }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{vcov}\NormalTok{(lm1)))[[}\StringTok{"Z"}\NormalTok{]]}

\DocumentationTok{\#\# Worth noting that if we had covariates in the model we would want this one}
\DocumentationTok{\#\# (which is identical to the previous one without covariates).}

\NormalTok{NeymanSE }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{vcovHC}\NormalTok{(lm1, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{)))[[}\StringTok{"Z"}\NormalTok{]]}

\NormalTok{compareSEs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \AttributeTok{simSE =}\NormalTok{ seEstATEsim,}
  \AttributeTok{feasibleSE =}\NormalTok{ estSEEstATE,}
  \AttributeTok{trueSE =}\NormalTok{ seEstATETrue,}
  \AttributeTok{olsIIDSE =}\NormalTok{ iidSE,}
  \AttributeTok{NeymanDesignSE =}\NormalTok{ NeymanSE}
\NormalTok{)}
\FunctionTok{sort}\NormalTok{(compareSEs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        trueSE       olsIIDSE          simSE NeymanDesignSE     feasibleSE 
        0.6760         0.8930         0.9256         1.0387         1.0439 
\end{verbatim}

The Neyman SE is supposed to be conservative relative to the true SE.
Below, we show this to be the case. In this particular case, the SE of
the OLS estimator is larger than both of the other SEs --- recall that
our design involves different variance between the outcomes in the
treated group and the control group --- so we expect that what we are
calling the ``iid'' SE should be biased but not necessarily guaranteed
to be overly conservative or liberal in all cases.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sePerfFn }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(Z, y1, y0) \{}
\NormalTok{  Znew }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(Z)}
\NormalTok{  Ynew }\OtherTok{\textless{}{-}}\NormalTok{ Znew }\SpecialCharTok{*}\NormalTok{ y1 }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Znew) }\SpecialCharTok{*}\NormalTok{ y0}
\NormalTok{  lm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Ynew }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew)}
\NormalTok{  iidSE }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{vcov}\NormalTok{(lm1)))[[}\StringTok{"Znew"}\NormalTok{]]}
\NormalTok{  NeymanSE }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{vcovHC}\NormalTok{(lm1, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{)))[[}\StringTok{"Znew"}\NormalTok{]]}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{estATE =} \FunctionTok{coef}\NormalTok{(lm1)[[}\StringTok{"Znew"}\NormalTok{]],}
    \AttributeTok{estSEiid =}\NormalTok{ iidSE,}
    \AttributeTok{estSENeyman =}\NormalTok{ NeymanSE}
\NormalTok{  ))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{sePerformance }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{replicate}\NormalTok{(sims, }\FunctionTok{sePerfFn}\NormalTok{(}\AttributeTok{Z =}\NormalTok{ Z, }\AttributeTok{y1 =}\NormalTok{ y1, }\AttributeTok{y0 =}\NormalTok{ y0)))}
\FunctionTok{apply}\NormalTok{(sePerformance[}\FunctionTok{c}\NormalTok{(}\StringTok{"estSEiid"}\NormalTok{, }\StringTok{"estSENeyman"}\NormalTok{), ], }\DecValTok{1}\NormalTok{, summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        estSEiid estSENeyman
Min.      0.7004      0.6373
1st Qu.   0.8301      0.8949
Median    0.8511      0.9579
Mean      0.8511      0.9574
3rd Qu.   0.8720      1.0205
Max.      0.9600      1.2640
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ExpectedSEs }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(sePerformance[}\FunctionTok{c}\NormalTok{(}\StringTok{"estSEiid"}\NormalTok{, }\StringTok{"estSENeyman"}\NormalTok{), ], }\DecValTok{1}\NormalTok{, mean)}
\FunctionTok{c}\NormalTok{(ExpectedSEs, }\AttributeTok{trueSE =}\NormalTok{ seEstATETrue, }\AttributeTok{simSE =} \FunctionTok{sd}\NormalTok{(sePerformance[}\StringTok{"estATE"}\NormalTok{, ]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   estSEiid estSENeyman      trueSE       simSE 
     0.8511      0.9574      0.6760      0.9256 
\end{verbatim}

When we have a two arm trial, we can estimate the ATE and calculate
design-based standard errors and use them to create large-sample
justified confidence intervals in relatively large experiments using
either of the following approaches:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# the difference\_in\_means function comes from the estimatr package}
\NormalTok{estAndSE1 }\OtherTok{\textless{}{-}} \FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}
\DocumentationTok{\#\# coeftest and coefci come from the lmtest package}
\NormalTok{est2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}
\NormalTok{estAndSE2 }\OtherTok{\textless{}{-}} \FunctionTok{coeftest}\NormalTok{(est2, }\AttributeTok{vcov. =} \FunctionTok{vcovHC}\NormalTok{(est2, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{))}
\NormalTok{estAndCI2 }\OtherTok{\textless{}{-}} \FunctionTok{coefci}\NormalTok{(est2, }\AttributeTok{vcov. =} \FunctionTok{vcovHC}\NormalTok{(est2, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{), }\AttributeTok{parm =} \StringTok{"Z"}\NormalTok{)}

\NormalTok{estAndSE1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Design:  Standard 
  Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper    DF
Z    4.637      1.039   4.465 8.792e-05    2.524     6.75 33.12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE2[}\StringTok{"Z"}\NormalTok{, , drop }\OtherTok{=} \ConstantTok{FALSE}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Estimate Std. Error t value  Pr(>|t|)
Z    4.637      1.039   4.465 2.147e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndCI2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  2.5 % 97.5 %
Z 2.576  6.699
\end{verbatim}

\hypertarget{summary-what-does-a-design-based-approach-mean-for-policy-evaluation}{%
\section{Summary: What does a design based approach mean for policy
evaluation?}\label{summary-what-does-a-design-based-approach-mean-for-policy-evaluation}}

Hypothesis tests produce \(p\)-values telling us how much information we
have against null hypotheses. Estimators produce estimates --- guesses
about some causal effect like the average treatment effect. Standard
errors summarize how our estimates might vary from experiment to
experiment. Confidence intervals tell us which ranges of null hypotheses
are more versus less consistent with our data.

Recall that \(p\)-values and standard errors refer to probability
distributions of test statistics under a null hypothesis and the
distributions of estimators across repeated experiments, respectively.
In the frequentist approach to probability, these probability
distributions arise from some process of repetition. Statistics
textbooks often encourage us to imagine that this process of repetition
involves repeated sampling from a population, or even a hypothetical
super-population. But, most of the work of the OES involves a pool of
people who are not a well-definied population, nor do we tend to have a
strong probability model of how these people entered our sample.
Instead, we have a known process of random assignment to an experimental
intervention. And this makes a randomization-based inference approach
natural for our work, and helps our work be easiest to explain and
interepret for our policy partners.

\hypertarget{randomization-and-design}{%
\chapter{Randomization and Design}\label{randomization-and-design}}

After working together with our agency partners to translate insights
from the social and behavioral sciences into policy recommendations
following our \href{https://oes.gsa.gov/methods/}{process}, our combined
OES and agency teams assess these new ideas by observing differences and
changes in real world outcomes (usually measured using existing
administrative data). Nearly always, we design a randomized control
trial (an RCT) to ensure that the differences and changes we observe
arise from the policy intervention and not from some other pre-existing
difference or change. Here we show examples of the ways that we create
the random numbers that form the core of our different types of RCTs
that we use to build evidence about the effectiveness of the new policy.

\hypertarget{coin-flipping-randomization-versus-urn-drawing-randomization}{%
\section{Coin flipping randomization versus Urn-drawing
randomization}\label{coin-flipping-randomization-versus-urn-drawing-randomization}}

Many discussions of RCTs begin by talking about the intervention being
assigned to units (people, schools, offices, districts) ``by the flip of
a coin''. We rarely use this method directly even though it is a useful
way to introduce the idea that RCTs guarantee fair access to the new
policy.

The following code contrasts coin-flipping style randomization (where
the number of units in each condition is not guaranteed) with
drawing-from-an-urn style, or complete, randomization (where the number
of units in each condition is guaranteed). We try to avoid the
coin-flipping style of randomization because of this lack of control
over the number of units in each condition --- coin-flipping based
experiments are still valid and tell us about the underlying
counterfactuals, but they can have less statistical power.

Notice that the simple randomization implemented in the code below
results in more observations in the treatment group (group \texttt{1})
than in the control group (group \texttt{0}). The complete randomization
will always assign 5 units to the treatment, 5 to the control.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Start with a small experiment with only 10 units}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10}
\DocumentationTok{\#\# Set a seed for the pseudo{-}random number generator so that we always get the same results}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\DocumentationTok{\#\# Coin flipping does not guarantee half and half treated and control}
\DocumentationTok{\#\# This next bit of code shows the base R version of coin flipping randomization}
\DocumentationTok{\#\# trt\_coinflip \textless{}{-} rbinom(10, size = 1, prob = .5)}
\NormalTok{trt\_coinflip }\OtherTok{\textless{}{-}} \FunctionTok{simple\_ra}\NormalTok{(n)}
\DocumentationTok{\#\# Drawing from an urn or shuffling cards, guarantees half treated and control}
\DocumentationTok{\#\# trt\_urn \textless{}{-} sample(rep(c(1, 0), n / 2))}
\NormalTok{trt\_urn }\OtherTok{\textless{}{-}} \FunctionTok{complete\_ra}\NormalTok{(n)}
\FunctionTok{table}\NormalTok{(trt\_coinflip)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
trt_coinflip
0 1 
3 7 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(trt\_urn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
trt_urn
0 1 
5 5 
\end{verbatim}

\hypertarget{urn-drawing-or-complete-randomization-into-2-or-more-groups}{%
\section{Urn-Drawing or Complete Randomization into 2 or more
groups}\label{urn-drawing-or-complete-randomization-into-2-or-more-groups}}

We tend to use the \texttt{randomizr} R package \citep{R-randomizr} for
simple designs rather than the base R \texttt{sample} function because
thee \texttt{randomizr} does some quality control checks. Notice that we
implement a check on our code below with the \texttt{stopifnot} command:
the code will stop and issue a warning if we didn't actually assign 1/4
of the observations to the treatment condition. Here, we assign the
units first to 2 arms with equal probability (\texttt{Z2armEqual}) and
then, to show how the code works, to 2 arms where one arm has only 1/4
the probability of receiving treatment (imagining a design with an
expensive intervention) (\texttt{Z2armUnequalA} and
\texttt{Z2armUnequalB}), and then to a design with 4 arms, each with
equal probability. (We often use \(Z\) to refer to the variable
recording our intervention arms.)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(dat1)}
\DocumentationTok{\#\# Two equal arms}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z2armEqual }\OtherTok{\textless{}{-}} \FunctionTok{complete\_ra}\NormalTok{(N)}
\DocumentationTok{\#\# Two unequal arms: .25 chance of treatment}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z2armUnequalA }\OtherTok{\textless{}{-}} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{prob =}\NormalTok{ .}\DecValTok{25}\NormalTok{)}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Z2armUnequalA) }\SpecialCharTok{==}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{4}\NormalTok{)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z2armUnequalB }\OtherTok{\textless{}{-}} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{4}\NormalTok{)}
\DocumentationTok{\#\# Four equal arms}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z4arms }\OtherTok{\textless{}{-}} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m\_each =} \FunctionTok{rep}\NormalTok{(N }\SpecialCharTok{/} \DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{))}

\FunctionTok{table}\NormalTok{(}\AttributeTok{Z2armEqual =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z2armEqual)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z2armEqual
 0  1 
50 50 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(}\AttributeTok{Z2armUnequalA =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z2armUnequalA)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z2armUnequalA
 0  1 
75 25 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(}\AttributeTok{Z2armUnequalB =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z2armUnequalB)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z2armUnequalB
 0  1 
75 25 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(}\AttributeTok{Z4arms =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z4arms)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z4arms
T1 T2 T3 T4 
25 25 25 25 
\end{verbatim}

\hypertarget{factorial-designs}{%
\section{Factorial Designs}\label{factorial-designs}}

One can often test the effects of more than one intervention without
losing much statistical power by randomly assigning more than one
treatment independently of each other. The simplest design that we use
for this purpose is the \(2 \times 2\) factorial design. For example, in
the next table we see that we have assigned 50 observations to each arm
of both of two interventions. Since the randomization of
\texttt{treatment1} is independent of \texttt{treatment2}, we can assess
the effects of each treatment separately and pay little power penalty
unless one of the treatments dramatically increases the variance of the
outcome compared to the experiment with only one treatment assigned.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Two equal arms, second cross treatment}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z2armEqual2 }\OtherTok{\textless{}{-}} \FunctionTok{complete\_ra}\NormalTok{(N)}
\FunctionTok{table}\NormalTok{(}\AttributeTok{treatment1 =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z2armEqual, }\AttributeTok{treatment2 =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z2armEqual2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          treatment2
treatment1  0  1
         0 22 28
         1 28 22
\end{verbatim}

Although factorial designs allow us to test more than one intervention
at the same time, they tend to provide little statistical power for
testing hypotheses about the \textbf{interaction} of the two treatments.
If we want to learn about how two different interventions work together,
then the sample size requirements will be much larger than if we want to
learn about only each treatment separately.\footnote{But see
  \citet{small2011structured} for a way to increase the power of tests
  for such questions. This approach is not yet part of our standard
  practice.}

\hypertarget{block-random-assignment}{%
\section{Block Random Assignment}\label{block-random-assignment}}

Statistical power depends not only on the size of the experiment and the
strength of the treatment effect, but also on the amount of noise, or
non-treatment-related variability, in outcomes. Block-randomized designs
can help reduce the noise in outcomes, while simultaneously minimizing
estimation error -- the amount that our particular experiment's estimate
differs from the truth.

In a block-randomized, or stratified, experiment, we randomly assign
units to the policy interventions \emph{within} groups.

Suppose we are evaluating whether dedicated navigators can increase the
percentage of students who live in public housing who complete federal
financial aid applications (FAFSA). Our experiment will send navigators
to two of four eligible buildings, two of which are large and two of
which are small. Though we can never know the outcome in all buildings
both with and without navigators (the ``fundamental problem of causal
inference''), if we could, we might have the data below.

\begin{center}
\begin{tabular}{ccccc}
&&& FAFSA \% & FAFSA \% \\
Building & Size & Navigators? & if No Navigators & if Navigators   \\ \hline
1 & Large & $\_$ & 20 & 60 \\
2 & Large & $\_$ & 30 & 70 \\
3 & Small & $\_$ & 20 & 30 \\
4 & Small & $\_$ & 30 & 40 \\ \hline
&& Means: & 25 & 50 \\
\end{tabular}
\end{center}

In this case, the true average treatment effect for this sample is the
average under treatment minus the average under control:
\(\text{ATE} = 50-25=25\) percent more applications if navigators are
deployed everywhere.

If we randomly allocate two buildings to treatment and two to control,
we might treat the first two buildings and observe

\begin{center}
\begin{tabular}{ccccc}
&&& FAFSA \% & FAFSA \% \\
Building & Size & Navigators? & if No Navigators & if Navigators   \\ \hline
1 & Large & Yes &  & 60 \\
2 & Large & Yes &  & 70 \\
3 & Small & No & 20 &  \\
4 & Small & No & 30 &  \\ \hline
&& Means: & 25 & 65 \\
\end{tabular}
\end{center}

yielding an estimate of the treatment effect of \(65-25 = 40\) percent
more applications -- an estimate larger than the true value of 25.

Or, we might observe

\begin{center}
\begin{tabular}{ccccc}
&&& FAFSA \% & FAFSA \% \\
Building & Size & Navigators? & if No Navigators & if Navigators   \\ \hline
1 & Large & $\_$ &  & 60 \\
2 & Large & $\_$ & 30 &  \\
3 & Small & $\_$ &  & 30 \\
4 & Small & $\_$ & 30 &  \\ \hline
&& Means: & 30 & 45 \\
\end{tabular}
\end{center}

yielding an estimate of the treatment effect of \(45-30 = 15\) percent
fewer applications -- an estimate smaller than the true value of 25.

All the possible equiprobable assignments, and their estimated treatment
effects are below.

\begin{center}
\begin{tabular}{cc}
Assignments & Est TE \\ \hline
YYNN & 40  \\ 
NYNY & 35 \\
YNNY & 25 \\
NYYN & 25 \\
YNYN & 15 \\
NNYY & 10
\end{tabular}
\end{center}

These possible estimates have mean equal to the true value of 25,
showing that the difference in means is an unbiased estimator. However,
some of these estimates are far from the truth, and they have a lot of
variability.

To design our experiment to best estimate the true value, and to do so
with more statistical power, we can \emph{block} the experiment. Here,
this means restricting our randomization to those three possible
assignments that balance the large and small buildings across the
treatment groups.

\begin{center}
\begin{tabular}{cc}
Assignments & Est TE \\ \hline
NYNY & 35 \\
YNNY & 25 \\
NYYN & 25 \\
YNYN & 15 \\
\end{tabular}
\end{center}

With the blocked design, we will get an estimate no more than 10
percentage points from the truth. Further, our estimates will have less
variability (an SD of 8.16 rather than 11.4), improving the power of our
design.

For a more realistic example, suppose our experiment has two hospitals.
We might randomly assign people to treatment and control \emph{within}
each hospital. We might assign half of the people in hospital ``A'' to
treatment and half to control and likewise in hospital ``B''.\footnote{We
  use ``block'' rather than ``strata'' throughout this document to refer
  to groups of experimental units that are fixed before randomization,
  where group membership cannot be changed by the experiment itself.}
Below, we have 50 units in hospital ``A'' and 50 in hospital ``B''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{blockID }\OtherTok{\textless{}{-}} \FunctionTok{gl}\NormalTok{(}\AttributeTok{n =} \DecValTok{2}\NormalTok{, }\AttributeTok{k =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{))}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(}\AttributeTok{blockID =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blockID))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
blockID
 A  B 
50 50 
\end{verbatim}

We assign half of the units in each hospital to each treatment
condition:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z2armBlocked }\OtherTok{\textless{}{-}} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blockID)}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(blockID, Z2armBlocked))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       Z2armBlocked
blockID  0  1
      A 25 25
      B 25 25
\end{verbatim}

If, say, there were fewer people eligible for treatment in hospital
``A'' --- or perhaps the intervention was more expensive in that block
--- we might assign treatment with different probability within each
block. The code below shows half of the hospital ``A'' units assigned to
treatment, but only a quarter of those from hospital ``B''. Again, we
check that this code worked by including a test. This approach is an
informal version of one of the best practices in writing code in
general, called ``unit testing''. See the
\href{https://rawgit.com/egap/methods-guides/master/workflow/workflow.html\#to-minimize-error-build-testing-into-the-code}{EGAP
Guide to Workflow for more examples}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Z2armBlockedUneqProb }\OtherTok{\textless{}{-}} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blockID, }\AttributeTok{block\_prob =} \FunctionTok{c}\NormalTok{(.}\DecValTok{5}\NormalTok{, .}\DecValTok{25}\NormalTok{))}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(blockID, Z2armBlockedUneqProb))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       Z2armBlockedUneqProb
blockID  0  1
      A 25 25
      B 38 12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Z2armBlockedUneqProb }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blockID }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{) }\SpecialCharTok{==} \FunctionTok{ceiling}\NormalTok{(}\FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{blockID }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{) }\SpecialCharTok{/} \DecValTok{4}\NormalTok{) }\SpecialCharTok{|}
  \FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Z2armBlockedUneqProb }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blockID }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{) }\SpecialCharTok{==} \FunctionTok{floor}\NormalTok{(}\FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{blockID }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{) }\SpecialCharTok{/} \DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Our team tries to implement block-randomized assignment whenever
possible in order to increase the statistical power of our experiments.
We also often find it useful in cases where different administrative
units are implementing the treatment or where we expect different groups
of people to have different reactions to the treatment.

\hypertarget{using-only-a-few-covariates-to-create-blocks}{%
\subsection{Using only a few covariates to create
blocks}\label{using-only-a-few-covariates-to-create-blocks}}

If we have background information on a few covariates, we can great
blocks by hand using the kind of process demonstrated here:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# For example, make three groups from the cov2 variable}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{cov2cat }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{cut}\NormalTok{(cov2, }\AttributeTok{breaks =} \DecValTok{3}\NormalTok{))}
\FunctionTok{table}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{cov2cat, }\AttributeTok{exclude =} \FunctionTok{c}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

(-7.32,-2.6]   (-2.6,2.1]   (2.1,6.82] 
          11           68           21 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{tapply}\NormalTok{(cov2, cov2cat, summary))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$`(-7.32,-2.6]`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  -7.30   -5.03   -3.67   -4.14   -3.01   -2.77 

$`(-2.6,2.1]`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-2.3916 -0.7630 -0.0194 -0.0218  0.7592  2.0864 

$`(2.1,6.82]`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   2.13    2.46    2.95    3.24    3.68    6.80 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# And we can make blocks that are the same on two covariates}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{cov1bin }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{cov1 }\SpecialCharTok{\textgreater{}} \FunctionTok{median}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{cov1))}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{blockV2 }\OtherTok{\textless{}{-}} \FunctionTok{droplevels}\NormalTok{(}\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{interaction}\NormalTok{(cov1bin, cov2cat)))}
\FunctionTok{table}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{blockV2, }\AttributeTok{exclude =} \FunctionTok{c}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

0.(-7.32,-2.6] 1.(-7.32,-2.6]   0.(-2.6,2.1]   1.(-2.6,2.1]   0.(2.1,6.82]   1.(2.1,6.82] 
             7              4             38             30              5             16 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# And then assign within these blocks}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{ZblockV2 }\OtherTok{\textless{}{-}} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blockV2)}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(blockV2, ZblockV2, }\AttributeTok{exclude =} \FunctionTok{c}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                ZblockV2
blockV2           0  1
  0.(-7.32,-2.6]  4  3
  1.(-7.32,-2.6]  2  2
  0.(-2.6,2.1]   19 19
  1.(-2.6,2.1]   15 15
  0.(2.1,6.82]    2  3
  1.(2.1,6.82]    8  8
\end{verbatim}

\hypertarget{multivariate-blocking-using-many-covariates}{%
\subsection{Multivariate blocking using many
covariates}\label{multivariate-blocking-using-many-covariates}}

If we have many background variables, we can increase precision by
thinking about the problem of blocking as a problem of matching or
creating sets of units which are as similar as possible in terms of the
collection of those covariates
\citep{moore2012multivariate, moore2016bT063}. Here we show two
approaches.

Creating pairs:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# using the blockTools package}
\NormalTok{mvblocks }\OtherTok{\textless{}{-}} \FunctionTok{block}\NormalTok{(dat1, }\AttributeTok{id.vars =} \StringTok{"id"}\NormalTok{, }\AttributeTok{block.vars =} \FunctionTok{c}\NormalTok{(}\StringTok{"cov1"}\NormalTok{, }\StringTok{"cov2"}\NormalTok{), }\AttributeTok{algorithm =} \StringTok{"optimal"}\NormalTok{)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{blocksV3 }\OtherTok{\textless{}{-}} \FunctionTok{createBlockIDs}\NormalTok{(mvblocks, }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{id.var =} \StringTok{"id"}\NormalTok{)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{ZblockV3 }\OtherTok{\textless{}{-}} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blocksV3)}
\DocumentationTok{\#\# just show the first ten pairs}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(blocksV3, ZblockV3, }\AttributeTok{exclude =} \FunctionTok{c}\NormalTok{()))[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        ZblockV3
blocksV3 0 1
      1  1 1
      2  1 1
      3  1 1
      4  1 1
      5  1 1
      6  1 1
      7  1 1
      8  1 1
      9  1 1
      10 1 1
\end{verbatim}

Creating larger blocks:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# using the quickblock package}
\NormalTok{distmat }\OtherTok{\textless{}{-}} \FunctionTok{distances}\NormalTok{(dat1,}
  \AttributeTok{dist\_variables =} \FunctionTok{c}\NormalTok{(}\StringTok{"cov1"}\NormalTok{, }\StringTok{"cov2"}\NormalTok{), }\AttributeTok{id\_variable =}
    \StringTok{"id"}\NormalTok{, }\AttributeTok{normalize =} \StringTok{"mahalanobiz"}
\NormalTok{)}
\NormalTok{distmat[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       1      2      3      4      5
1 0.0000 1.4766 0.3313 0.2835 0.6736
2 1.4766 0.0000 1.6919 1.5891 0.9681
3 0.3313 1.6919 0.0000 0.5477 0.7729
4 0.2835 1.5891 0.5477 0.0000 0.9089
5 0.6736 0.9681 0.7729 0.9089 0.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{quantile}\NormalTok{(}\FunctionTok{as.vector}\NormalTok{(distmat), }\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      0%      10%      20%      30%      40%      50%      60%      70%      80%      90%     100% 
-3.13279 -1.18748 -0.79019 -0.38455 -0.14051  0.08898  0.26701  0.53818  0.89242  1.34321  2.91687 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The caliper argument is supposed to prevent the inclusion of ill{-}matched}
\DocumentationTok{\#\# points.}
\NormalTok{mvbigblock }\OtherTok{\textless{}{-}} \FunctionTok{quickblock}\NormalTok{(distmat, }\AttributeTok{size\_constraint =}\NormalTok{ 6L) }\CommentTok{\# ,caliper=2.5)}
\DocumentationTok{\#\# Look for missing points}
\FunctionTok{table}\NormalTok{(mvbigblock, }\AttributeTok{exclude =} \FunctionTok{c}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
mvbigblock
 0  1  2  3  4  5  6  7  8  9 10 11 
 6  6  6  6  8 11 14  7  7 10  7 12 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{blocksV4 }\OtherTok{\textless{}{-}}\NormalTok{ mvbigblock}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{ZblockV4 }\OtherTok{\textless{}{-}} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{blocksV4)}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(blocksV4, ZblockV3, }\AttributeTok{exclude =} \FunctionTok{c}\NormalTok{()))[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        ZblockV3
blocksV4 0 1
       0 3 3
       1 2 4
       2 4 2
       3 3 3
       4 5 3
       5 6 5
       6 6 8
       7 4 3
       8 4 3
       9 4 6
\end{verbatim}

Here we produce some description of the differences within block: the
proportion of people in category ``1'' on the binary covariate (notice
that the sets are homogeneous on this covariate) and the difference
between the largest and smallest value on the continuous covariate.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{blockingDescEval }\OtherTok{\textless{}{-}}\NormalTok{ dat1 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(blocksV4) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{cov2diff =} \FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(cov2))}
    \SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{abs}\NormalTok{(cov2)),}
    \AttributeTok{cov1 =} \FunctionTok{mean}\NormalTok{(cov1)}
\NormalTok{  )}
\NormalTok{blockingDescEval}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 3
   blocksV4   cov2diff    cov1
   <qb_blckn>    <dbl>   <dbl>
 1  0             3.62  0.555 
 2  1             2.92  4.21  
 3  2             1.91 -3.89  
 4  3             3.64 -1.38  
 5  4             2.78  3.60  
 6  5             1.28  1.51  
 7  6             3.44  0.577 
 8  7             1.91 -0.0277
 9  8             1.46  1.56  
10  9             2.61 -2.41  
11 10             2.68 -1.35  
12 11             1.16 -0.770 
\end{verbatim}

\hypertarget{cluster-random-assignment}{%
\section{Cluster random assignment}\label{cluster-random-assignment}}

We often implement a new policy intervention at the level of some group
of people --- like a doctor's practice, or a building, or some other
administrative unit. Notice that, even though we have 100 units in our
example data, imagine that they are grouped into 10 buildings, and the
policy intervention is at the building level. Below, we assign 50 of
those units to treatment and 50 to control. Everyone in each building
has the same treatment assignment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ndat1 }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(dat1)}
\DocumentationTok{\#\# Make an indicator of cluster membership}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{buildingID }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{(ndat1 }\SpecialCharTok{/} \DecValTok{10}\NormalTok{), }\AttributeTok{length =}\NormalTok{ ndat1)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Zcluster }\OtherTok{\textless{}{-}} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{buildingID)}
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(Zcluster, buildingID))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        buildingID
Zcluster  1  2  3  4  5  6  7  8  9 10
       0 10  0 10 10  0  0  0  0 10 10
       1  0 10  0  0 10 10 10 10  0  0
\end{verbatim}

Cluster randomized designs raise new questions about estimation and
testing and thus statistical power. We describe our approaches to
analysis and power analysis of cluster randomized designs
\protect\hyperlink{clusterrandanalysis}{in the section on the analysis
of Cluster Randomized Trials}.

\hypertarget{other-designs}{%
\section{Other designs}\label{other-designs}}

Our team has also designed stepped-wedge style designs, saturation
designs aimed to discover whether the effects of the experimental
intervention are communicated across people (via some spillover or
network mechanism), and designs where we try to isolate certain
experimental units (like buildings) from each other so that we can focus
our learning about the effects of the intervention rather than on the
effects of communication of the intervention across people. In later
versions of this document we will include simple descriptions and code
for those other, less common designs.

\hypertarget{randomization-assessment}{%
\section{Randomization assessment}\label{randomization-assessment}}

If we have covariates, we can assess the performance of the
randomization procedure by testing the hypothesis that the
treatment-vs-control differences, or differences across treatment arms,
in covariates are consistent with our claimed mechanism of
randomization. In the absence of covariates, we assess whether the
number of units assigned to each arm (conditional on other design
features, such as blocking or stratification) are consistent with the
claimed random assignment.

Here is an example with a binary treatment and a continuous outcome and
10 covariates. In this case we use the \(d^2\) omnibus balance test
function \texttt{xBalance()} in the package \texttt{RItools}
\citetext{\citealp[see][
]{hansen_covariate_2008}; \citealp{bowers_ritools_2016}}.

The ``overall'' \(p\)-value below shows us that we have little evidence
against the idea that treatment (\(Z\)) was assigned at random --- at
least in terms of the relationships between the two covariates and the
treatment assignment. The test statistics here are mean differences.
This overall or omnibus test is the key here --- if we had many
covariates, it would easy to discover one or a few covariates with means
that differ detectably from zero just by chance. That is, in a
well-operating experiment, we would expect some baseline imbalances (as
measured using randomization based tests) -- roughly 5 in 100. Thus the
value of the omnibus test is that we will not be misled by chance false
positives.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{randAssessV1 }\OtherTok{\textless{}{-}} \FunctionTok{balanceTest}\NormalTok{(Z }\SpecialCharTok{\textasciitilde{}}\NormalTok{ cov1 }\SpecialCharTok{+}\NormalTok{ cov2, }\AttributeTok{data =}\NormalTok{ dat1)}
\NormalTok{randAssessV1}\SpecialCharTok{$}\NormalTok{overall[, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   chisquare df p.value
--     1.998  2  0.3683
\end{verbatim}

Here is an example of randomization assessment with block-randomized
assignment:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{randAssessV3 }\OtherTok{\textless{}{-}} \FunctionTok{balanceTest}\NormalTok{(ZblockV3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ cov1 }\SpecialCharTok{+}\NormalTok{ cov2 }\SpecialCharTok{+} \FunctionTok{strata}\NormalTok{(blocksV3), }\AttributeTok{data =}\NormalTok{ dat1)}
\NormalTok{randAssessV3}\SpecialCharTok{$}\NormalTok{overall[, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         chisquare df p.value
blocksV3    2.8342  2  0.2424
--          0.1365  2  0.9340
\end{verbatim}

One can also assess the randomization given both block and cluster
random assignment using a formula like so:
\texttt{Z\ \textasciitilde{}\ cov1\ +\ cov2\ +\ strata(blockID)\ +\ cluster(clusterID)}.

This approach, using the \texttt{RItools} package, works well for
experiments that are not overly small. In a very small experiment, say,
an experiment with 5 clusters assigned to treatment and 5 clusters
assigned to control, we would do the same test, but would not use the
\(\chi^2\) distribution. Instead, we would do a permutation-based test.

We do not use \(F\)-tests or Likelihood Ratio tests to assess
randomization. See \citet{hansen_covariate_2008} for some evidence that
a test based on randomization-inference (like the \(d^2\) test developed
in that article) maintains false positive rates better than the
sampling- or likelihood-justified \(F\) and likelihood ratio tests.

\hypertarget{what-to-do-with-failed-randomization-assessments}{%
\subsection{What to do with ``failed'' randomization
assessments?}\label{what-to-do-with-failed-randomization-assessments}}

A \(p\)-value less than .05 on a test of randomization mechanism ought
to triggers extra scrutiny of how the randomization was conducted and
how the data were recorded by the agency. For example, we might contact
our agency partner to learn more deetails about how the random numbers
themselves were generated, or we may ask for the SQL or SAS code or
other code that might have been used to randomize. In most cases, we
will learn that randomization worked well but that our understanding of
the design and the data were incorrect. In some cases, we will learn
that the randomization occurred as we had initially understood. In such
cases, we tend to assume that rejecting the null in our randomization
assessment is a false positive from our testing procedure (we assume we
would see about 5 such errors in every 100 experiments). If the
rejection of the null appears to be driven by one or more particularly
substantively relevant covariates, say, the variable age looks very
imbalanced between treated and control groups in a health study, then we
will present both the unadjusted results but also adjust for that
covariate via stratification and/or covariance adjustment as we describe
later in this document. A chance rejection of the null that the
experiment was randomized as it should not cause us to the use the
adjusted estimate as our primary causal effect --- after all, it will be
biased whereas the unadjusted estimate will not be biased undere chance
departures from the null. But, large differences between the two
estimates can inform the qualitative task of substantive interpretation
of the study: looking at different effects by age groups, for example,
might tell us something about the particular context of the study and,
in turn, help us think about what we have learned.

\hypertarget{how-to-minimize-large-chance-departures-of-randomization}{%
\subsection{How to minimize large chance departures of
randomization?}\label{how-to-minimize-large-chance-departures-of-randomization}}

Our approach to block-randomization helps us avoid these problems. We
can also restrict our randomization in ways that are more flexible than
requiring blocks, but which, in turn should minimize chance. We tend not
to use re-randomization, among methods of restricted randomization, only
because we often can use block-randomization and thus can minimize the
complexity of later analysis. However, since we pursue a
randomization-based approach to the analysis of experiments, we can
easily (in concept) estimate causal effects and test hypotheses about
causal effects as well after such modes of randomization.

\hypertarget{analysis-choices}{%
\chapter{Analysis Choices}\label{analysis-choices}}

We organize our discussion of analysis tactics by design of the study.
Different study designs require different analyses. But there are a few
general tactics that we use to pursue the strategy of transparent,
valid, and statistically precise statements about the results of our
experiments.

The nature of the data that we expect to see from a given experiment
also informs our analysis plans. For example, we may make some specific
choices depending on the nature of the measured outcome --- a binary
outcome, a symmetrically distributed continuous outcome, and a heavily
skewed continuous outcome each might require some different approaches
within the blocked/not blocked and clustered/not clustered designs.

We tend to ask three questions of each of our studies that we answer
with a different statistical procedure.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Can we detect an effect of our experiment? (We use hypothesis tests to
  answer this question).
\item
  What is our best guess about the size of the effect of the experiment?
  (We estimate the average treatment effect of our interventions to
  answer this question.)
\item
  How precise is our guess? (We report confidence intervals and standard
  errors.)
\end{enumerate}

Each procedure below describes testing a hypothesis of no effect,
estimating an average treatment effect, and finding standard errors and
confidence intervals for different categories of experiments.

In our
\href{https://oes.gsa.gov/methodsdetail/\#analysis-plans}{Analysis
Plans}, we try to anticipate many of the common decisions involved in
data analysis --- including how we treat missing data, how we rescale,
recode, and combine columns of raw data, etc. We touch on some of these
topics below in general terms.

\hypertarget{completely-or-urn-draw-randomized-trials}{%
\section{Completely or Urn-Draw Randomized
Trials}\label{completely-or-urn-draw-randomized-trials}}

\hypertarget{two-arms}{%
\subsection{Two arms}\label{two-arms}}

\hypertarget{continuous-outcomes}{%
\subsubsection{Continuous outcomes}\label{continuous-outcomes}}

In a completely randomized trial where outcomes take on many levels
(units like times, counts of events, dollars, percentages, etc.), we
assess the weak null hypothesis of no average effects, we estimate an
average treatment effect, and we often assess the sharp null hypothesis
of no effects using some test statistic other than a difference of
means. We perform this last assessment often as a check on whether our
choice to focus on means matters for our substantive interpretation of
the results of the study.

\hypertarget{estimating-the-average-treatment-effect-and-testing-the-weak-null-of-no-average-effects}{%
\paragraph{Estimating the average treatment effect and testing the weak
null of no average
effects}\label{estimating-the-average-treatment-effect-and-testing-the-weak-null-of-no-average-effects}}

We show the kind of code we use for these purposes here. Below,
\texttt{Y} is the outcome variable and \texttt{Z} is an indicator of the
assignment to treatment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE1 }\OtherTok{\textless{}{-}} \FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}
\FunctionTok{print}\NormalTok{(estAndSE1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Design:  Standard 
  Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper    DF
Z    4.637      1.039   4.465 8.792e-05    2.524     6.75 33.12
\end{verbatim}

Notice that the standard errors that we use are not the same as the
result from OLS itself:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE1OLS }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}
\FunctionTok{summary}\NormalTok{(estAndSE1OLS)}\SpecialCharTok{$}\NormalTok{coef}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            Estimate Std. Error t value  Pr(>|t|)
(Intercept)    2.132     0.4465   4.775 6.283e-06
Z              4.637     0.8930   5.193 1.123e-06
\end{verbatim}

The standard errors we use by default reflect repeated randomization
from a fixed experimental pool. This is known as the HC2 standard error.
\citet{lin_agnostic_2013} and \citet{samii_equivalencies_2012} show this
is equivalent to the design-based standard error for standard unbiased
estimators of the average treatment effect. These correct SEs are
produced by default from the \texttt{estimatr} package's function
\texttt{difference\_in\_means()} and the \texttt{lmtest} package's
functions \texttt{coeftest()} and \texttt{coefci()}.

\hypertarget{testing-the-sharp-null-of-no-effects}{%
\paragraph{Testing the sharp null of no
effects}\label{testing-the-sharp-null-of-no-effects}}

We also tend to assess the sharp null of no effects via direct
permutation as a check on the assumptions underlying the statistical
inferences above. We tend to use a \(t\)-statistic as the test statistic
in this case to parallel the above test, and also use a rank-based test
if we are concerned about long-tails reducing power in the above test.

Below, we show how to perform these tests using three different R
packages: \texttt{RItools}, \texttt{coin}, and \texttt{ri2}. First the
\texttt{RItools} package \citep{R-RItools}:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Currently RItest is only in the randomization{-}distribution development branch}
\DocumentationTok{\#\# of RItools. This code would work if that branch were installed.}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{test1T }\OtherTok{\textless{}{-}} \FunctionTok{RItest}\NormalTok{(}\AttributeTok{y =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Y, }\AttributeTok{z =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z, }\AttributeTok{test.stat =}\NormalTok{ t.mean.difference, }\AttributeTok{samples =} \DecValTok{1000}\NormalTok{)}
\FunctionTok{print}\NormalTok{(test1T)}
\NormalTok{test1R }\OtherTok{\textless{}{-}} \FunctionTok{RItest}\NormalTok{(}\AttributeTok{y =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{rankY, }\AttributeTok{z =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z, }\AttributeTok{test.stat =}\NormalTok{ t.mean.difference, }\AttributeTok{samples =} \DecValTok{1000}\NormalTok{)}
\FunctionTok{print}\NormalTok{(test1R)}
\end{Highlighting}
\end{Shaded}

The \texttt{coin} package \citep{R-coin}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test1coinT }\OtherTok{\textless{}{-}} \FunctionTok{oneway\_test}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{distribution =} \FunctionTok{approximate}\NormalTok{(}\AttributeTok{nresample =} \DecValTok{1000}\NormalTok{))}
\NormalTok{test1coinT}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Approximative Two-Sample Fisher-Pitman Permutation Test

data:  Y by factor(Z) (0, 1)
Z = -4.6, p-value <0.001
alternative hypothesis: true mu is not equal to 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test1coinR }\OtherTok{\textless{}{-}} \FunctionTok{oneway\_test}\NormalTok{(rankY }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{distribution =} \FunctionTok{approximate}\NormalTok{(}\AttributeTok{nresample =} \DecValTok{1000}\NormalTok{))}
\NormalTok{test1coinR}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Approximative Two-Sample Fisher-Pitman Permutation Test

data:  rankY by factor(Z) (0, 1)
Z = -4.9, p-value <0.001
alternative hypothesis: true mu is not equal to 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test1coinWR }\OtherTok{\textless{}{-}} \FunctionTok{wilcox\_test}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{distribution =} \FunctionTok{approximate}\NormalTok{(}\AttributeTok{nresample =} \DecValTok{1000}\NormalTok{))}
\NormalTok{test1coinWR}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Approximative Wilcoxon-Mann-Whitney Test

data:  Y by factor(Z) (0, 1)
Z = -4.9, p-value <0.001
alternative hypothesis: true mu is not equal to 0
\end{verbatim}

The ri2 package \citep{R-ri2}:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# using the ri2 package}
\NormalTok{thedesign1 }\OtherTok{\textless{}{-}}\NormalTok{ randomizr}\SpecialCharTok{:::}\FunctionTok{declare\_ra}\NormalTok{(}\AttributeTok{N =}\NormalTok{ ndat1, }\AttributeTok{m =} \FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Z))}
\NormalTok{thedesign1}
\NormalTok{test1riT }\OtherTok{\textless{}{-}} \FunctionTok{conduct\_ri}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z,}
  \AttributeTok{declaration =}\NormalTok{ thedesign1,}
  \AttributeTok{sharp\_hypothesis =} \DecValTok{0}\NormalTok{, }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{sims =} \DecValTok{1000}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(test1riT)}
\NormalTok{test1riR }\OtherTok{\textless{}{-}} \FunctionTok{conduct\_ri}\NormalTok{(rankY }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z,}
  \AttributeTok{declaration =}\NormalTok{ thedesign1,}
  \AttributeTok{sharp\_hypothesis =} \DecValTok{0}\NormalTok{, }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{sims =} \DecValTok{1000}
\NormalTok{)}
\FunctionTok{summary}\NormalTok{(test1riR)}
\end{Highlighting}
\end{Shaded}

\hypertarget{binary-outcomes}{%
\subsubsection{Binary outcomes}\label{binary-outcomes}}

We tend to focus on differences in proportions when we are working with
binary outcomes. A statement such as ``The effect was 5 percentage
points.'' has tended to make communication with our policy partners
easier than a discussion in terms of log odds or odds ratios or
probabilities. Our tests of the hypothesis of no difference tend to
change in the case of binary outcomes, however, in order to increase
statistical power. In addition to the problem of interpretation and
communication, we also avoid logistic regression coefficients because of
the bias problem noticed by \citet{freedman2008randomization} in the
case of covariance adjustment or more complicated research designs. See
our memo on \texttt{binary\_outcomes.Rmd} for some simulation studies
showing the code and explaining more of the reasoning behind Freedman's
results.

\hypertarget{estimating-the-average-treatment-effect-and-testing-the-weak-null-of-no-average-effects-1}{%
\paragraph{Estimating the average treatment effect and testing the weak
null of no average
effects}\label{estimating-the-average-treatment-effect-and-testing-the-weak-null-of-no-average-effects-1}}

In our standard practice, we can estimate effects and produce standard
errors for differences of proportions using the same process as above.
The estimate is an estimate of the difference in proportions of positive
responses between the treatment conditions. The standard error is valid
because it is based on the design of the study and not the distribution
of the outcomes.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Make some binary outcomes}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{u }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(ndat1)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{v }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(ndat1)}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{y0bin }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{u }\SpecialCharTok{\textgreater{}}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{) }\CommentTok{\# potential outcomes}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{y1bin }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{((dat1}\SpecialCharTok{$}\NormalTok{u }\SpecialCharTok{+}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{v) }\SpecialCharTok{\textgreater{}}\NormalTok{ .}\DecValTok{75}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{) }\CommentTok{\# potential outcomes}
\NormalTok{dat1}\SpecialCharTok{$}\NormalTok{Ybin }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, Z }\SpecialCharTok{*}\NormalTok{ y1bin }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Z) }\SpecialCharTok{*}\NormalTok{ y0bin)}
\NormalTok{truePropDiff }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{y1bin) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{y0bin)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE2 }\OtherTok{\textless{}{-}} \FunctionTok{difference\_in\_means}\NormalTok{(Ybin }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat1)}
\FunctionTok{print}\NormalTok{(estAndSE2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Design:  Standard 
  Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper    DF
Z   0.1733     0.1084   1.599   0.1168 -0.04503   0.3917 44.65
\end{verbatim}

When we have an experiment that includes treatment and control with
binary outcomes and we are estimating the ATE, the standard errors in
the difference in proportions test are the same as the standard errors
in a regular OLS regression, which are also the same as the Neyman
standard errors.

Difference of proportions standard errors are estimated with the
following equation:

\begin{equation}
\widehat{SE}_{prop} = \sqrt{\frac{p_{1}(1-p_{1})}{n_{1}}+\frac{p_{2}(1-p_{2})}{n_{2}}}
\end{equation}

where we can think of \(n_1\) as the size of the group assigned
treatment, \(n_2\) as the size of the group assigned control, \(p_1\) as
the proportion of ``successes'' in the group assigned treatment, and
\(p_2\) as the proportion of ``successes'' in the group assigned
control.

We can compare this with the Neyman standard errors equation, see
\citet{lin_agnostic_2013}:

\begin{equation}
\widehat{SE}_{Neyman} = \sqrt{\frac{VAR(Y_{t})}{n_1}+\frac{VAR(Y_{c})}{n_2}}
\end{equation}

where \(Y_c\) is outcomes under control and \(Y_t\) is outcomes under
treatment; we use the variance of each population to find the Neyman
standard error.

We can also compare both difference in proportions and Neyman standard
errors to OLS standard errors, written in matrix form:

\[ \widehat{SE}_{OLS} = \sqrt{VAR(\widehat{ATE})(X'X)^{-1}} \]

where \(VAR(\widehat{ATE})\) is the variance of the estimated ATE
coefficient and \((X'X)^{-1}\) is a scalar since X is a vector.

When no additional covariates and only binary outcomes are in the model,
all three versions produce the same standard errors, as depicted in the
code below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nt }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Z)}
\NormalTok{nc }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z)}

\DocumentationTok{\#\# 2. Find SE for difference of proportions.}
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Ybin[dat1}\SpecialCharTok{$}\NormalTok{Z }\SpecialCharTok{==} \DecValTok{1}\NormalTok{])}
\NormalTok{p0 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Ybin[dat1}\SpecialCharTok{$}\NormalTok{Z }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
\NormalTok{se1 }\OtherTok{\textless{}{-}}\NormalTok{ (p1 }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p1)) }\SpecialCharTok{/}\NormalTok{ nt}
\NormalTok{se0 }\OtherTok{\textless{}{-}}\NormalTok{ (p0 }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p0)) }\SpecialCharTok{/}\NormalTok{ nc}
\NormalTok{se\_prop }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(se1 }\SpecialCharTok{+}\NormalTok{ se0), }\DecValTok{4}\NormalTok{)}

\DocumentationTok{\#\# 3. Find Neyman SE}
\NormalTok{varc\_s }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Ybin[dat1}\SpecialCharTok{$}\NormalTok{Z }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
\NormalTok{vart\_s }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(dat1}\SpecialCharTok{$}\NormalTok{Ybin[dat1}\SpecialCharTok{$}\NormalTok{Z }\SpecialCharTok{==} \DecValTok{1}\NormalTok{])}
\NormalTok{se\_neyman }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{((vart\_s }\SpecialCharTok{/}\NormalTok{ nt) }\SpecialCharTok{+}\NormalTok{ (varc\_s }\SpecialCharTok{/}\NormalTok{ nc)), }\DecValTok{4}\NormalTok{)}

\DocumentationTok{\#\# 4. Find OLS SE}
\NormalTok{simpOLS }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Ybin }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, dat1)}
\NormalTok{se\_ols }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{coef}\NormalTok{(}\FunctionTok{summary}\NormalTok{(simpOLS))[}\StringTok{"Z"}\NormalTok{, }\StringTok{"Std. Error"}\NormalTok{], }\DecValTok{2}\NormalTok{)}

\DocumentationTok{\#\# 5. Find Neyman SE (which are the HC2 SEs)}
\NormalTok{se\_neyman2 }\OtherTok{\textless{}{-}} \FunctionTok{coeftest}\NormalTok{(simpOLS, }\AttributeTok{vcov =} \FunctionTok{vcovHC}\NormalTok{(simpOLS, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{))[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\NormalTok{se\_neyman3 }\OtherTok{\textless{}{-}}\NormalTok{ estAndSE2}\SpecialCharTok{$}\NormalTok{std.error}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 5. Show SEs}
\NormalTok{se\_compare }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(se\_prop, se\_neyman, se\_neyman2, se\_neyman3, se\_ols))}
\FunctionTok{rownames}\NormalTok{(se\_compare) }\OtherTok{\textless{}{-}} \StringTok{"SE(ATE)"}
\FunctionTok{colnames}\NormalTok{(se\_compare) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"diff in prop"}\NormalTok{, }\StringTok{"neyman"}\NormalTok{, }\StringTok{"neyman"}\NormalTok{, }\StringTok{"neyman"}\NormalTok{, }\StringTok{"ols"}\NormalTok{)}
\FunctionTok{print}\NormalTok{(se\_compare)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        diff in prop neyman neyman neyman  ols
SE(ATE)       0.1066 0.1084 0.1084 0.1084 0.11
\end{verbatim}

\hypertarget{testing-the-sharp-null-of-no-effects-1}{%
\paragraph{Testing the sharp null of no
effects}\label{testing-the-sharp-null-of-no-effects-1}}

In this case, with a binary treatment and a binary outcome, we can also
do a simple test of the hypothesis that outcomes are independent of
treatment assignment using Fisher's exact test and we can also use the
approaches above to produce results that do not rely on asymptotic
assumptions. Below we show how the Fisher's exact test, the Exact
Cochran-Mantel-Haenszel test, and the Exact \(\chi\)-squared test
produce the same answers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test2fisher }\OtherTok{\textless{}{-}} \FunctionTok{fisher.test}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Z, }\AttributeTok{y =}\NormalTok{ dat1}\SpecialCharTok{$}\NormalTok{Ybin)}
\FunctionTok{print}\NormalTok{(test2fisher)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Fisher's Exact Test for Count Data

data:  dat1$Z and dat1$Ybin
p-value = 0.2
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 0.7349 6.7377
sample estimates:
odds ratio 
     2.117 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test2chisq }\OtherTok{\textless{}{-}} \FunctionTok{chisq\_test}\NormalTok{(}\FunctionTok{factor}\NormalTok{(Ybin) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{distribution =} \FunctionTok{exact}\NormalTok{())}
\FunctionTok{print}\NormalTok{(test2chisq)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Exact Pearson Chi-Squared Test

data:  factor(Ybin) by factor(Z) (0, 1)
chi-squared = 2.3, p-value = 0.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test2cmh }\OtherTok{\textless{}{-}} \FunctionTok{cmh\_test}\NormalTok{(}\FunctionTok{factor}\NormalTok{(Ybin) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{distribution =} \FunctionTok{exact}\NormalTok{())}
\FunctionTok{print}\NormalTok{(test2cmh)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Exact Generalized Cochran-Mantel-Haenszel Test

data:  factor(Ybin) by factor(Z) (0, 1)
chi-squared = 2.3, p-value = 0.2
\end{verbatim}

Notice that a difference of proportions test can be done directly rather
than through least squares where the null hypothesis is tested using a
binomial distribution rather than a Normal distribution --- both
approximate the underlying randomization distribution well.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mat }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(Z, Ybin))}
\NormalTok{matpt }\OtherTok{\textless{}{-}} \FunctionTok{prop.test}\NormalTok{(mat[, }\DecValTok{2}\SpecialCharTok{:}\DecValTok{1}\NormalTok{])}
\NormalTok{matpt}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    2-sample test for equality of proportions with continuity correction

data:  mat[, 2:1]
X-squared = 1.7, df = 1, p-value = 0.2
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.40898  0.06231
sample estimates:
prop 1 prop 2 
0.5467 0.7200 
\end{verbatim}

\hypertarget{multiple-arms}{%
\subsection{Multiple arms}\label{multiple-arms}}

Multiple treatment arms can be analyzed as above, except that we tend to
have more than one comparison between a treated group and a control
group and so such studies raise both substantive and statistical
questions about multiple testing or multiple comparisons. For example,
the \texttt{difference\_in\_means} function asks which average treatment
effect it should estimate --- and it only presents one comparison at a
time: here we compare the treatment \texttt{T2} with the baseline
outcome of \texttt{T1}. We can compare arms 2--3 with arm 1, as in the
second set of results (\texttt{lm\_robust} implements the same standard
errors as \texttt{difference\_in\_means} but allows for more
flexibility).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE3 }\OtherTok{\textless{}{-}} \FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z4arms, }\AttributeTok{data =}\NormalTok{ dat1, }\AttributeTok{condition1 =} \StringTok{"T1"}\NormalTok{, }\AttributeTok{condition2 =} \StringTok{"T2"}\NormalTok{)}
\FunctionTok{print}\NormalTok{(estAndSE3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Design:  Standard 
         Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper    DF
Z4armsT2   0.2457      1.174  0.2092   0.8352   -2.118    2.609 46.35
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE3multarms }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z4arms, }\AttributeTok{data =}\NormalTok{ dat1)}
\FunctionTok{print}\NormalTok{(estAndSE3multarms)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF
(Intercept)   3.0158      0.748  4.0316 0.0001111    1.531    4.501 96
Z4armsT2      0.2457      1.174  0.2092 0.8347052   -2.086    2.577 96
Z4armsT3      0.1602      1.108  0.1446 0.8853288   -2.039    2.359 96
Z4armsT4      0.6972      1.271  0.5485 0.5846318   -1.826    3.220 96
\end{verbatim}

In this case, we could have \(((4 \times 4)-4)/2)=6\) tests. And if
there were really no effects, and we rejected the null at
\(\alpha=.05\), we would claim that there was at least one effect out of
six tests much more than 5\% of the time: \(1 - ( 1 - .05)^6 = .27\) or
27\% of the time we would make a false positive error, claiming an
effect existed when it did not.

In general, our analysis of studies with multiple arms should reflect
the fact that we are making multiple comparisons for two reasons. First,
the family-wise error rate of these tests will differ from the
individual error rate of single test. In short, testing more than one
hypothesis increases the chance of making a Type I error (i.e.,
incorrectly rejecting a true null hypothesis). Suppose instead of
testing a single hypothesis at a conventional significance level of
\(\alpha = 0.05\) we tested two hypothesis at \(\alpha = 0.05\). The
probability of retaining both hypotheses is \((1-\alpha)^2 = .9025\) and
the probability of rejecting at least one of these hypotheses is
\(1-(1-\alpha)^2 = .0975\) --- almost double our stated significance
threshold of \(\alpha = 0.05\).

Second, multiple tests will often be correlated and our tests should
recognize these relationships (which will penalize the multiple testing
less).\footnote{Imagine testing two hypotheses with \(\alpha = .05\) but
  the reference distributions of the tests were identical: we just by
  accident ran the same exact code twice. In that case, we are really
  just doing one test and so haven't changed our probability of
  rejecting a true null hypothesis for either test. If the two tests
  were correlated at .99, we would have changed this probability but
  only very slightly since both tests would basically still be the same.}

So, our standard practice in multi-arm trials is the following:

\begin{itemize}
\item
  First, decide on a focal comparison: say, control/status quo versus
  receiving any version of the treatment. This test has a lot of
  statistical power and would have a controlled false positive rate.
\item
  Next, either do the rest of the comparisons as exploration for future
  studies --- to give hints about where we might be seeing more or less
  of an effect OR do a second series of comparisons but adjusting for
  the collective false positive rate (i.e.~adjusting the Family Wise
  Error Rate --- see more later on when we might use FDR versus FWER).
  We will often use the Tukey HSD procedure for pairwise comparisons in
  this case \emph{or} test the hypotheses in a particular order to
  preserve statistical power (\citet{rosenbaum2008a}).
\end{itemize}

\hypertarget{adjusting-p-values-and-confidence-intervals-for-multiple-comparisons-using-tukey-hsd-in-r}{%
\subsubsection{Adjusting p-values and confidence intervals for multiple
comparisons using Tukey HSD in
R}\label{adjusting-p-values-and-confidence-intervals-for-multiple-comparisons-using-tukey-hsd-in-r}}

Here is an illustration of how we might adjust for multiple comparisons.

To reflect that fact that we are making multiple comparisons, we can
adjust \(p\)-values from our tests to control the familywise error rate
at \(\alpha\) through either a single step
(e.g.~\href{https://en.wikipedia.org/wiki/Bonferroni_correction}{Bonferroni
correction}) or stepwise procedure (such as the
\href{https://en.wikipedia.org/wiki/Holm\%E2\%80\%93Bonferroni_method}{Holm
correction} or the
\href{https://en.wikipedia.org/wiki/False_discovery_rate\#Benjamini.E2.80.93Hochberg_procedure}{Benjamini-Hochberg
correction}).

Our standard practice is to adjust FWER using the Holm adjustment.

For more on such adjustments and multiple comparisons see EGAP's
\href{http://egap.org/methods-guides/10-things-you-need-know-about-multiple-comparisons}{10
Things you need to know about multiple comparisons}.

\textbf{Explain here about what constitutes a family and how we choose.
Also why Holm. And when FDR.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Get p{-}values but exclude intercept}
\NormalTok{pvals }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(estAndSE3multarms)}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{]}
\FunctionTok{round}\NormalTok{(}\FunctionTok{p.adjust}\NormalTok{(pvals, }\StringTok{"none"}\NormalTok{), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z4armsT2 Z4armsT3 Z4armsT4 
   0.835    0.885    0.585 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{p.adjust}\NormalTok{(pvals, }\StringTok{"bonferroni"}\NormalTok{), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z4armsT2 Z4armsT3 Z4armsT4 
       1        1        1 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{p.adjust}\NormalTok{(pvals, }\StringTok{"holm"}\NormalTok{), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z4armsT2 Z4armsT3 Z4armsT4 
       1        1        1 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{p.adjust}\NormalTok{(pvals, }\StringTok{"hochberg"}\NormalTok{), }\DecValTok{3}\NormalTok{) }\DocumentationTok{\#\# The  FDR Correction}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Z4armsT2 Z4armsT3 Z4armsT4 
   0.885    0.885    0.885 
\end{verbatim}

Simply adjusting \(p\)-values from this linear model, however, ignores
the fact that we are likely interested in other pairwise comparisons,
such as the difference between simply receiving an email and receiving
an email with framing A (or framing B). It also ignores potential
correlations in the distribution of test statistics.

Below we demonstrate how to implement a Tukey Honest Signficant
Differences (HSD) test. The Tukey HSD test (sometimes called a Tukey
range test or just a Tuke test) calculates adjusted \(p\)-values and
simultaneous confidence intervals from a studentized range distribution
\emph{for all pairwise comparisons} in a model, taking into account the
correlation of test statistics.

The test statistic for any comparison between group \(i\) and \(j\):

\[ t_{ij} = \frac{\bar{y_i}-\bar{y_j}}{s\sqrt{\frac{2}{n}}} \]

Where, \(\bar{y_i}\) and \(\bar{y_j}\) are the means in groups \(i\) and
\(j\), respectively, \(s\) is the pooled standard deviation and \(n\) is
the common sample size.

The confidence interval for any difference is simply:

\[ \left[
     \bar{y_i}-\bar{y_j}-u_{1-\alpha}s\sqrt{\frac{2}{n}};\bar{y_i}-\bar{y_j}+u_{1-\alpha}s\sqrt{\frac{2}{n}}\right]
\]

Where \(u_{1-\alpha}\) denotes the \((1-\alpha)\)-quantile of the
multivariate \(t\)-distribution.

We present an implementation of the Tukey HSD test using the
\texttt{glht()} function from the \texttt{multcomp} package which offers
more flexiblity than the \texttt{TukeyHSD} in the base \texttt{stats}
package at the price of a slightly more complicated syntax.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# We can use aov() or lm()}
\DocumentationTok{\#\# aovmod \textless{}{-} aov(Y\textasciitilde{}Z4arms, dat1)}
\NormalTok{lmmod }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z4arms, dat1)}
\end{Highlighting}
\end{Shaded}

Using the \texttt{glht()} function's \texttt{linfcnt} argument, we tell
the function to conduct a Tukey test of all pairwise comparisons for our
treatment indicator, \(Z\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tukey\_mc }\OtherTok{\textless{}{-}} \FunctionTok{glht}\NormalTok{(lmmod, }\AttributeTok{linfct =} \FunctionTok{mcp}\NormalTok{(}\AttributeTok{Z4arms =} \StringTok{"Tukey"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(tukey\_mc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

     Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lm(formula = Y ~ Z4arms, data = dat1)

Linear Hypotheses:
             Estimate Std. Error t value Pr(>|t|)
T2 - T1 == 0   0.2457     1.2456    0.20     1.00
T3 - T1 == 0   0.1602     1.2456    0.13     1.00
T4 - T1 == 0   0.6972     1.2456    0.56     0.94
T3 - T2 == 0  -0.0856     1.2456   -0.07     1.00
T4 - T2 == 0   0.4515     1.2456    0.36     0.98
T4 - T3 == 0   0.5370     1.2456    0.43     0.97
(Adjusted p values reported -- single-step method)
\end{verbatim}

We can plot the 95-percent family wise confidence intervals from these
comparisons

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Save dfault ploting parameters}
\NormalTok{op }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{()}
\CommentTok{\# Add space to lefthand outer margin}
\FunctionTok{par}\NormalTok{(}\AttributeTok{oma =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(tukey\_mc)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/tukeyplot-1}

And also obtain simultaneous confidence intervals at other levels of
statistical significance using \texttt{confint()} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tukey\_mc\_90ci }\OtherTok{\textless{}{-}} \FunctionTok{confint}\NormalTok{(tukey\_mc, }\AttributeTok{level =}\NormalTok{ .}\DecValTok{90}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(tukey\_mc\_90ci)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/plot_tukey_ci-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Restore plotting defaults}
\DocumentationTok{\#\# par(op)}
\end{Highlighting}
\end{Shaded}

See also: \texttt{pairwise.prop.test} for binary outcomes.

\hypertarget{multiple-outcomes}{%
\subsection{Multiple Outcomes}\label{multiple-outcomes}}

Some times our studies involve more than one outcome. Assessing the
effect of even a simple two-arm treatment on 10 different outcomes
raises the same kinds of questions that come up in the context of
multi-arm trials.

\hypertarget{covariance-adjustment-the-use-of-background-information-to-increase-precision}{%
\section{Covariance Adjustment (the use of background information to
increase
precision)}\label{covariance-adjustment-the-use-of-background-information-to-increase-precision}}

When we have background or baseline information about experimental
units, we can use this to increase the precision with which we estimate
our treatment effects (or, equivalently, increase the statistical power
of our tests). We prefer to use this information during the design phase
to create block randomized designs, but we sometimes have access to such
background information after the study has been fielded, and so we will
pre-specify use of this information to increase our statistical power.

We tend to avoid the practice of adjusting for the covariates in a
linear and additive fashion because of this estimator of the average
treatment effect is biased \citep{freedman2008rae} whereas a version of
the estimator that we call the ``Lin estimator'' is not
\citep{lin_agnostic_2013}. Note that the bias in the commonly used
linear covariance adjustment estimator tends to be quite small, and
especially small when sample sizes are large \citep{lin_agnostic_2013}.
Yet, because it is basically costless to use the Lin estimator, this is
our standard practice (see also
\url{https://declaredesign.org/blog/2018-09-11-controlling-pretreatment-covariates.html})

\hypertarget{intuition-about-bias-in-the-least-squares-estimator-of-the-ate-with-covariates}{%
\subsection{Intuition about bias in the least squares estimator of the
ATE with
covariates}\label{intuition-about-bias-in-the-least-squares-estimator-of-the-ate-with-covariates}}

When we estimate the average treatment effect by using a least squares
we tend to say that we ``regress'' some outcome for each unit \(i\),
\(Y_i\), on (often binary) treatment assignment, \(Z_i\), where
\(Z_i=1\) if a unit is assigned to treatment and 0 if assigned to
control. And we write a linear model relating \(Z\) and \(Y\) as below,
where \(\beta_1\) represents the difference in means of \(Y\) between
units with \(Z=1\) and \(Z=0\):

\begin{equation}
Y_i = \beta_0 + \beta_1 Z_i + e_i \label{eq:olsbiv}
\end{equation}

This is a common practice because, we know that the formula to estimate
\(\beta_1\) in equation \eqref{eq:olsbiv} is the same as the difference of
means in \(Y\) between treatment and control groups:

\begin{equation}
\hat{\beta}_1 = \overline{Y|Z=1} - \overline{Y|Z=0} = \frac{cov(Y,Z)}{var(Z)}.
\end{equation}

This last term, expressed with covariances and variances, is the
expression for the least squares coefficient in a bivariate linear least
squares model. And we also know that this estimator of the average
treatment effect has no systematic error (i.e.~is unbiased), so we can
write \(E_R(\hat{\beta}_1)=\beta_1 \equiv \text{ATE}\) where we take the
expectation across randomizations consistent with the experimental
design.

Now, sometimes we have a covariate \(X_i\) and we use it as would be
common in the analysis of non-experimental data:

\begin{equation}
Y_i = \beta_0 + \beta_1 Z_i + \beta_2 X_i + e_i \label{eq:olscov}
\end{equation}

What is \(\beta_1\) in this case? We know the matrix representation here
\((\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\mathbf{y}\), but here is
the scalar formula for this particular case in \eqref{eq:olsbiv}:

\[ \hat{\beta}_1 = \frac{\mathrm{Var}(X)\mathrm{Cov}(Z,Y) - \mathrm{Cov}(X,Z)\mathrm{Cov}(X,Y)}{\mathrm{Var}(Z)\mathrm{Var}(X) - \mathrm{Cov}(Z,X)^2} \]

In very large experiments \(\mathrm{Cov}(X,Z) \approx 0\) --- because
\(Z\) is randomly assigned and is thus independent of background
variables like \(X\) --- however in any given finite sized experiment
\(cov(X,Z) \ne 0\) so this does not reduce to the unbiased estimator of
the bivariate case. Thus, \citet{freedman2008rae} showed that there is a
small amount of bias in using equation \eqref{eq:olscov} to estimate the
average treatment effect.

As a way to engage with this problem, \citet{lin_agnostic_2013}
suggested using the following least squares approach --- regressing the
outcome on binary treatment assignment \(Z_i\) and its interaction with
mean-centered covariates.

\begin{equation}
Y_i = \beta_0 + \beta_1 Z_i + \beta_2 ( X_i  -  \bar{X} ) + \beta_3 Z_i (X_i - \bar{X}) +  e_i\label{eq:olscov} 
\end{equation}

See the
\href{https://alexandercoppock.com/Green-Lab-SOP/Green_Lab_SOP.html\#using-covariates-in-analysis}{Green-Lin-Coppock
SOP} for more examples of this approach to covariance adjustment.

\hypertarget{the-lin-approach-to-covariance-adjustment}{%
\subsection{The Lin Approach to Covariance
Adjustment}\label{the-lin-approach-to-covariance-adjustment}}

Here we show how covariance adjustment can create bias in estimation of
the average treatment effect --- and how to reduce this bias while using
the Lin procedure as well as by increasing the size of the experiment.
In this case, we compare an experiment with 20 units to an experiement
with 100 units, in each case with half of the units assigned to
treatment by complete random assignment.

We use the \href{https://declaredesign.org/}{DeclareDesign} package for
R to make this process of assessing bias easier. So, much of the code
that follows provides input to the \texttt{diagnose\_design} command
which repeats the design of the experiment many times, each time
estimating an average treatment effect, and comparing the mean of those
estimate to the truth (labeled ``Mean Estimand'' below).

The true potential outcomes (\texttt{y1} and \texttt{y0}) are generated
using one covariate, called \texttt{cov2}. In what follows we compare
the performance of the simple estimator using OLS, to estimators that
use Lin's procedure involving just the correct covariate, to estimators
that use incorrect covariates (since we rarely know exactly the
covariates that help generate any given behavioral outcome).

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# summary(lm(y0\textasciitilde{}cov2,data=dat1))$r.squared}
\DocumentationTok{\#\# summary(lm(y1\textasciitilde{}cov2,data=dat1))$r.squared}

\NormalTok{wrkdat1 }\OtherTok{\textless{}{-}}\NormalTok{ dat1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(id, y1, y0, }\FunctionTok{contains}\NormalTok{(}\StringTok{"cov"}\NormalTok{))}
\NormalTok{popbigdat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(wrkdat1)}

\DocumentationTok{\#\# Make a small dataset to represent a small experiment or a cluster randomized experiment with few clusters}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{smalldat1 }\OtherTok{\textless{}{-}}\NormalTok{ dat1 }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(id, y1, y0, }\FunctionTok{contains}\NormalTok{(}\StringTok{"cov"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{sample\_n}\NormalTok{(}\DecValTok{20}\NormalTok{)}
\DocumentationTok{\#\# The relevant covariate is a reasonably strong predictor of the outcome}
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(y0 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ cov2, }\AttributeTok{data =}\NormalTok{ smalldat1))}\SpecialCharTok{$}\NormalTok{r.squared}

\DocumentationTok{\#\#\# Now declare the differeent inputs for DeclareDesign}
\NormalTok{popsmalldat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(smalldat1)}

\NormalTok{assignsmalldat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Znew =} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m =} \DecValTok{10}\NormalTok{))}
\NormalTok{assignbigdat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Znew =} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m =} \DecValTok{50}\NormalTok{))}

\DocumentationTok{\#\# No additional treatment effects other than those created when we made y0 and y1 earlier}
\NormalTok{po\_functionNull }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y\_Znew\_0 }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{y0}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y\_Znew\_1 }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{y1}
\NormalTok{  data}
\NormalTok{\}}

\NormalTok{ysdat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_potential\_outcomes}\NormalTok{(}\AttributeTok{handler =}\NormalTok{ po\_functionNull)}
\NormalTok{theestimanddat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Znew\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Znew\_0))}
\NormalTok{theobsidentdat1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_reveal}\NormalTok{(Y, Znew)}

\NormalTok{thedesignsmalldat1 }\OtherTok{\textless{}{-}}\NormalTok{ popsmalldat1 }\SpecialCharTok{+}\NormalTok{ assignsmalldat1 }\SpecialCharTok{+}\NormalTok{ ysdat1 }\SpecialCharTok{+}\NormalTok{ theestimanddat1 }\SpecialCharTok{+}
\NormalTok{  theobsidentdat1}

\NormalTok{thedesignbigdat1 }\OtherTok{\textless{}{-}}\NormalTok{ popbigdat1 }\SpecialCharTok{+}\NormalTok{ assignbigdat1 }\SpecialCharTok{+}\NormalTok{ ysdat1 }\SpecialCharTok{+}\NormalTok{ theestimanddat1 }\SpecialCharTok{+}
\NormalTok{  theobsidentdat1}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estCov0 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew, }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"CovAdj0: Lm, No covariates"}\NormalTok{)}
\NormalTok{estCov1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew }\SpecialCharTok{+}\NormalTok{ cov2, }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"CovAdj1: Lm,Correct Covariate"}\NormalTok{)}
\NormalTok{estCov2 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew }\SpecialCharTok{+}\NormalTok{ cov1 }\SpecialCharTok{+}\NormalTok{ cov2 }\SpecialCharTok{+}\NormalTok{ cov3 }\SpecialCharTok{+}\NormalTok{ cov4 }\SpecialCharTok{+}\NormalTok{ cov5 }\SpecialCharTok{+}\NormalTok{ cov6 }\SpecialCharTok{+}\NormalTok{ cov7 }\SpecialCharTok{+}\NormalTok{ cov8, }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"CovAdj2: Lm,  Mixed Covariates"}\NormalTok{)}
\NormalTok{estCov3 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew }\SpecialCharTok{+}\NormalTok{ cov1 }\SpecialCharTok{+}\NormalTok{ cov3 }\SpecialCharTok{+}\NormalTok{ cov4 }\SpecialCharTok{+}\NormalTok{ cov5 }\SpecialCharTok{+}\NormalTok{ cov6, }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"CovAdj3: Lm, Wrong Covariates"}\NormalTok{)}
\NormalTok{estCov4 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew, }\AttributeTok{covariates =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ cov1 }\SpecialCharTok{+}\NormalTok{ cov2 }\SpecialCharTok{+}\NormalTok{ cov3 }\SpecialCharTok{+}\NormalTok{ cov4 }\SpecialCharTok{+}\NormalTok{ cov5 }\SpecialCharTok{+}\NormalTok{ cov6 }\SpecialCharTok{+}\NormalTok{ cov7 }\SpecialCharTok{+}\NormalTok{ cov8, }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{model =}\NormalTok{ lm\_lin, }\AttributeTok{label =} \StringTok{"CovAdj4: Lin, Mixed Covariates"}\NormalTok{)}
\NormalTok{estCov5 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew, }\AttributeTok{covariates =} \SpecialCharTok{\textasciitilde{}}\NormalTok{cov2, }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{model =}\NormalTok{ lm\_lin, }\AttributeTok{label =} \StringTok{"CovAdj5: Lin, Correct Covariate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{thedesignsmalldat1PlusEstimators }\OtherTok{\textless{}{-}}\NormalTok{ thedesignsmalldat1 }\SpecialCharTok{+}\NormalTok{ estCov0 }\SpecialCharTok{+}\NormalTok{ estCov1 }\SpecialCharTok{+}\NormalTok{ estCov2 }\SpecialCharTok{+}
\NormalTok{  estCov3 }\SpecialCharTok{+}\NormalTok{ estCov4 }\SpecialCharTok{+}\NormalTok{ estCov5}

\NormalTok{thedesignbigdat1PlusEstimators }\OtherTok{\textless{}{-}}\NormalTok{ thedesignbigdat1 }\SpecialCharTok{+}\NormalTok{ estCov0 }\SpecialCharTok{+}\NormalTok{ estCov1 }\SpecialCharTok{+}\NormalTok{ estCov2 }\SpecialCharTok{+}
\NormalTok{  estCov3 }\SpecialCharTok{+}\NormalTok{ estCov4 }\SpecialCharTok{+}\NormalTok{ estCov5}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims }\OtherTok{\textless{}{-}} \DecValTok{200}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{thediagnosisCovAdj1 }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignsmalldat1PlusEstimators, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\NormalTok{thediagnosisCovAdj1}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{thediagnosisCovAdj2 }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignbigdat1PlusEstimators, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\NormalTok{thediagnosisCovAdj2}
\end{Highlighting}
\end{Shaded}

After 1000 simulations using the small experiment (N=20) we can see that
the ``CovAdj1: Lm, Correct Covariate'' lines show fairly large bias
compared to the estimator using no covariates at all. The Lin approach
using only the known to be correct covariate reduces the bias, but does
not erase it. However, the unadjusted estimator has fairly low power
where as the Lin approach with the correct covariate ``CovAdj5: Lin,
Correct Covariate'' has excellent power to detect the 1 SD effect built
into this experiment. One interesting result here is that the Lin
approach is worst (in power and even false positive rate (called
``Coverage'' below) when a mixture or correct and incorrect covariates
are added to the linear model following the interaction-and-centering
based approach.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagcols }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{11}\NormalTok{)}
\DocumentationTok{\#\# See https://haozhu233.github.io/kableExtra/awesome\_table\_in\_html.html}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisCovAdj1)[, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "400px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l}
\hline
Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
CovAdj0: Lm, No covariates & Znew & 5.03 & 5.08 & 0.05 & 1.78 & 1.78 & 0.65\\
\hline
CovAdj1: Lm,Correct Covariate & Znew & 5.03 & 5.32 & 0.29 & 1.08 & 1.11 & 0.98\\
\hline
CovAdj2: Lm,  Mixed Covariates & Znew & 5.03 & 5.12 & 0.09 & 1.39 & 1.39 & 0.89\\
\hline
CovAdj3: Lm, Wrong Covariates & Znew & 5.03 & 5.21 & 0.18 & 1.64 & 1.65 & 0.78\\
\hline
CovAdj4: Lin, Mixed Covariates & Znew & 5.03 & 4.58 & -0.45 & 8.07 & 8.06 & 0.35\\
\hline
CovAdj5: Lin, Correct Covariate & Znew & 5.03 & 5.13 & 0.10 & 1.05 & 1.05 & 1.00\\
\hline
\end{tabular}

The experiment with \(N=100\) shows much smaller bias than the small
experiment above. Since all estimators allow us to detect the 1 SD
effect (Power=1), the RMSE (Root Mean Squared Error) column or ``Mean
Se'' columns tell us about the precision of the estimators. Again, the
unadjusted approach has low bias, but has the largest standard error.
While the Lin approach with a mixture of correct and incorrect
covariates has low bias, it shows slightly worse coverage (or false
positive error rate) even it has most precision.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# See https://haozhu233.github.io/kableExtra/awesome\_table\_in\_html.html}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisCovAdj2)[, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "400px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l}
\hline
Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
CovAdj0: Lm, No covariates & Znew & 5.45 & 5.45 & -0.01 & 0.76 & 0.76 & 1.00\\
\hline
CovAdj1: Lm,Correct Covariate & Znew & 5.45 & 5.47 & 0.02 & 0.50 & 0.50 & 1.00\\
\hline
CovAdj2: Lm,  Mixed Covariates & Znew & 5.45 & 5.48 & 0.03 & 0.53 & 0.53 & 1.00\\
\hline
CovAdj3: Lm, Wrong Covariates & Znew & 5.45 & 5.44 & -0.01 & 0.63 & 0.63 & 1.00\\
\hline
CovAdj4: Lin, Mixed Covariates & Znew & 5.45 & 5.47 & 0.02 & 0.53 & 0.53 & 1.00\\
\hline
CovAdj5: Lin, Correct Covariate & Znew & 5.45 & 5.47 & 0.01 & 0.50 & 0.50 & 1.00\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simdesignsCovAdj1 }\OtherTok{\textless{}{-}} \FunctionTok{get\_simulations}\NormalTok{(thediagnosisCovAdj1)}
\NormalTok{trueATE1covadj }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{mean}\NormalTok{(y1 }\SpecialCharTok{{-}}\NormalTok{ y0))}

\DocumentationTok{\#\# simdesigns \textless{}{-} simulate\_design(thedesign,sims=sims)}
\NormalTok{simmeansCovAdj1 }\OtherTok{\textless{}{-}}\NormalTok{ simdesignsCovAdj1 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(estimator) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{expest =} \FunctionTok{mean}\NormalTok{(estimate))}
\end{Highlighting}
\end{Shaded}

Although the Lin approach works well when covariates are few and sample
sizes are large, these simulations show where the approach is weak: when
covariates are many. In this case the estimator involving both correct
and irrelevant covariates used 18 terms. Fitting a model with 18 terms
with N=20 allows nearly any observation to exert undue influence,
increases the risk of serious multicollinearity, and leads to
overfitting problems in general.

So far, our team has not run into this problem because our studies have
tended to involve many thousands of units and relatively few covariates.
However, we are considering a few alternative approaches should we
confront this situation in the future such as (1) collapsing the
covariates into fewer dimensions (using a Mahalanobis distance or
principal components based distance) or working with a residualized
version of the outcome as described below.

\hypertarget{the-rosenbaum-approach-the-covariance-adjustment}{%
\subsection{The Rosenbaum Approach The Covariance
Adjustment}\label{the-rosenbaum-approach-the-covariance-adjustment}}

When we have many covariates, sometimes the Lin style approach prevents
us from calculating appropriate standard errors and/or can have inflated
bias due to overfitting. \citet{rosenbaum:2002a} showed an approach in
which the outcomes are regressed on covariates, ignoring treatment
assignment, and then the residuals from that regression are used to
estimate an average treatment effect.

We do a similar evaluation of that approach here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{make\_est\_fun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(covs) \{}
  \DocumentationTok{\#\# covs is a vector of character names of covariates}
  \FunctionTok{force}\NormalTok{(covs)}
\NormalTok{  covfmla }\OtherTok{\textless{}{-}} \FunctionTok{reformulate}\NormalTok{(covs, }\AttributeTok{response =} \StringTok{"Y"}\NormalTok{)}
  \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{    data}\SpecialCharTok{$}\NormalTok{e\_y }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(}\FunctionTok{lm}\NormalTok{(covfmla, }\AttributeTok{data =}\NormalTok{ data))}
\NormalTok{    obj }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(e\_y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Znew, }\AttributeTok{data =}\NormalTok{ data)}
\NormalTok{    res }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(obj) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{==} \StringTok{"Znew"}\NormalTok{)}
    \FunctionTok{return}\NormalTok{(res)}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{est\_fun\_correct }\OtherTok{\textless{}{-}} \FunctionTok{make\_est\_fun}\NormalTok{(}\StringTok{"cov2"}\NormalTok{)}
\NormalTok{est\_fun\_mixed }\OtherTok{\textless{}{-}} \FunctionTok{make\_est\_fun}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"cov1"}\NormalTok{, }\StringTok{"cov2"}\NormalTok{, }\StringTok{"cov3"}\NormalTok{, }\StringTok{"cov4"}\NormalTok{, }\StringTok{"cov5"}\NormalTok{, }\StringTok{"cov6"}\NormalTok{, }\StringTok{"cov7"}\NormalTok{, }\StringTok{"cov8"}\NormalTok{))}
\NormalTok{est\_fun\_incorrect }\OtherTok{\textless{}{-}} \FunctionTok{make\_est\_fun}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"cov1"}\NormalTok{, }\StringTok{"cov2"}\NormalTok{, }\StringTok{"cov3"}\NormalTok{, }\StringTok{"cov4"}\NormalTok{, }\StringTok{"cov5"}\NormalTok{, }\StringTok{"cov6"}\NormalTok{))}

\DocumentationTok{\#\# est\_fun\_correct(blah)}

\NormalTok{estCov6 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(est\_fun\_correct), }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{label =} \StringTok{"CovAdj6: Resid, Correct"}\NormalTok{)}
\NormalTok{estCov7 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(est\_fun\_mixed), }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{label =} \StringTok{"CovAdj7: Resid, Mixed"}\NormalTok{)}
\NormalTok{estCov8 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(est\_fun\_incorrect), }\AttributeTok{inquiry =}\NormalTok{ theestimanddat1, }\AttributeTok{label =} \StringTok{"CovAdj8: Resid, InCorrect"}\NormalTok{)}

\NormalTok{thedesignsmalldat1PlusRoseEstimators }\OtherTok{\textless{}{-}}\NormalTok{ thedesignsmalldat1 }\SpecialCharTok{+}\NormalTok{ estCov0 }\SpecialCharTok{+}\NormalTok{ estCov1 }\SpecialCharTok{+}\NormalTok{ estCov2 }\SpecialCharTok{+}
\NormalTok{  estCov3 }\SpecialCharTok{+}\NormalTok{ estCov4 }\SpecialCharTok{+}\NormalTok{ estCov5 }\SpecialCharTok{+}\NormalTok{ estCov6 }\SpecialCharTok{+}\NormalTok{ estCov7 }\SpecialCharTok{+}\NormalTok{ estCov8}

\NormalTok{thedesignbigdat1PlusRoseEstimators }\OtherTok{\textless{}{-}}\NormalTok{ thedesignbigdat1 }\SpecialCharTok{+}\NormalTok{ estCov0 }\SpecialCharTok{+}\NormalTok{ estCov1 }\SpecialCharTok{+}\NormalTok{ estCov2 }\SpecialCharTok{+}
\NormalTok{  estCov3 }\SpecialCharTok{+}\NormalTok{ estCov4 }\SpecialCharTok{+}\NormalTok{ estCov5 }\SpecialCharTok{+}\NormalTok{ estCov6 }\SpecialCharTok{+}\NormalTok{ estCov7 }\SpecialCharTok{+}\NormalTok{ estCov8}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{thediagnosisCovAdj3 }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignsmalldat1PlusRoseEstimators, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\NormalTok{thediagnosisCovAdj3}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{thediagnosisCovAdj4 }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignbigdat1PlusRoseEstimators, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\NormalTok{thediagnosisCovAdj3}
\end{Highlighting}
\end{Shaded}

With a small sample (N=20), the Rosenbaum-style approach yields very
little bias and quite high power using the correct covariate (``CovAdj6:
Resid, Correct''), but poor performance in terms of bias and coverage
with incorrect covariates --- recall that coverage here uses the t-test
that in turn relies on asymptotic approximations, and we are challenging
this approximation with a small experiment and overfitting problems.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# See https://haozhu233.github.io/kableExtra/awesome\_table\_in\_html.html}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisCovAdj3)[}\DecValTok{7}\SpecialCharTok{:}\DecValTok{9}\NormalTok{, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "400px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l}
\hline
  & Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
7 & CovAdj6: Resid, Correct & Znew & 5.03 & 5.00 & -0.03 & 1.02 & 1.02 & 1.00\\
\hline
8 & CovAdj7: Resid, Mixed & Znew & 5.03 & 2.95 & -2.08 & 1.11 & 2.35 & 0.81\\
\hline
9 & CovAdj8: Resid, InCorrect & Znew & 5.03 & 3.53 & -1.50 & 1.20 & 1.92 & 0.85\\
\hline
\end{tabular}

With a larger experiment, the bias goes down, but coverage is poor with
incorrect covariates in this approach as well. We speculate that
performance might improve if we fit the covariance adjustment models
that produce residuals separately for the treated and control groups.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# See https://haozhu233.github.io/kableExtra/awesome\_table\_in\_html.html}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisCovAdj4)[}\DecValTok{7}\SpecialCharTok{:}\DecValTok{9}\NormalTok{, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "400px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l}
\hline
  & Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
7 & CovAdj6: Resid, Correct & Znew & 5.45 & 5.42 & -0.03 & 0.49 & 0.49 & 1.00\\
\hline
8 & CovAdj7: Resid, Mixed & Znew & 5.45 & 5.05 & -0.40 & 0.53 & 0.67 & 1.00\\
\hline
9 & CovAdj8: Resid, InCorrect & Znew & 5.45 & 5.14 & -0.31 & 0.52 & 0.61 & 1.00\\
\hline
\end{tabular}

\hypertarget{how-to-choose-covariates-for-covariance-adjustment}{%
\section{How to choose covariates for covariance
adjustment?}\label{how-to-choose-covariates-for-covariance-adjustment}}

Our analysis plans commonly specify a few covariates based on what we
know about the mechanisms and context of the study. In general, if we
have a measurement of the outcome \emph{before the treatment was
assigned}, the baseline outcome, we try to use it via blocking and/or
via covariance adjustment.

When we have access to many covariates, we sometimes use simple machine
learning methods to select variables that strongly predict the outcome.

\hypertarget{example-of-using-the-adaptive-lasso-for-variable-selection}{%
\subsubsection{Example of using the adaptive lasso for variable
selection}\label{example-of-using-the-adaptive-lasso-for-variable-selection}}

Here we show how we use baseline data, data collected before the
treatment was assigned or new policy implemented, to choose covariates
that we then use as we have described above.

We tend to use the adaptive lasso rather than the simple lasso because
the adaptive lasso has better theoretical properties (insert citation to
Zhou) but also because the adaptive lasso tends to produce sparser
results --- and the bias from covariance adjustment can be severe if we
add many many covariates to a covriance adjustment procedure.

\textbf{TO DO}

\hypertarget{blockrandanalysis}{%
\section{Block-randomized trials}\label{blockrandanalysis}}

We design block-randomized trials by splitting units into groups based
on predefined characteristics --- covariates that cannot be changed by
the experimental treatment --- and then randomly assigning treatment
within each group. We use this procedure when we want to increase our
ability to detect signal from noise and we think that the noise, or
variation in the outcome of the experiment, is driven in part by the
covariates that we use for blocking. For example, if we imagine the
patterns of energy use will tend to differ according to size of family,
we may create blocks or strata of different family sizes and randomly
assign an energy saving intervention separately within those blocks. We
also design block-randomized experiments when we want to assess effects
within and across subgroups (for example, if we want to ensure that we
have enough statistical power to detect a \emph{difference in effects}
between veterans and non-veterans). If we have complete random
assignment, it is likely that the proportion of veterans assigned
treatment will not be exactly same as the proportion of non-veterans
receiving treatment. However, if we stratify or block the group on
military status, and randomly assign treatment and control within each
group, we can then ensure that equal proportions (or numbers) or
veterans and non-veterans receive the treatment and control.

Most of the general ideas that we demonstrated in the context of
completely randomized trials have direct analogues in the case of block
randomized trials. The only additional question that arises with block
randomized trials is about how to weight the contributions of each
individual block when calculating an overall average treatment effect or
testing an overall hypothesis about treatment effects.

We begin here with the simple case of testing the sharp null of no
effects when we have a binary outcome --- in the case of the
Cochran-Mantel-Haenszel test the weighting of the different blocks is
automatic.

\hypertarget{testing-the-null-of-no-effects-with-binary-outcomes-and-block-randomization-cochran-mantel-haenszel-cmh-test-for-k-x-2-x-2-tables}{%
\subsection{Testing the null of no effects with binary outcomes and
block randomization: Cochran-Mantel-Haenszel (CMH) test for K X 2 X 2
tables}\label{testing-the-null-of-no-effects-with-binary-outcomes-and-block-randomization-cochran-mantel-haenszel-cmh-test-for-k-x-2-x-2-tables}}

We use the CMH test as a test of no effect for block-randomized trials
with binary outcome.\footnote{Binary outcomes implies that there are
  only two outcomes for an experiment, and we have recorded one or the
  other. Usually, we use indicator variables (0, 1) to record these
  outcomes.} Because the blocks or strata are important to the
experiment and outcomes, we want to keep the outcomes for each strata
intact rather than pooling the outcomes together. Since we repeat the
same experiment across each stratum, the CMH test tells us if the odds
ratio in the experiments indicate that there is an association between
outcomes and treatment/control across strata
\citep{cochran_methods_1954, mantel_statistical_1959}.

To set up the CMH test, we need \emph{k} sets of 2x2 contingency tables.
Suppose the table below represents outcomes from stratum \emph{i} where
A,B,C, and D are counts of observations:

\begin{longtable}[]{@{}llll@{}}
\toprule()
Assignment & Response & No response & Total \\
\midrule()
\endhead
Treatment & A & B & A+B \\
Control & C & D & C+D \\
Total & A+C & B+D & A+B+C+D = T \\
\bottomrule()
\end{longtable}

The CMH test statistic compares the sum of squared deviation between
observed and expected outcomes of an experiment within one stratum to
the variance of those outcomes, conditional on marginal totals.

\[CMH = \frac{\sum_{i=1}^{k} (A_{i} -
\mathrm{E}[{A_{i}}])}{\sum{\mathrm{VAR}[{A_i}]}}\]

where \[\mathrm{E}[A_{i}] =  \frac{(A_i+B_i)(A_i+C_i)}{T_i}\]

and \[\mathrm{VAR}[A_{i}] =
\frac{(A_i+B_i)(A_i+C_i)(B_i+D_i)(C_i+D_i)}{{T_i}^2(T_i-1)}\]

In large enough samples, if there are no associations between Treatment
and Reponse across strata, we would expect to see an odds ratio which is
equal to 1, and, across randomizations and in large samples, this test
statistic would have an asymptotic \(\chi^2\) distribution with degrees
of freedom = 1.

The odds ratio in this scenario is the combined weighted odds ratio of
each two-armed trial with binary outcomes within one block or stratum.

The odds ratio for a given stratum is

\[ OR = \frac{\frac{A}{B}}{\frac{C}{D}} = \frac{AD}{BC}\]

With many strata, we can find a common odds ratio

\begin{equation}
 OR_{CMH} = \frac{\sum_{i=1}^{k} \frac{A_{i}D_{i}}{T_{i}}}{\sum_{i=1}^{k}{B_{i}C_{i}}{T_{i}}}
\end{equation}

That is, we add the odds ratios of each stratum and weigh it by the
total in that stratum. If the odds ratio is greater than 1 then we
suspect that there may be an association between the outcome and
treatment across all strata and the CMH test statistic will be large. If
\(OR_{CMH} = 1\), then this supports the null hypothesis that there is
no association between treatment and outcome and the CMH test statistic
will be small.

We can also use the CMH test to compare odds ratios between experiments,
rather than compare against the null that the odds ratio = 1.

\hypertarget{blockrandate}{%
\subsection{Estimating an overall Average Treatment
Effect}\label{blockrandate}}

Our team nearly always reports a single estimate of the average
treatment effect whether or not we randomly assign a policy intervention
within blocks or strata. We randomly assign the intervention within each
block independently and we tend to \textbf{define} our overall ATE (the
estimand) as a simple average of the individual additive treatment
effects (for two treatments, remember that we tend to write this
unobserved causal effect as \(\tau_i = y_{i,0} - y_{i,1}\)). So we tend
to define the overall ATE as \(\bar{\tau}=(1/n) \sum_{i=1}^n \tau_i\).
Now, we have randomly assigned within blocks in order to (1) increase
precision and (2) enable subgroup analysis. How can we ``analyze as we
have randomized'' if we want to learn about \(\bar{\tau}\) using what we
observe? Our approach is to build up from the block-level (see
\citet{gerber_field_2012} for more on this approach). Say, for example,
we imagine that the unobserved ATE within a given block, \(b\), was
\(\text{ATE}_{b}=\bar{\tau}_b=(1/n_b)\sum_{i=1}^{n_b} \tau_{i}\) where
we are averaging the individual level treatment effects (\(\tau_{i}\))
across all \(n_b\) people in block \(b\). And now, imagine that we had
an experiment with blocks of different sizes (and perhaps with different
proportions assigned to treatment within block --- perhaps certain
blocks are more expensive places in which to run an experiment). We
could learn about \(\bar{\tau}\) with a block-size weighted average of
the \(\bar{\tau}_b\) such that
\(\bar{\tau}_{\text{nbwt}}= (1/B) \sum_{b=1}^B (n_b/n) \bar{\tau}_b\).
We can estimate \(\bar{\tau}_{\text{nbwt}}\) with the observed analogue
just as we have with the completely randomized experiment (after all,
each block is a small completely randomized experiment in this example,
and so we can estimate \(\bar{\tau}_b\) using the unbiased estimator
where \(i \in t\) means ``for \(i\) in the treatment group'',
\(\hat{\tau}_b=\sum_{i \in t} Y_{ib}/m_b - \sum_{i \in c} Y_{ib}/(n_b - m_b)\)
where \(m_b\) is the number of units assigned to treatment in block
\(b\).

\textbf{Note that many people do not use this unbiased estimator because
the precision of tests based on this estimator are worse that those of
another estimator that is slightly biased.} We will demonstrate both
methods --- the block-size weighted estimator and what we call the
precision-weighted estimator --- here and offer some reflections on when
a biased estimator that tends to produce answers closer to the truth
might be preferred over an unbiased estimator where any given estimate
may be farther from the truth. This estimator uses harmonic-weights. We
have tended to call it a ``precision-weighted average'' and the weights
on the blocks combine both the block size \(n_b\) and the proportion of
the block assigned to treatment
\(p_b = (1/n_b) \sum_{i=1}^{n_b} Z_{ib}\) for a binary treatment,
\(Z_{ib}\) so that the weight is \(h_b = n_b p_b (1 - p_b)\) and the
estimator is
\(\bar{\tau}_{\text{hbwt}}= (1/B) \sum_{b=1}^B (1/h_b) \bar{\tau}_b\).

First we show multiple approaches to producing estimates using these
estimators. And then we demonstrate how (1) ignoring the blocks when
estimating can produce problems in both estimation and testing, (2) how
the block-size weighted approaches are unbiased but possibly less
precise than the precision weighted approaches.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Create block sizes and create block weights}
\NormalTok{B }\OtherTok{\textless{}{-}} \DecValTok{10} \CommentTok{\# Number of blocks}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{b =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{B, }\FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{800}\NormalTok{)))}
\NormalTok{dat}\SpecialCharTok{$}\NormalTok{bF }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{b)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2201}\NormalTok{)}
\DocumentationTok{\#\# x1 is a covariate that strongly predicts the outcome without treatment}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(dat, b) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}
  \AttributeTok{nb =} \FunctionTok{n}\NormalTok{(),}
  \AttributeTok{x1 =} \FunctionTok{rpois}\NormalTok{(}\AttributeTok{n =}\NormalTok{ nb, }\AttributeTok{lambda =} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{1}\NormalTok{, }\AttributeTok{max =} \DecValTok{2000}\NormalTok{))}
\NormalTok{)}

\DocumentationTok{\#\# The treatment effect varies by size of block (using sqrt(nb) because nb has such a large range.)}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(dat, b) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}
  \AttributeTok{y0 =} \FunctionTok{sd}\NormalTok{(x1) }\SpecialCharTok{*}\NormalTok{ x1 }\SpecialCharTok{+} \FunctionTok{rchisq}\NormalTok{(}\AttributeTok{n =}\NormalTok{ nb, }\AttributeTok{df =} \DecValTok{1}\NormalTok{),}
  \AttributeTok{y0 =}\NormalTok{ y0 }\SpecialCharTok{*}\NormalTok{ (y0 }\SpecialCharTok{\textgreater{}} \FunctionTok{quantile}\NormalTok{(y0, .}\DecValTok{05}\NormalTok{)),}
  \AttributeTok{tauib =} \SpecialCharTok{{-}}\NormalTok{(}\FunctionTok{sd}\NormalTok{(y0)) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(nb) }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\FunctionTok{n}\NormalTok{(), }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(y0)),}
  \AttributeTok{y1 =}\NormalTok{ y0 }\SpecialCharTok{+}\NormalTok{ tauib,}
  \AttributeTok{y1 =}\NormalTok{ y1 }\SpecialCharTok{*}\NormalTok{ (y1 }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}
\NormalTok{)}
\NormalTok{blockpredpower }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(y0 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bF, }\AttributeTok{data =}\NormalTok{ dat))}\SpecialCharTok{$}\NormalTok{r.squared}
\end{Highlighting}
\end{Shaded}

To make the differences between the approaches to estimation most vivid,
we create a dataset with blocks of widely varying sizes, half of the
blocks have half of the units assigned to treatment and the other half
10\% of the units assigned to treatment. The baseline outcomes are
strongly predicted by the blocks (\(R^2\) around \(0.87\)).

We will use the \texttt{DeclareDesign} approach to assess bias, coverage
and power (or precision) of the different estimators here. The next code
block sets up the simulation and also demonstrates different approaches
to calculating the same numbers to represent the true underlying ATE (we
can only do this because we are using simulation here to learn about
different statistical techniques.)

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Using the Declare Design Machinery to ensure that the data here  and the}
\DocumentationTok{\#\# simulations below match}

\DocumentationTok{\#\# Setting up Declare Design:}
\NormalTok{thepop }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(dat)}

\NormalTok{po\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y\_Z\_0 }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{y0}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y\_Z\_1 }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{y1}
\NormalTok{  data}
\NormalTok{\}}

\NormalTok{theys }\OtherTok{\textless{}{-}} \FunctionTok{declare\_potential\_outcomes}\NormalTok{(}\AttributeTok{handler =}\NormalTok{ po\_function)}
\NormalTok{theestimand }\OtherTok{\textless{}{-}} \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0))}

\NormalTok{numtreated }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{nb)) }\SpecialCharTok{/} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{10}\NormalTok{), B }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}

\NormalTok{theassign }\OtherTok{\textless{}{-}} \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{block\_ra}\NormalTok{(}
  \AttributeTok{blocks =}\NormalTok{ bF,}
  \AttributeTok{block\_m =}\NormalTok{ numtreated}
\NormalTok{))}

\NormalTok{theobsident }\OtherTok{\textless{}{-}} \FunctionTok{declare\_reveal}\NormalTok{(Y, Z)}

\NormalTok{thedesign }\OtherTok{\textless{}{-}}\NormalTok{ thepop }\SpecialCharTok{+}\NormalTok{ theys }\SpecialCharTok{+}\NormalTok{ theestimand }\SpecialCharTok{+}\NormalTok{ theassign }\SpecialCharTok{+}\NormalTok{ theobsident}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2201}\NormalTok{)}
\NormalTok{dat2 }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(thedesign)}

\DocumentationTok{\#\# Adding rank transformed outcomes for use later.}
\NormalTok{dat2 }\OtherTok{\textless{}{-}}\NormalTok{ dat2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(b) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{y0md =}\NormalTok{ y0 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y0),}
    \AttributeTok{y1md =}\NormalTok{ y1 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y1),}
    \AttributeTok{alignedY =}\NormalTok{ Y }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y),}
    \AttributeTok{rankalignedY =} \FunctionTok{rank}\NormalTok{(alignedY)}
\NormalTok{  )}
\DocumentationTok{\#\# Now add individual level weights to the data. Different textbooks and algebra yield different expressions. We show that they are all the same.}
\NormalTok{dat2 }\OtherTok{\textless{}{-}}\NormalTok{ dat2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(b) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{nb =} \FunctionTok{n}\NormalTok{(), }\DocumentationTok{\#\# Size of block}
    \AttributeTok{pib =} \FunctionTok{mean}\NormalTok{(Z), }\DocumentationTok{\#\# prob of treatment assignment}
    \AttributeTok{nTb =} \FunctionTok{sum}\NormalTok{(Z), }\DocumentationTok{\#\# Number treated}
    \AttributeTok{nCb =}\NormalTok{ nb }\SpecialCharTok{{-}}\NormalTok{ nTb, }\DocumentationTok{\#\# Number control}
    \AttributeTok{nbwt =}\NormalTok{ (Z }\SpecialCharTok{/}\NormalTok{ pib) }\SpecialCharTok{+}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Z) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pib)),}
    \AttributeTok{nbwt2 =}\NormalTok{ nb }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(dat2),}
    \CommentTok{\# hbwt = 2 * (nCb * nTb )  / (nTb + nCb), \#\# Precision weight/Harmonic}
    \CommentTok{\# hbwt2 = 2 * ( nbwt2 )*(pib*(1{-}pib)),}
    \AttributeTok{hbwt3 =}\NormalTok{ nbwt }\SpecialCharTok{*}\NormalTok{ (pib }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pib))}
\NormalTok{  )}

\NormalTok{dat2}\SpecialCharTok{$}\NormalTok{nbwt3 }\OtherTok{\textless{}{-}}\NormalTok{ dat2}\SpecialCharTok{$}\NormalTok{nbwt2 }\SpecialCharTok{/}\NormalTok{ dat2}\SpecialCharTok{$}\NormalTok{nb}

\NormalTok{thepop2 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(dat2)}
\NormalTok{thedesign2 }\OtherTok{\textless{}{-}}\NormalTok{ thepop2 }\SpecialCharTok{+}\NormalTok{ theys }\SpecialCharTok{+}\NormalTok{ theestimand }\SpecialCharTok{+}\NormalTok{ theassign }\SpecialCharTok{+}\NormalTok{ theobsident}

\DocumentationTok{\#\# And create the block level dataset, with block level weights.}
\NormalTok{datB }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(dat2, b) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarize}\NormalTok{(}
  \AttributeTok{taub =} \FunctionTok{mean}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]),}
  \AttributeTok{truetaub =} \FunctionTok{mean}\NormalTok{(y1) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y0),}
  \AttributeTok{nb =} \FunctionTok{n}\NormalTok{(),}
  \AttributeTok{nTb =} \FunctionTok{sum}\NormalTok{(Z),}
  \AttributeTok{nCb =}\NormalTok{ nb }\SpecialCharTok{{-}}\NormalTok{ nTb,}
  \AttributeTok{estvartaub =}\NormalTok{ (nb }\SpecialCharTok{/}\NormalTok{ (nb }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{var}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ nTb) }\SpecialCharTok{+}\NormalTok{ (}\FunctionTok{var}\NormalTok{(Y[Z }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ nCb),}
  \AttributeTok{pb =} \FunctionTok{mean}\NormalTok{(Z),}
  \AttributeTok{nbwt =} \FunctionTok{unique}\NormalTok{(nb }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(dat2)),}
  \AttributeTok{pbwt =}\NormalTok{ pb }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pb),}
  \AttributeTok{hbwt2 =}\NormalTok{ nbwt }\SpecialCharTok{*}\NormalTok{ pbwt,}
  \AttributeTok{hbwt5 =}\NormalTok{ pbwt }\SpecialCharTok{*}\NormalTok{ nb,}
  \AttributeTok{hbwt =}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (nCb }\SpecialCharTok{*}\NormalTok{ nTb) }\SpecialCharTok{/}\NormalTok{ (nTb }\SpecialCharTok{+}\NormalTok{ nCb))}
\NormalTok{)}
\NormalTok{datB}\SpecialCharTok{$}\NormalTok{greenlabrule }\OtherTok{\textless{}{-}} \DecValTok{20} \SpecialCharTok{*}\NormalTok{ datB}\SpecialCharTok{$}\NormalTok{hbwt5 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{hbwt5)}

\DocumentationTok{\#\# Notice that all of these different ways to express the harmonic mean weight are the same.}
\NormalTok{datB}\SpecialCharTok{$}\NormalTok{hbwt01 }\OtherTok{\textless{}{-}}\NormalTok{ datB}\SpecialCharTok{$}\NormalTok{hbwt }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{hbwt)}
\NormalTok{datB}\SpecialCharTok{$}\NormalTok{hbwt201 }\OtherTok{\textless{}{-}}\NormalTok{ datB}\SpecialCharTok{$}\NormalTok{hbwt2 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{hbwt2)}
\NormalTok{datB}\SpecialCharTok{$}\NormalTok{hbwt501 }\OtherTok{\textless{}{-}}\NormalTok{ datB}\SpecialCharTok{$}\NormalTok{hbwt5 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{hbwt5)}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{hbwt01, datB}\SpecialCharTok{$}\NormalTok{hbwt201))}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{hbwt01, datB}\SpecialCharTok{$}\NormalTok{hbwt501))}

\DocumentationTok{\#\# What is the "true" ATE?}
\NormalTok{trueATE1 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(dat2, }\FunctionTok{mean}\NormalTok{(y1) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y0))}
\NormalTok{trueATE2 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(datB, }\FunctionTok{sum}\NormalTok{(truetaub }\SpecialCharTok{*}\NormalTok{ nbwt))}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(trueATE1, trueATE2))}
\DocumentationTok{\#\# We could define the following as an estimand, too. But it is a bit weird.}
\DocumentationTok{\#\# trueATE3 \textless{}{-} with(datB, sum(truetaub*hbwt01))}

\DocumentationTok{\#\# c(trueATE1,trueATE2,trueATE3)}

\DocumentationTok{\#\# We can get the same answer using R\textquotesingle{}s weighted.mean command}
\NormalTok{trueATE2b }\OtherTok{\textless{}{-}} \FunctionTok{weighted.mean}\NormalTok{(datB}\SpecialCharTok{$}\NormalTok{truetaub, }\AttributeTok{w =}\NormalTok{ datB}\SpecialCharTok{$}\NormalTok{nbwt)}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(trueATE2b, trueATE2))}
\end{Highlighting}
\end{Shaded}

Here we can see the design:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(dat2, }\FunctionTok{table}\NormalTok{(}\AttributeTok{treatment =}\NormalTok{ Z, }\AttributeTok{blocknumber =}\NormalTok{ b))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         blocknumber
treatment   1   2   3   4   5   6   7   8   9  10
        0   4  18  15  36  25  54  35  72  50 720
        1   4   2  15   4  25   6  35   8  50  80
\end{verbatim}

Now, we will show multiple ways to get the same answer and later show
evidence about bias and precision. Notice that we do not use fixed
effects on their own in any of these approaches. There are two
approaches that do use fixed effects/indicator variables but they only
include them in interaction with the treatment assignment. Below we will
show that all of these approaches are unbiased estimators of
\(\bar{\tau}_{\text{nbwt}}\) (the ATE treating all individuals equally
although randomizing within block).

For example, below we see 6 different ways to estimate the average
treatment effect using block-size weights: \texttt{simple\_block} refers
to calculating meaen differences within blocks and then taking the
block-size weighted averagee of them; diffmeans uses the
\texttt{difference\_in\_means} function from the \texttt{estimatr}
package \citep{R-estimatr}; \texttt{lmlin} uses the Lin approach to
covariance adjustment but uses block indicators instead of other
covariates using the \texttt{lm\_lin} function; \texttt{lmlinbyhand}
verifies that function using matrix operations; \texttt{intereactionBFE}
uses the \texttt{EstimateIWE} function from the \texttt{bfe} package
\citep{R-bfe}; and \texttt{regwts} uses the basic OLS function from R
\texttt{lm} with appropriate weights.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# Block size weighting}
\NormalTok{ate\_nbwt1 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(datB, }\FunctionTok{sum}\NormalTok{(taub }\SpecialCharTok{*}\NormalTok{ nbwt))}
\NormalTok{ate\_nbwt2 }\OtherTok{\textless{}{-}} \FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{blocks =}\NormalTok{ b, }\AttributeTok{data =}\NormalTok{ dat2)}
\NormalTok{ate\_nbwt3 }\OtherTok{\textless{}{-}} \FunctionTok{lm\_lin}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{covariates =} \SpecialCharTok{\textasciitilde{}}\NormalTok{bF, }\AttributeTok{data =}\NormalTok{ dat2)}
\NormalTok{ate\_nbwt5 }\OtherTok{\textless{}{-}} \FunctionTok{EstimateIWE}\NormalTok{(}\AttributeTok{y =} \StringTok{"Y"}\NormalTok{, }\AttributeTok{treatment =} \StringTok{"Z"}\NormalTok{, }\AttributeTok{group =} \StringTok{"bF"}\NormalTok{, }\AttributeTok{controls =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{data =} \FunctionTok{as.data.frame}\NormalTok{(dat2))}
\NormalTok{ate\_nbwt6 }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat2, }\AttributeTok{weights =}\NormalTok{ nbwt)}
\NormalTok{ate\_nbwt6a }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat2, }\AttributeTok{weights =}\NormalTok{ nbwt)}
\NormalTok{ate\_nbwt6ase }\OtherTok{\textless{}{-}} \FunctionTok{coeftest}\NormalTok{(ate\_nbwt6a, }\AttributeTok{vcov =} \FunctionTok{vcovHC}\NormalTok{(ate\_nbwt6a, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{))}

\DocumentationTok{\#\# This next implements the lm\_lin method from Lin 2013 by hand:}
\DocumentationTok{\#\# Implementing Lin\textquotesingle{}s method from https://alexandercoppock.com/Green{-}Lab{-}SOP/Green\_Lab\_SOP.html\#taking{-}block{-}randomization{-}into{-}account{-}in{-}ses{-}and{-}cis.}

\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ bF }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ dat2)}
\NormalTok{barX }\OtherTok{\textless{}{-}} \FunctionTok{colMeans}\NormalTok{(X)}
\NormalTok{Xmd }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(X, }\DecValTok{2}\NormalTok{, barX)}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{((X[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(X[, }\DecValTok{3}\NormalTok{])), Xmd[, }\DecValTok{3}\NormalTok{]))}
\NormalTok{ZXmd }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(Xmd, }\DecValTok{1}\NormalTok{, dat2}\SpecialCharTok{$}\NormalTok{Z, }\AttributeTok{FUN =} \StringTok{"*"}\NormalTok{)}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{all.equal}\NormalTok{(dat2}\SpecialCharTok{$}\NormalTok{Z }\SpecialCharTok{*}\NormalTok{ Xmd[, }\DecValTok{3}\NormalTok{], ZXmd[, }\DecValTok{3}\NormalTok{]))}
\NormalTok{bigX }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\AttributeTok{Intercept =} \DecValTok{1}\NormalTok{, }\AttributeTok{Z =}\NormalTok{ dat2}\SpecialCharTok{$}\NormalTok{Z, Xmd[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], ZXmd[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\CommentTok{\# ate\_nbwt4 \textless{}{-} lm.fit(x=bigX,y=dat$Y)}
\NormalTok{bigXdf }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(bigX, }\AttributeTok{Y =}\NormalTok{ dat2}\SpecialCharTok{$}\NormalTok{Y)}
\NormalTok{ate\_nbwt4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ bigXdf)}
\NormalTok{ate\_nbwt4se }\OtherTok{\textless{}{-}} \FunctionTok{coeftest}\NormalTok{(ate\_nbwt4, }\AttributeTok{vcov. =} \FunctionTok{vcovHC}\NormalTok{(ate\_nbwt4, }\AttributeTok{type =} \StringTok{"HC2"}\NormalTok{))}


\NormalTok{nbwtates }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \AttributeTok{simple\_block =}\NormalTok{ ate\_nbwt1,}
  \AttributeTok{diffmeans =}\NormalTok{ ate\_nbwt2}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]],}
  \AttributeTok{lmlin =}\NormalTok{ ate\_nbwt3}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]],}
  \AttributeTok{lmlinbyhand =}\NormalTok{ ate\_nbwt4}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]],}
  \AttributeTok{interactionBFE =}\NormalTok{ ate\_nbwt5}\SpecialCharTok{$}\NormalTok{swe.est,}
  \AttributeTok{regwts =}\NormalTok{ ate\_nbwt6}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]]}
\NormalTok{)}

\NormalTok{nbwtates}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  simple_block      diffmeans          lmlin    lmlinbyhand interactionBFE         regwts 
        -12823         -12823         -12823         -12823         -12823         -12823 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Comparing the Standard Errors}
\DocumentationTok{\#\# ate\_nbwt1se \textless{}{-} sqrt(sum(datB$nbwt\^{}2 * datB$estvartaub))}
\DocumentationTok{\#\#}
\DocumentationTok{\#\# nbwtses \textless{}{-} c(simple\_block=ate\_nbwt1se,}
\DocumentationTok{\#\#       diffmeans=ate\_nbwt2$std.error,}
\DocumentationTok{\#\#       lmlin=ate\_nbwt3$std.error[["Z"]],}
\DocumentationTok{\#\#       interaction1=ate\_nbwt4se["Z","Std. Error"],}
\DocumentationTok{\#\#       interaction2=ate\_nbwt5$swe.var\^{}.5,}
\DocumentationTok{\#\#       wts=ate\_nbwt6$std.error[["Z"]])}
\DocumentationTok{\#\# nbwtses}
\end{Highlighting}
\end{Shaded}

Weighting by block size allows us to define the average treatment effect
in a way that treats each unit equally. And we have shown six different
ways to estimate this effect. If we want to calculate standard errors
for these estimators, so as to produce confidence intervals, we will, in
general, be leaving statistical power on the table in exchange for an
easier to interpret estimate, an estimator that relates to its
underlying target in an unbiased fashion. Below we show an approach
which is optimal from the perspective of statistical power, precision,
or narrow confidence intervals which we call ``precision weighted''
average treatment effects.\footnote{See Section 5 of
  \citet{hansen_covariate_2008} for proof that this kind of weighting is
  optimal from the perspective of precision.} In some literatures using
the least squares machinery to calculate the weighted means this
approach is called Least Squared Dummy Variables, or ``fixed effects''.
However, we show below that these approaches are all versions of a
weighted least squares estimator.

Below we see that we can estimate the precision-weighted ATE in five
different ways: \texttt{simple\_block} calculates simple differences of
means within blocks and then takes a weighted average of those
differences, using the precision weights; \texttt{lm\_fixed\_effects1}
uses \texttt{lm\_robust} with indicators for block;
\texttt{lm\_fixed\_effects2} uses \texttt{lm\_robust} with the
\texttt{fixed\_effects} option including a factor variable recording
block membership; \texttt{direct\_wts} uses \texttt{lm\_robust} without
block-indicators but with precision weights; and \texttt{demeaned}
regresses a block-centered version of the outcome on a block-centered
version of the treatment indicator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ate\_hbwt1 }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(datB, }\FunctionTok{sum}\NormalTok{(taub }\SpecialCharTok{*}\NormalTok{ hbwt01))}
\NormalTok{ate\_hbwt2 }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ bF, }\AttributeTok{data =}\NormalTok{ dat2)}
\NormalTok{ate\_hbwt3 }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{fixed\_effects =} \SpecialCharTok{\textasciitilde{}}\NormalTok{bF, }\AttributeTok{data =}\NormalTok{ dat2)}
\NormalTok{ate\_hbwt4 }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ dat2, }\AttributeTok{weights =}\NormalTok{ hbwt3)}
\NormalTok{ate\_hbwt5 }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(}\FunctionTok{I}\NormalTok{(Y }\SpecialCharTok{{-}} \FunctionTok{ave}\NormalTok{(Y, b)) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{I}\NormalTok{(Z }\SpecialCharTok{{-}} \FunctionTok{ave}\NormalTok{(Z, b)), }\AttributeTok{data =}\NormalTok{ dat2)}
\NormalTok{hbwtates }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \AttributeTok{simple\_block =}\NormalTok{ ate\_hbwt1,}
  \AttributeTok{lm\_fixed\_effects1 =}\NormalTok{ ate\_hbwt2}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]],}
  \AttributeTok{lm\_fixed\_effects2 =}\NormalTok{ ate\_hbwt3}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]],}
  \AttributeTok{direct\_wts =}\NormalTok{ ate\_hbwt4}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]],}
  \AttributeTok{demeaned =}\NormalTok{ ate\_hbwt5}\SpecialCharTok{$}\NormalTok{coefficient[[}\DecValTok{2}\NormalTok{]]}
\NormalTok{)}
\NormalTok{hbwtates}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     simple_block lm_fixed_effects1 lm_fixed_effects2        direct_wts          demeaned 
           -13981            -13981            -13981            -13981            -13981 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# ate\_hbwt1se \textless{}{-} sqrt(sum(datB$hbwt01\^{}2 * datB$estvartaub))}
\DocumentationTok{\#\#}
\DocumentationTok{\#\# hbwtses \textless{}{-} c(simple\_block=ate\_hbwt1se,}
\DocumentationTok{\#\#       diffmeans=ate\_hbwt2$std.error[["Z"]],}
\DocumentationTok{\#\#       lmfe=ate\_hbwt3$std.error[["Z"]],}
\DocumentationTok{\#\#       wts=ate\_hbwt4$std.error[["Z"]],}
\DocumentationTok{\#\#       demean=ate\_hbwt5$std.error[[2]])}
\DocumentationTok{\#\# hbwtses}
\DocumentationTok{\#\#}
\DocumentationTok{\#\# nbwtses}
\end{Highlighting}
\end{Shaded}

Now, we claimed that the block size weighted estimator is unbiased but
perhaps less precise than the precision-weighted estimator. We use
\texttt{DeclareDesign} to to compare the performance of these
estimators. We focus here on the use of least squares to calculate the
weighted averages and standard errors but, as we showed above, one could
calculate the estimates easily without using least squares.

We implement those estimators as functions usable by the
\texttt{diagnose\_design} function in the next code block.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define estimators that can be repeated in the simulation below}
\NormalTok{estnowtHC2 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"E1: Ignores Blocks, Design SE"}\NormalTok{)}
\NormalTok{estnowtIID }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm, }\AttributeTok{label =} \StringTok{"E0: Ignores Blocks, IID SE"}\NormalTok{)}
\NormalTok{estnbwt1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ difference\_in\_means, }\AttributeTok{blocks =}\NormalTok{ b, }\AttributeTok{label =} \StringTok{"E2: Diff Means Block Size Weights, Design SE"}\NormalTok{)}
\NormalTok{estnbwt2 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_lin, }\AttributeTok{covariates =} \SpecialCharTok{\textasciitilde{}}\NormalTok{bF, }\AttributeTok{label =} \StringTok{"E3: Treatment Interaction with Block Indicators, Design SE"}\NormalTok{)}

\NormalTok{iwe\_est\_fun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  obj }\OtherTok{\textless{}{-}} \FunctionTok{EstimateIWE}\NormalTok{(}\AttributeTok{y =} \StringTok{"Y"}\NormalTok{, }\AttributeTok{treatment =} \StringTok{"Z"}\NormalTok{, }\AttributeTok{group =} \StringTok{"bF"}\NormalTok{, }\AttributeTok{controls =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{data =}\NormalTok{ data)}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{summary.iwe}\NormalTok{(obj)[}\StringTok{"SWE"}\NormalTok{, ]}
\NormalTok{  res}\SpecialCharTok{$}\NormalTok{term }\OtherTok{\textless{}{-}} \StringTok{"Z"}
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}

\NormalTok{estnbwt3 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(iwe\_est\_fun), }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{label =} \StringTok{"E4: Treatment Interaction with Block Indicators, Design SE"}\NormalTok{)}

\NormalTok{nbwt\_est\_fun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{newnbwt }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(data, (Z }\SpecialCharTok{/}\NormalTok{ pib) }\SpecialCharTok{+}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Z) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pib)))}
\NormalTok{  obj }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ data, }\AttributeTok{weights =}\NormalTok{ newnbwt)}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(obj) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{==} \StringTok{"Z"}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}

\NormalTok{hbwt\_est\_fun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{newnbwt }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(data, (Z }\SpecialCharTok{/}\NormalTok{ pib) }\SpecialCharTok{+}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Z) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pib)))}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{newhbwt }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(data, newnbwt }\SpecialCharTok{*}\NormalTok{ (pib }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pib)))}
\NormalTok{  obj }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ data, }\AttributeTok{weights =}\NormalTok{ newhbwt)}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(obj) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{==} \StringTok{"Z"}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}

\NormalTok{estnbwt4 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(nbwt\_est\_fun), }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{label =} \StringTok{"E5: Least Squares with Block Size Weights, Design SE"}\NormalTok{)}
\NormalTok{esthbwt1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ bF, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"E6: Precision Weights via Fixed Effects, Design SE"}\NormalTok{)}
\NormalTok{esthbwt2 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{fixed\_effects =} \SpecialCharTok{\textasciitilde{}}\NormalTok{bF, }\AttributeTok{label =} \StringTok{"E7: Precision Weights via Demeaning, Design SE"}\NormalTok{)}
\NormalTok{esthbwt3 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(hbwt\_est\_fun), }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{label =} \StringTok{"E8: Direct Precision Weights, Design SE"}\NormalTok{)}

\NormalTok{direct\_demean\_fun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(data, Y }\SpecialCharTok{{-}} \FunctionTok{ave}\NormalTok{(Y, b))}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Z }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(data, Z }\SpecialCharTok{{-}} \FunctionTok{ave}\NormalTok{(Z, b))}
\NormalTok{  obj }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ data)}
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{term =} \StringTok{"Z"}\NormalTok{,}
    \AttributeTok{estimate =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{coefficients[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{std.error =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{std.error[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{statistic =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{statistic[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{p.value =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{p.value[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{conf.low =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{conf.low[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{conf.high =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{conf.high[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{df =}\NormalTok{ obj}\SpecialCharTok{$}\NormalTok{df[[}\DecValTok{2}\NormalTok{]],}
    \AttributeTok{outcome =} \StringTok{"Y"}
\NormalTok{  )}
\NormalTok{\}}

\NormalTok{esthbwt4 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{tidy\_estimator}\NormalTok{(direct\_demean\_fun), }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{label =} \StringTok{"E9: Direct Demeaning, Design SE"}\NormalTok{)}

\NormalTok{theestimators }\OtherTok{\textless{}{-}} \FunctionTok{ls}\NormalTok{(}\AttributeTok{patt =} \StringTok{"\^{}est.*?wt"}\NormalTok{)}
\NormalTok{theestimators}

\NormalTok{checkest }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(theestimators, }\ControlFlowTok{function}\NormalTok{(x) \{}
  \FunctionTok{get}\NormalTok{(x)(}\FunctionTok{as.data.frame}\NormalTok{(dat2))[}\FunctionTok{c}\NormalTok{(}\StringTok{"estimate"}\NormalTok{, }\StringTok{"std.error"}\NormalTok{)]}
\NormalTok{\})}

\NormalTok{checkest}

\NormalTok{thedesignPlusEstimators }\OtherTok{\textless{}{-}}\NormalTok{ thedesign2 }\SpecialCharTok{+}
\NormalTok{  estnowtHC2 }\SpecialCharTok{+}\NormalTok{ estnowtIID }\SpecialCharTok{+}\NormalTok{ estnbwt1 }\SpecialCharTok{+}\NormalTok{ estnbwt2 }\SpecialCharTok{+}\NormalTok{ estnbwt3 }\SpecialCharTok{+}\NormalTok{ estnbwt4 }\SpecialCharTok{+}
\NormalTok{  esthbwt1 }\SpecialCharTok{+}\NormalTok{ esthbwt2 }\SpecialCharTok{+}\NormalTok{ esthbwt3 }\SpecialCharTok{+}\NormalTok{ esthbwt4}

\DocumentationTok{\#\# Verifying that this works with a fixed population}
\DocumentationTok{\#\# datv1 \textless{}{-} draw\_data(thedesign)}
\DocumentationTok{\#\# datv2 \textless{}{-} draw\_data(thedesign)}
\DocumentationTok{\#\# table(datv1$Z,datv2$Z)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims }\OtherTok{\textless{}{-}} \DecValTok{200}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{thediagnosis }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignPlusEstimators, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We see that the estimator using block-size weights (E2, E3, E4, or E5)
all eliminate bias (within simulation error). The estimators ignoring
blocks (E0 and E1), have bias, and in this simulation, the precision
weighed estimators (E6--E9) also show high bias --- with some of them
also producing poor coverage or false positive rates (E7 and E9).

The diagnostic output also shows us the ``SD Estimate'' (which is a good
estimate of the standard error of the estimate) and the ``Mean SE''
(which is the average of the analytic estimates of the standard error).
In the case of E2, E3, E4 or E5 the Mean SE is larger than the SD
Estimate --- this is good in that it means that our analytic standard
errors will be conservative. However, we also would prefer that our
analytic standard errors not be \emph{too} conservative, for example, E5
looks good but the mean analytic standard error is quite high compared
to E4, for example.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# See https://haozhu233.github.io/kableExtra/awesome\_table\_in\_html.html}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosis)[, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "600px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l}
\hline
Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
E0: Ignores Blocks, IID SE & Z & -12900.57 & -12355.37 & 545.20 & 106.01 & 555.36 & 1.00\\
\hline
E1: Ignores Blocks, Design SE & Z & -12900.57 & -12355.37 & 545.20 & 106.01 & 555.36 & 1.00\\
\hline
E2: Diff Means Block Size Weights, Design SE & Z & -12900.57 & -12900.11 & 0.46 & 115.65 & 115.36 & 1.00\\
\hline
E3: Treatment Interaction with Block Indicators, Design SE & Z & -12900.57 & -12900.11 & 0.46 & 115.65 & 115.36 & 1.00\\
\hline
E4: Treatment Interaction with Block Indicators, Design SE & Z & -12900.57 & -12900.11 & 0.46 & 115.65 & 115.36 & 1.00\\
\hline
E5: Least Squares with Block Size Weights, Design SE & Z & -12900.57 & -12900.11 & 0.46 & 115.65 & 115.36 & 1.00\\
\hline
E6: Precision Weights via Fixed Effects, Design SE & Z & -12900.57 & -14143.05 & -1242.48 & 208.64 & 1259.79 & 1.00\\
\hline
E7: Precision Weights via Demeaning, Design SE & Z & -12900.57 & -14143.05 & -1242.48 & 208.64 & 1259.79 & 1.00\\
\hline
E8: Direct Precision Weights, Design SE & Z & -12900.57 & -14143.05 & -1242.48 & 208.64 & 1259.79 & 1.00\\
\hline
E9: Direct Demeaning, Design SE & Z & -12900.57 & -14143.05 & -1242.48 & 208.64 & 1259.79 & 1.00\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simdesigns }\OtherTok{\textless{}{-}} \FunctionTok{get\_simulations}\NormalTok{(thediagnosis)}
\DocumentationTok{\#\# simdesigns \textless{}{-} simulate\_design(thedesign,sims=sims)}
\NormalTok{simmeans }\OtherTok{\textless{}{-}}\NormalTok{ simdesigns }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(estimator) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{expest =} \FunctionTok{mean}\NormalTok{(estimate))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Now compare to better behaved outcomes.}
\NormalTok{g }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simdesigns, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ estimate, }\AttributeTok{color =}\NormalTok{ estimator)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ trueATE1) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simmeans, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ expest, }\AttributeTok{y =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)), }\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \DecValTok{6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(.}\DecValTok{9}\NormalTok{, .}\DecValTok{8}\NormalTok{))}
\FunctionTok{print}\NormalTok{(g)}
\end{Highlighting}
\end{Shaded}

Since we wondered whether these biases might be exacerbated by the
highly skewed nature of our outcome data (which is designed to look like
administrative outcomes in its prevalence of zeros and long tails), we
transformed the outcomes to ranks. This less skewed outcome nearly
erases the bias from the block-sizee weighted estimators, and the
precision-weighted approach also performs well. Ignoring the blocked
design is still a problem here --- E0 and E1 showing high bias.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{po\_functionNorm }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(b) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{Y\_Z\_0 =} \FunctionTok{rank}\NormalTok{(y0),}
      \AttributeTok{Y\_Z\_1 =} \FunctionTok{rank}\NormalTok{(y1)}
\NormalTok{    )}
  \FunctionTok{as.data.frame}\NormalTok{(data)}
\NormalTok{\}}

\NormalTok{theysNorm }\OtherTok{\textless{}{-}} \FunctionTok{declare\_potential\_outcomes}\NormalTok{(}\AttributeTok{handler =}\NormalTok{ po\_functionNorm)}

\NormalTok{thedesignNorm }\OtherTok{\textless{}{-}}\NormalTok{ thepop2 }\SpecialCharTok{+}\NormalTok{ theysNorm }\SpecialCharTok{+}\NormalTok{ theestimand }\SpecialCharTok{+}\NormalTok{ theassign }\SpecialCharTok{+}\NormalTok{ theobsident}

\NormalTok{datNorm }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(thedesignNorm)}

\NormalTok{thedesignPlusEstimatorsNorm }\OtherTok{\textless{}{-}}\NormalTok{ thedesignNorm }\SpecialCharTok{+}
\NormalTok{  estnowtHC2 }\SpecialCharTok{+}\NormalTok{ estnowtIID }\SpecialCharTok{+}\NormalTok{ estnbwt1 }\SpecialCharTok{+}\NormalTok{ estnbwt2 }\SpecialCharTok{+}\NormalTok{ estnbwt3 }\SpecialCharTok{+}\NormalTok{ estnbwt4 }\SpecialCharTok{+}
\NormalTok{  esthbwt1 }\SpecialCharTok{+}\NormalTok{ esthbwt2 }\SpecialCharTok{+}\NormalTok{ esthbwt3 }\SpecialCharTok{+}\NormalTok{ esthbwt4}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{thediagnosisNorm }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignPlusEstimatorsNorm, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisNorm)[, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "600px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l}
\hline
Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
E0: Ignores Blocks, IID SE & Z & 0.00 & -127.08 & -127.08 & 1.85 & 127.10 & 1.00\\
\hline
E1: Ignores Blocks, Design SE & Z & 0.00 & -127.08 & -127.08 & 1.85 & 127.10 & 1.00\\
\hline
E2: Diff Means Block Size Weights, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.70 & 1.70 & 0.00\\
\hline
E3: Treatment Interaction with Block Indicators, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.70 & 1.70 & 0.00\\
\hline
E4: Treatment Interaction with Block Indicators, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.70 & 1.70 & 0.00\\
\hline
E5: Least Squares with Block Size Weights, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.70 & 1.70 & 0.00\\
\hline
E6: Precision Weights via Fixed Effects, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.36 & 1.36 & 0.00\\
\hline
E7: Precision Weights via Demeaning, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.36 & 1.36 & 0.00\\
\hline
E8: Direct Precision Weights, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.36 & 1.36 & 0.00\\
\hline
E9: Direct Demeaning, Design SE & Z & 0.00 & 0.11 & 0.11 & 1.36 & 1.36 & 0.00\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simdesignsNorm }\OtherTok{\textless{}{-}} \FunctionTok{get\_simulations}\NormalTok{(thediagnosisNorm)}
\DocumentationTok{\#\# simdesigns \textless{}{-} simulate\_design(thedesign,sims=sims)}
\NormalTok{simmeansNorm }\OtherTok{\textless{}{-}}\NormalTok{ simdesignsNorm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(estimator) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{expest =} \FunctionTok{mean}\NormalTok{(estimate))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g2 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simdesignsNorm, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ estimate, }\AttributeTok{color =}\NormalTok{ estimator)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ trueATE1) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simmeansNorm, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ expest, }\AttributeTok{y =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)), }\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \DecValTok{6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(.}\DecValTok{9}\NormalTok{, .}\DecValTok{8}\NormalTok{))}
\FunctionTok{print}\NormalTok{(g2)}
\end{Highlighting}
\end{Shaded}

In a pair-randomized design, we know that bias should not arise from
ignoring the blocking structure but we could double our statistical
power by taking the pairing into account \citep{bowers2011mem}. This
next simulation changes the design to still have unequal sized blocks,
but with all of the blocks having the same probability of treatment
assignment although they vary greatly in size. Here only two esimators
show appreciable bias (E5 and E8). However, ignoring the blocks leads to
overly conservative standard errors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theassignEqual }\OtherTok{\textless{}{-}} \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ bF))}

\NormalTok{thedesignNormEqual }\OtherTok{\textless{}{-}}\NormalTok{ thepop2 }\SpecialCharTok{+}\NormalTok{ theysNorm }\SpecialCharTok{+}\NormalTok{ theestimand }\SpecialCharTok{+}\NormalTok{ theassignEqual }\SpecialCharTok{+}\NormalTok{ theobsident}

\NormalTok{datNormEqual }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(thedesignNormEqual)}

\NormalTok{thedesignPlusEstimatorsNormEqual }\OtherTok{\textless{}{-}}\NormalTok{ thedesignNormEqual }\SpecialCharTok{+}
\NormalTok{  estnowtHC2 }\SpecialCharTok{+}\NormalTok{ estnowtIID }\SpecialCharTok{+}\NormalTok{ estnbwt1 }\SpecialCharTok{+}\NormalTok{ estnbwt2 }\SpecialCharTok{+}\NormalTok{ estnbwt3 }\SpecialCharTok{+}\NormalTok{ estnbwt4 }\SpecialCharTok{+}
\NormalTok{  esthbwt1 }\SpecialCharTok{+}\NormalTok{ esthbwt2 }\SpecialCharTok{+}\NormalTok{ esthbwt3 }\SpecialCharTok{+}\NormalTok{ esthbwt4}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{thediagnosisNormEqual }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignPlusEstimatorsNormEqual, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisNormEqual)[, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "600px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l}
\hline
Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
E0: Ignores Blocks, IID SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E1: Ignores Blocks, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E2: Diff Means Block Size Weights, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E3: Treatment Interaction with Block Indicators, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E4: Treatment Interaction with Block Indicators, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E5: Least Squares with Block Size Weights, Design SE & Z & 0.00 & 77.64 & 77.64 & 4.10 & 77.75 & 1.00\\
\hline
E6: Precision Weights via Fixed Effects, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E7: Precision Weights via Demeaning, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
E8: Direct Precision Weights, Design SE & Z & 0.00 & 127.10 & 127.10 & 2.72 & 127.13 & 1.00\\
\hline
E9: Direct Demeaning, Design SE & Z & 0.00 & -0.26 & -0.26 & 4.75 & 4.75 & 0.00\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simdesignsNormEqual }\OtherTok{\textless{}{-}} \FunctionTok{get\_simulations}\NormalTok{(thediagnosisNorm)}
\NormalTok{simmeansNormEqual }\OtherTok{\textless{}{-}}\NormalTok{ simdesignsNormEqual }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(estimator) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{expest =} \FunctionTok{mean}\NormalTok{(estimate))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Now compare to better behaved outcomes.}
\NormalTok{g3 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simdesignsNormEqual, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ estimate, }\AttributeTok{color =}\NormalTok{ estimator)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ trueATE1) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simmeansNormEqual, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ expest, }\AttributeTok{y =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)), }\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \DecValTok{6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(.}\DecValTok{9}\NormalTok{, .}\DecValTok{8}\NormalTok{))}
\FunctionTok{print}\NormalTok{(g3)}
\end{Highlighting}
\end{Shaded}

\hypertarget{summary-of-approaches-to-the-analysis-of-block-randomized-trials}{%
\subsubsection{Summary of Approaches to the Analysis of Block Randomized
Trials}\label{summary-of-approaches-to-the-analysis-of-block-randomized-trials}}

Our team prefers block randomized trials because of their potential to
increase statistical power (and thus provide more bang for the research
buck) as well as their ability to let us focus on subgroup effects when
relevant. The approach of our team to the analysis of blocked
experiments has been guided by evidence like that shown here: we analyze
as we randomize to avoid bias and increase statistical power, and we are
careful in our choice of weighting approaches. Different designs will
require different specific decisions --- sometimes we may be willing to
trade a small amount of bias for a guarantee that our estimates will be
closer to the truth and more precise, on average (i.e.~trade
mean-squared error for bias). Other studies will be so large or small
that one or another strategy will become obvious. We use our Analysis
Plans to specify these approaches and simulation studies like those
shown here when we are uncertain about the applicability of statistical
rules of thumb to any given design.

\hypertarget{clusterrandanalysis}{%
\section{Cluster-randomized trials}\label{clusterrandanalysis}}

A cluster randomized trial tends to distinguish signal from noise less
well than an experiment where we can assign treatment directly to
individuals because the number of independent pieces of information
available to learn about the treatment effect is closer to the number of
clusters (each of which tends to be assigned to treatment independently
of each other) than it is to the number of dependent observations within
a cluster (See
\href{https://egap.org/methods-guides/10-things-you-need-know-about-cluster-randomization}{10
Things You Need to Know about Cluster Randomization}).

Since we analyze as we randomize, a cluster randomized experiment
requires that we (1) weight the combination of cluster-level average
treatment effects by cluster size if we are trying to estimate the
average of the individual level causal effects
\citep{middleton2015unbiased} and (2) change how we calculate standard
errors and \(p\)-values to account for the fact that uncertainty is
generated at the level of the cluster and not at the level of the
individual \citep{hansen_covariate_2008, gerber_field_2012}. For
example, imagine that we had 10 clusters (administrative offices,
physicians groups, etc..) with half assigned to treatment and half
assigned to control.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\DocumentationTok{\#\# Randomly assign half of the clusters to treatment and half to control}
\NormalTok{dat3}\SpecialCharTok{$}\NormalTok{Zcluster }\OtherTok{\textless{}{-}} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ dat3}\SpecialCharTok{$}\NormalTok{cluster)}
\CommentTok{\# dat3$falsestratum \textless{}{-} rep(1,nrow(dat3))}
\CommentTok{\# dat3$iprweight \textless{}{-}  with(dat3,ipr(Zcluster,falsestratum,clusterF))}
\FunctionTok{with}\NormalTok{(dat3, }\FunctionTok{table}\NormalTok{(Zcluster, cluster))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        cluster
Zcluster   1   2   3   4   5   6   7   8   9  10
       0   8   0  30  40   0   0   0   0 100 800
       1   0  20   0   0  50  60  70  80   0   0
\end{verbatim}

So, although our data has 1258 observations, we do not have 1258 pieces
of independent information about the effect of the treatment because
people were assigned in groups. Rather we have some amount of
information in between 100 and the number of clusters, in this case, 10.
For example, here we can see the number of people within each cluster
--- and notice that all of the people are coded as either control or
treatment because assignment is at the level of the cluster.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Setup the cluster{-}randomized design}
\FunctionTok{library}\NormalTok{(ICC)}
\NormalTok{iccres }\OtherTok{\textless{}{-}} \FunctionTok{ICCest}\NormalTok{(}\AttributeTok{x =}\NormalTok{ clusterF, }\AttributeTok{y =}\NormalTok{ Y, }\AttributeTok{data =}\NormalTok{ dat3)}
\NormalTok{dat3}\SpecialCharTok{$}\NormalTok{varweight }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ (iccres}\SpecialCharTok{$}\NormalTok{vara }\SpecialCharTok{+}\NormalTok{ (iccres}\SpecialCharTok{$}\NormalTok{varw }\SpecialCharTok{/}\NormalTok{ dat3}\SpecialCharTok{$}\NormalTok{nb))}

\NormalTok{thepop3 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(dat3)}

\NormalTok{po\_functionCluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y\_Zcluster\_0 }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{y0}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{Y\_Zcluster\_1 }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{y1}
\NormalTok{  data}
\NormalTok{\}}

\NormalTok{theysCluster }\OtherTok{\textless{}{-}} \FunctionTok{declare\_potential\_outcomes}\NormalTok{(}\AttributeTok{handler =}\NormalTok{ po\_functionCluster)}

\NormalTok{theestimandCluster }\OtherTok{\textless{}{-}} \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Zcluster\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Zcluster\_0))}

\NormalTok{theassignCluster }\OtherTok{\textless{}{-}} \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Zcluster =} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{clusters =}\NormalTok{ cluster))}

\NormalTok{theobsidentCluster }\OtherTok{\textless{}{-}} \FunctionTok{declare\_reveal}\NormalTok{(Y, Zcluster)}

\NormalTok{thedesignCluster }\OtherTok{\textless{}{-}}\NormalTok{ thepop3 }\SpecialCharTok{+}\NormalTok{ theysCluster }\SpecialCharTok{+}\NormalTok{ theestimandCluster }\SpecialCharTok{+}\NormalTok{ theassignCluster }\SpecialCharTok{+}\NormalTok{ theobsidentCluster}

\NormalTok{datCluster }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(thedesignCluster)}
\end{Highlighting}
\end{Shaded}

In everyday practice, with more than about 50 clusters, we produce
estimates and using more or less the same kinds software as we do above
but changing the standard error calculations to use the the \texttt{CR2}
cluster-robust standard error \citep{pustejovsky2019cr}. For example,
here are two approaches to such adjustment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE4a }\OtherTok{\textless{}{-}} \FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster, }\AttributeTok{data =}\NormalTok{ datCluster, }\AttributeTok{clusters =}\NormalTok{ cluster)}
\NormalTok{estAndSE4a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Design:  Clustered 
         Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper   DF
Zcluster   -15597       8336  -1.871   0.1232   -37356     6162 4.76
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estAndSE4b }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster, }\AttributeTok{data =}\NormalTok{ datCluster, }\AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"CR2"}\NormalTok{)}
\NormalTok{estAndSE4b}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper    DF
(Intercept)    15707       8332   1.885   0.1409    -8542    39955 3.578
Zcluster      -15597       8336  -1.871   0.1232   -37356     6162 4.760
\end{verbatim}

\hypertarget{bias-when-cluster-size-is-correlated-with-potential-outcomes}{%
\subsection{Bias when cluster size is correlated with potential
outcomes}\label{bias-when-cluster-size-is-correlated-with-potential-outcomes}}

When clusters have unequal sizes, we worry about bias in addition to
appropriate estimates of precision \citep{middleton2015unbiased} (see
also
\url{https://declaredesign.org/blog/bias-cluster-randomized-trials.html}).
Here we demonstrate how to reduce the bias, and also how bias can emerge
in the analysis of a cluster randomized trial.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define estimators that can be repeated in the simulation below}
\NormalTok{estC0 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm, }\AttributeTok{label =} \StringTok{"C0: Ignores Clusters, IID SE"}\NormalTok{)}
\NormalTok{estC1 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster, }\AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"C1: Ignores Clusters, CR2 SE"}\NormalTok{)}
\NormalTok{estC2 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"stata"}\NormalTok{, }\AttributeTok{label =} \StringTok{"C2: OLS Clusters, Stata RCSE"}
\NormalTok{)}
\NormalTok{estC3 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ difference\_in\_means,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{label =} \StringTok{"C3: Diff Means Cluster, CR2 SE"}
\NormalTok{)}
\NormalTok{estC4 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"CR2"}\NormalTok{, }\AttributeTok{label =} \StringTok{"C4: OLS Cluster, CR2 SE"}
\NormalTok{)}
\NormalTok{estC5 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ horvitz\_thompson,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{simple =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{condition\_prs =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{label =} \StringTok{"C5: Horvitz{-}Thompson Cluster, Young SE"}
\NormalTok{)}
\NormalTok{estC6 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand, }\AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{weights =}\NormalTok{ nb,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"CR2"}\NormalTok{, }\AttributeTok{label =} \StringTok{"C6: OLS Clusters with ClusterSize Weights, CR2 RCSE"}
\NormalTok{)}

\NormalTok{estC7 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster }\SpecialCharTok{+}\NormalTok{ nb,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand,}
  \AttributeTok{model =}\NormalTok{ lm\_robust, }\AttributeTok{weights =}\NormalTok{ varweight,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"CR2"}\NormalTok{,}
  \AttributeTok{label =} \StringTok{"C7: OLS Clusters with Weights, CR2 RCSE"}
\NormalTok{)}

\NormalTok{estC8 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster }\SpecialCharTok{+}\NormalTok{ nb,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand,}
  \AttributeTok{model =}\NormalTok{ lm\_robust,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"CR2"}\NormalTok{,}
  \AttributeTok{label =} \StringTok{"C8: OLS Clusters with adj for cluster size, CR2 RCSE"}
\NormalTok{)}

\NormalTok{estC9 }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Zcluster,}
  \AttributeTok{inquiry =}\NormalTok{ theestimand,}
  \AttributeTok{model =}\NormalTok{ lm\_lin, }\AttributeTok{covariates =} \SpecialCharTok{\textasciitilde{}}\NormalTok{nb,}
  \AttributeTok{clusters =}\NormalTok{ cluster, }\AttributeTok{se\_type =} \StringTok{"CR2"}\NormalTok{,}
  \AttributeTok{label =} \StringTok{"C9: OLS Clusters with adj for cluster size, CR2 RCSE"}
\NormalTok{)}
\CommentTok{\# estC10 \textless{}{-} declare\_estimator(Y\textasciitilde{}Zcluster, inquiry=theestimand,}
\CommentTok{\#              model=lm\_robust, weights= ipr(Zcluster,falsestratum,clusterF),}
\CommentTok{\#              clusters=cluster, se\_type="CR2",}
\CommentTok{\#              label="C10: OLS Clusters with IPR Weights, CR2 RCSE")}


\NormalTok{bt }\OtherTok{\textless{}{-}} \FunctionTok{balanceTest}\NormalTok{(Zcluster }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Y }\SpecialCharTok{+} \FunctionTok{cluster}\NormalTok{(cluster), }\AttributeTok{data =}\NormalTok{ datCluster)}
\NormalTok{bt0 }\OtherTok{\textless{}{-}} \FunctionTok{balanceTest}\NormalTok{(Zcluster }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Y, }\AttributeTok{data =}\NormalTok{ datCluster)}

\NormalTok{theestimatorsC }\OtherTok{\textless{}{-}} \FunctionTok{ls}\NormalTok{(}\AttributeTok{patt =} \StringTok{"\^{}estC[0{-}9]"}\NormalTok{)}
\NormalTok{theestimatorsC}

\NormalTok{checkestC }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(theestimatorsC, }\ControlFlowTok{function}\NormalTok{(x) \{}
  \FunctionTok{message}\NormalTok{(x)}
  \FunctionTok{get}\NormalTok{(x)(}\FunctionTok{as.data.frame}\NormalTok{(datCluster))[}\FunctionTok{c}\NormalTok{(}\StringTok{"estimate"}\NormalTok{, }\StringTok{"std.error"}\NormalTok{)]}
\NormalTok{\})}
\NormalTok{checkestC}

\NormalTok{thedesignClusterPlusEstimators }\OtherTok{\textless{}{-}}\NormalTok{ thedesignCluster }\SpecialCharTok{+}
\NormalTok{  estC0 }\SpecialCharTok{+}\NormalTok{ estC1 }\SpecialCharTok{+}\NormalTok{ estC2 }\SpecialCharTok{+}\NormalTok{ estC3 }\SpecialCharTok{+}\NormalTok{ estC4 }\SpecialCharTok{+}\NormalTok{ estC5 }\SpecialCharTok{+}\NormalTok{ estC6 }\SpecialCharTok{+}\NormalTok{ estC7 }\SpecialCharTok{+}\NormalTok{ estC8 }\SpecialCharTok{+}\NormalTok{ estC9 }\CommentTok{\#+ estC10}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims }\OtherTok{\textless{}{-}} \DecValTok{200}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{thediagnosisCluster }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(thedesignClusterPlusEstimators, }\AttributeTok{sims =}\NormalTok{ sims, }\AttributeTok{bootstrap\_sims =} \DecValTok{0}\NormalTok{)}
\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisCluster)[, diagcols]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                                              Estimator     Term Mean Estimand Mean Estimate
1                          C0: Ignores Clusters, IID SE Zcluster     -12900.57     -15166.65
2                          C1: Ignores Clusters, CR2 SE Zcluster     -12900.57     -15166.65
3                          C2: OLS Clusters, Stata RCSE Zcluster     -12900.57     -15166.65
4                        C3: Diff Means Cluster, CR2 SE Zcluster     -12900.57     -15166.65
5                               C4: OLS Cluster, CR2 SE Zcluster     -12900.57     -15166.65
6                C5: Horvitz-Thompson Cluster, Young SE Zcluster     -12900.57     -12710.34
7   C6: OLS Clusters with ClusterSize Weights, CR2 RCSE Zcluster     -12900.57     -12670.05
8               C7: OLS Clusters with Weights, CR2 RCSE Zcluster     -12900.57     -19047.82
9  C8: OLS Clusters with adj for cluster size, CR2 RCSE Zcluster     -12900.57     -19120.43
10 C9: OLS Clusters with adj for cluster size, CR2 RCSE Zcluster     -12900.57      61051.64
       Bias SD Estimate      RMSE Power
1  -2266.08     5916.55   6321.84  1.00
2  -2266.08     5916.55   6321.84  1.00
3  -2266.08     5916.55   6321.84  0.76
4  -2266.08     5916.55   6321.84  0.32
5  -2266.08     5916.55   6321.84  0.32
6    190.23     5595.09   5584.33  0.32
7    230.51     5931.54   5921.18  0.24
8  -6147.26     6717.76   9093.48  0.24
9  -6219.86     6709.44   9136.65  0.26
10 73952.20   124497.09 144537.04  0.06
\end{verbatim}

The results of our simulation using 200 simulations show how certain
approaches can yield very biased estimates and other approaches can
reduce the bias. The C5 and C6 estimators have the lowest bias in this
particular example with very few clusters. We also see the problems with
the standard errors --- the actual standard errors (in ``SD Estimate'')
should be much higher than those estimated by the approaches which
ignore the clustered design (C0 and C1).

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# See https://haozhu233.github.io/kableExtra/awesome\_table\_in\_html.html}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{reshape\_diagnosis}\NormalTok{(thediagnosisCluster)[, diagcols]) }\CommentTok{\# \%\textgreater{}\% kable\_styling() \%\textgreater{}\% scroll\_box(width = "100\%", height = "800px")}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l}
\hline
Estimator & Term & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power\\
\hline
C0: Ignores Clusters, IID SE & Zcluster & -12900.57 & -15166.65 & -2266.08 & 5916.55 & 6321.84 & 1.00\\
\hline
C1: Ignores Clusters, CR2 SE & Zcluster & -12900.57 & -15166.65 & -2266.08 & 5916.55 & 6321.84 & 1.00\\
\hline
C2: OLS Clusters, Stata RCSE & Zcluster & -12900.57 & -15166.65 & -2266.08 & 5916.55 & 6321.84 & 0.76\\
\hline
C3: Diff Means Cluster, CR2 SE & Zcluster & -12900.57 & -15166.65 & -2266.08 & 5916.55 & 6321.84 & 0.32\\
\hline
C4: OLS Cluster, CR2 SE & Zcluster & -12900.57 & -15166.65 & -2266.08 & 5916.55 & 6321.84 & 0.32\\
\hline
C5: Horvitz-Thompson Cluster, Young SE & Zcluster & -12900.57 & -12710.34 & 190.23 & 5595.09 & 5584.33 & 0.32\\
\hline
C6: OLS Clusters with ClusterSize Weights, CR2 RCSE & Zcluster & -12900.57 & -12670.05 & 230.51 & 5931.54 & 5921.18 & 0.24\\
\hline
C7: OLS Clusters with Weights, CR2 RCSE & Zcluster & -12900.57 & -19047.82 & -6147.26 & 6717.76 & 9093.48 & 0.24\\
\hline
C8: OLS Clusters with adj for cluster size, CR2 RCSE & Zcluster & -12900.57 & -19120.43 & -6219.86 & 6709.44 & 9136.65 & 0.26\\
\hline
C9: OLS Clusters with adj for cluster size, CR2 RCSE & Zcluster & -12900.57 & 61051.64 & 73952.20 & 124497.09 & 144537.04 & 0.06\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simdesigns }\OtherTok{\textless{}{-}} \FunctionTok{get\_simulations}\NormalTok{(thediagnosis)}
\DocumentationTok{\#\# simdesigns \textless{}{-} simulate\_design(thedesign,sims=sims)}
\NormalTok{simmeans }\OtherTok{\textless{}{-}}\NormalTok{ simdesigns }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(estimator) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{expest =} \FunctionTok{mean}\NormalTok{(estimate))}
\end{Highlighting}
\end{Shaded}

The following plot shows many of the estimators produce results far from
the truth (shown by the vertical black bar), and also shows the
diversity in precision of the estimators.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Now compare to better behaved outcomes.}
\NormalTok{gDiagClust }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simdesigns, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ estimate, }\AttributeTok{color =}\NormalTok{ estimator)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ trueATE1) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ simmeans, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ expest, }\AttributeTok{y =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)), }\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \DecValTok{6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\CommentTok{\#+}
\CommentTok{\# theme(legend.position = c(.9,.8))}
\FunctionTok{print}\NormalTok{(gDiagClust)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/clusterresultsplot-1}

\hypertarget{incorrect-false-positive-rates-from-tests-and-confidence-intervals}{%
\subsection{Incorrect false positive rates from tests and confidence
intervals}\label{incorrect-false-positive-rates-from-tests-and-confidence-intervals}}

When we have few clusters, analytic standard errors such as those used
by \texttt{difference\_in\_means} and \texttt{lm\_robust} may lead to
incorrect false positive rates for our hypothesis tests or confidence
intervals. We demonstrate how adjusting for cluster-randomization can
help ensure that the false positive rates of our hypothesis tests is
controlled/known, we also discuss the limitations of these approaches.
The next code block compares the false positive rates of two different
approaches to adjusting standard errors in a cluster randomized trial.

To distinguish between the problems of bias arising from unequal sized
clusters and problems of false positive rates or covereage arising from
the fact that we have fewer clusters than units, we use a design with
equal numbers of units per cluster:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(dat1, }\FunctionTok{table}\NormalTok{(Zcluster, buildingID))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        buildingID
Zcluster  1  2  3  4  5  6  7  8  9 10
       0 10  0 10 10  0  0  0  0 10 10
       1  0 10  0  0 10 10 10 10  0  0
\end{verbatim}

In this case, with equal sized clusters, a simple outcome, and equal
numbers of clusters in treatment and control, we see that the CR2
standard error controls the false positive rate (\textbf{less than} 5\%
of the 1000 simulations testing a true null hypothesis of no effects
return a \(p\)-value of less than .05) while the ``Stata'' standard
error has a slightly too high false positive rate of
\texttt{r\ fprateStata05} at the 5\% error level. We also saw above that
not controlling at all yields very poor coverage (see the rows for C0
and C1) --- and we saw that the ``Stata'' approach has poor coverage
relative to the CR2 based approaches as well, in this case with only 10
clusters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{checkFP }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(dat, }\AttributeTok{setype =} \StringTok{"CR2"}\NormalTok{) \{}
  \DocumentationTok{\#\# Break any relationship between treatment and outcomes by permuting}
  \DocumentationTok{\#\# or shuffling the treatment variable. This means that H0,  the null,}
  \DocumentationTok{\#\# of no effects is true.}
\NormalTok{  dat}\SpecialCharTok{$}\NormalTok{newZ }\OtherTok{\textless{}{-}} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ dat}\SpecialCharTok{$}\NormalTok{buildingID)}
\NormalTok{  newest }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ newZ, }\AttributeTok{dat =}\NormalTok{ dat, }\AttributeTok{clusters =}\NormalTok{ buildingID, }\AttributeTok{se\_type =}\NormalTok{ setype)}
  \FunctionTok{return}\NormalTok{(}\AttributeTok{nullp =}\NormalTok{ newest}\SpecialCharTok{$}\NormalTok{p.value[}\StringTok{"newZ"}\NormalTok{])}
\NormalTok{\}}

\NormalTok{smalldat }\OtherTok{\textless{}{-}}\NormalTok{ dat1[, }\FunctionTok{c}\NormalTok{(}\StringTok{"Y"}\NormalTok{, }\StringTok{"buildingID"}\NormalTok{)]}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{fpresCR2 }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\FunctionTok{checkFP}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ smalldat))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{fpresStata }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\FunctionTok{checkFP}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ smalldat, }\AttributeTok{setype =} \StringTok{"stata"}\NormalTok{))}
\NormalTok{fprateCR205 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(fpresCR2 }\SpecialCharTok{\textless{}=}\NormalTok{ .}\DecValTok{05}\NormalTok{)}
\NormalTok{fprateCR205}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.045
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fprateStata05 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(fpresStata }\SpecialCharTok{\textless{}=}\NormalTok{ .}\DecValTok{05}\NormalTok{)}
\NormalTok{fprateStata05}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.054
\end{verbatim}

The following plot shows that, in this case the Stata standard error
tends to make slightly too many false positive errors (shown by open
circles above the 45 degree line) and the CR2 standard error tends
control the error rate of the test (with black dots below the 45 degree
line).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{ecdf}\NormalTok{(fpresCR2), }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{ecdf}\NormalTok{(fpresStata), }\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/plotfpr-1}

When a simulation like the above shows false positive rate problems with
the CR2 standard error, we then use permutation-based randomization
inference (rather than the asymptotic justified randomization inference
of the CR2 standard error).

{[}TO DO: An example using permutation based inference and its false
positive rate{]}.

\hypertarget{poweranalysis}{%
\chapter{Power Analysis}\label{poweranalysis}}

In this section we provide examples of how we assess statistical power
for different experimental research designs. We often prefer to use
simulation to assess the power of different research designs because we
rarely have designs that fit easily into the assumptions made by
analytic tools.

However, for the sake of an example, we will show a version that uses
simulation that produces the same answer as the faster analytic version.

Imagine that we thought that a study would have an effect of about 1
standard deviation -- this is more or less the effect difference we have
created in our example dataset so far. How large a study do we need in
order to distinguish this effect from noise?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{population }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(dat1)}
\NormalTok{potentials }\OtherTok{\textless{}{-}} \FunctionTok{declare\_potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z }\SpecialCharTok{*}\NormalTok{ y1 }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Z) }\SpecialCharTok{*}\NormalTok{ y0)}

\NormalTok{assignment }\OtherTok{\textless{}{-}} \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{complete\_ra}\NormalTok{(N))}
\NormalTok{reveal }\OtherTok{\textless{}{-}} \FunctionTok{declare\_reveal}\NormalTok{(Y, Z)}
\NormalTok{design }\OtherTok{\textless{}{-}}\NormalTok{ population }\SpecialCharTok{+}\NormalTok{ potentials }\SpecialCharTok{+}\NormalTok{ assignment }\SpecialCharTok{+}\NormalTok{ reveal}

\NormalTok{simdat1 }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(design)}

\CommentTok{\# Notice that we have new potential outcomes called Y\_Z\_1 and Y\_Z\_0 that are}
\CommentTok{\# copies of y0 and y1}
\FunctionTok{stopifnot}\NormalTok{(}\FunctionTok{with}\NormalTok{(simdat1, }\FunctionTok{cor}\NormalTok{(y0, Y\_Z\_0)) }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}

\NormalTok{estimand }\OtherTok{\textless{}{-}} \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0))}
\NormalTok{estimator }\OtherTok{\textless{}{-}} \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =}\NormalTok{ estimand, }\AttributeTok{label =} \StringTok{"Simple D{-}I{-}M"}\NormalTok{)}

\CommentTok{\# We can see how the estimator function works using some data simulated based on}
\CommentTok{\# the design}
\FunctionTok{estimator}\NormalTok{(simdat1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     estimator term estimate std.error statistic   p.value conf.low conf.high df outcome inquiry
1 Simple D-I-M    Z    5.571    0.8153     6.834 7.069e-10    3.953     7.189 98       Y     ATE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{designPlusEst }\OtherTok{\textless{}{-}}\NormalTok{ design }\SpecialCharTok{+}\NormalTok{ estimand }\SpecialCharTok{+}\NormalTok{ estimator}
\end{Highlighting}
\end{Shaded}

Now that the setup is complete, we can assess the statistical power of
our proposed design with \(N=100\) and an effect of roughly 1 SD. The
output below shows the statistical power as well as the false positive
rate (called ``Coverage'' below) as well as the difference between the
mean difference we calculate and the true average treatment effect
(called ``Bias'' below).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{diagnose\_design}\NormalTok{(designPlusEst, }\AttributeTok{sims =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Research design diagnosis based on 1000 simulations. Diagnosis completed in 13 secs. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates).

        Design Inquiry    Estimator Outcome Term N Sims Mean Estimand Mean Estimate   Bias
 designPlusEst     ATE Simple D-I-M       Y    Z   1000          5.45          5.47   0.02
                                                               (0.00)        (0.02) (0.02)
 SD Estimate   RMSE  Power Coverage
        0.71   0.71   1.00     0.97
      (0.02) (0.02) (0.00)   (0.01)
\end{verbatim}

The analytic approach suggests more power than the simulation based
approach -- a difference that we suspect arises from our fairly skewed
outcome.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{power.t.test}\NormalTok{(}\AttributeTok{n =} \DecValTok{100}\NormalTok{, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

     Two-sample t test power calculation 

              n = 100
          delta = 1
             sd = 1
      sig.level = 0.05
          power = 1
    alternative = two.sided

NOTE: n is number in *each* group
\end{verbatim}

For ways to compare different sample sizes, effect sizes, etc. see
\href{https://declaredesign.org/blog/2018-10-02-power-strategies.html}{more
information from the DeclareDesign package}.

\hypertarget{an-example-of-the-off-the-shelf-approach}{%
\section{An example of the off-the-shelf
approach}\label{an-example-of-the-off-the-shelf-approach}}

To demonstrate how a power analysis might work in principle, consider
another example using the R function \texttt{power.t.test()}.

When using this function, there are three parameters that we're most
concerned with, two of which are specified by the user, and the third of
which is then calculated and returned by the function. These are:

\begin{itemize}
\tightlist
\item
  \texttt{n} = sample size, or number of observations;,
\item
  \texttt{delta} = the target effect size, or a minimum detectable
  effect (MDE); and
\item
  \texttt{power} = the probability of detecting an effect if in fact
  there is a true effect of size \texttt{delta}.
\end{itemize}

Say, for example, you want to know the MDE for a two-arm study with
1,000 participants. Using \texttt{power.t.test()} you would specify:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{power.t.test}\NormalTok{(}
  \AttributeTok{n =} \DecValTok{500}\NormalTok{, }\CommentTok{\# n denotes the number of obs. per treatment arm}
  \AttributeTok{power =} \FloatTok{0.8} \CommentTok{\# use traditional power threshold of 80\%}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

     Two-sample t test power calculation 

              n = 500
          delta = 0.1774
             sd = 1
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

NOTE: n is number in *each* group
\end{verbatim}

If we wanted to extract the MDE we could write:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{power.t.test}\NormalTok{(}
  \AttributeTok{n =} \DecValTok{500}\NormalTok{, }\CommentTok{\# number of obs. per treatment arm}
  \AttributeTok{power =} \FloatTok{0.8} \CommentTok{\# traditional power threshold of 80\%}
\NormalTok{)}\SpecialCharTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1774
\end{verbatim}

We can similarly extract other parameters, like sample size and power,
using \texttt{\$n} or \texttt{\$power} instead of \texttt{\$delta}. If
you need to, you can adjust other parameters, like the standard
deviation of the response, the level of the test, or whether the test is
one-sided rather than two-sided. There are also other functions
available for different types of outcomes. For example, if you have a
binary response, you can use \texttt{power.prop.test()} to calculate
power for a difference in proportions test.

An equivalent approach in Stata is as follows:

\begin{verbatim}
power twomeans 0, power(0.8) n(1000) sd(1)
\end{verbatim}

Stata users can learn more about available tools by checking out Stata's
plethora of
\href{https://www.stata.com/features/power-and-sample-size/}{relevant
help files}.

\hypertarget{an-example-of-the-simulation-approach}{%
\section{An example of the simulation
approach}\label{an-example-of-the-simulation-approach}}

We can compare this approach with \texttt{power.t.test()} to the output
from a computational approach, which we define in the code chunk below.
Results are shown in the subsequent Figure XXXX. Though clearly the
computational estimates are slightly different, they comport quite well
with the analytic estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Workflow for power simulation toolkit:}
\CommentTok{\# Replicate, Estimate, Evaluate (REE)}
\CommentTok{\#}
\CommentTok{\# replicate\_design(...) {-}{-}{-}: Generate multiple replicates of a}
\CommentTok{\#                             a simulated d.g.p. + treatment assignment.}
\CommentTok{\# estimate(...) {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}: Estimate the null test{-}stat for treatment(s).}
\CommentTok{\# evaluate\_power(...) {-}{-}{-}{-}{-}: Evaluate power to detect non{-}zero effects.}
\CommentTok{\# evaluate\_mde(...) {-}{-}{-}{-}{-}{-}{-}: Find MDE, searching over range of effect sizes.}
\CommentTok{\# evaluate\_bias(...) {-}{-}{-}{-}{-}{-}: Compute bias and other diagnostics.}

\DocumentationTok{\#\#\#\#\# REPLICATE a design \#\#\#\#\#}

\NormalTok{replicate\_design }\OtherTok{\textless{}{-}}
  \ControlFlowTok{function}\NormalTok{(}\AttributeTok{R =} \DecValTok{200}\NormalTok{, ...) \{}
\NormalTok{    design }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
      \CommentTok{\# require(magrittr)}
      \CommentTok{\# require(fabricatr)}
\NormalTok{      fabricatr}\SpecialCharTok{::}\FunctionTok{fabricate}\NormalTok{(}
\NormalTok{        ...}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{list}\NormalTok{()}
\NormalTok{    \}}
\NormalTok{    rep }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}
      \AttributeTok{n =}\NormalTok{ R,}
      \AttributeTok{expr =} \FunctionTok{design}\NormalTok{()}
\NormalTok{    )}

    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(rep)) \{}
\NormalTok{      rep[[i]] }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{        dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
          \AttributeTok{sim =}\NormalTok{ i}
\NormalTok{        )}
\NormalTok{    \}}
    \FunctionTok{return}\NormalTok{(rep)}
\NormalTok{  \}}

\DocumentationTok{\#\#\#\#\# ESTIMATE the null \#\#\#\#\#}

\NormalTok{estimate }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}
\NormalTok{    formula, vars, }\AttributeTok{data =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{estimator =}\NormalTok{ estimatr}\SpecialCharTok{::}\NormalTok{lm\_robust) \{}
  \CommentTok{\#  require(magrittr)}
\NormalTok{  data }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    purrr}\SpecialCharTok{::}\FunctionTok{map}\NormalTok{(}
      \SpecialCharTok{\textasciitilde{}} \FunctionTok{estimator}\NormalTok{(}
\NormalTok{        formula,}
        \AttributeTok{data =}\NormalTok{ .}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{        estimatr}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{        dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}
\NormalTok{          .data}\SpecialCharTok{$}\NormalTok{term }\SpecialCharTok{\%in\%}\NormalTok{ vars}
\NormalTok{        )}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{bind\_rows}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{sim =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(data), }\AttributeTok{each =} \FunctionTok{n}\NormalTok{() }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(data)),}
      \AttributeTok{term =} \FunctionTok{factor}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{term, }\AttributeTok{levels =}\NormalTok{ vars)}
\NormalTok{    )}
\NormalTok{\}}

\DocumentationTok{\#\#\#\#\# EVALUATE power \#\#\#\#\#}

\NormalTok{evaluate\_power }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, delta, }\AttributeTok{level =} \FloatTok{0.05}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{missing}\NormalTok{(delta)) \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"Specify \textquotesingle{}delta\textquotesingle{} to proceed."}\NormalTok{)}
\NormalTok{  \}}
  \CommentTok{\#  require(foreach)}
  \CommentTok{\#  require(magrittr)}

\NormalTok{  foreach}\SpecialCharTok{::}\FunctionTok{foreach}\NormalTok{(}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(delta),}
    \AttributeTok{.combine =} \StringTok{"bind\_rows"}
\NormalTok{  ) }\SpecialCharTok{\%do\%}
\NormalTok{    \{}
\NormalTok{      data }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{        dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
          \AttributeTok{delta =}\NormalTok{ delta[i],}
          \AttributeTok{new\_statistic =}\NormalTok{ (.data}\SpecialCharTok{$}\NormalTok{estimate }\SpecialCharTok{+}\NormalTok{ .data}\SpecialCharTok{$}\NormalTok{delta) }\SpecialCharTok{/}\NormalTok{ .data}\SpecialCharTok{$}\NormalTok{std.error}
\NormalTok{        ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{        dplyr}\SpecialCharTok{::}\FunctionTok{group\_split}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{term) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{        purrr}\SpecialCharTok{::}\FunctionTok{map}\NormalTok{(}
          \SpecialCharTok{\textasciitilde{}}\NormalTok{ \{}
\NormalTok{            tibble}\SpecialCharTok{::}\FunctionTok{tibble}\NormalTok{(}
              \AttributeTok{term =}\NormalTok{ .}\SpecialCharTok{$}\NormalTok{term,}
              \AttributeTok{delta =}\NormalTok{ .}\SpecialCharTok{$}\NormalTok{delta,}
              \AttributeTok{p.value =} \FunctionTok{foreach}\NormalTok{(}
                \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(.}\SpecialCharTok{$}\NormalTok{new\_statistic),}
                \AttributeTok{.combine =} \StringTok{"c"}
\NormalTok{              ) }\SpecialCharTok{\%do\%} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(.}\SpecialCharTok{$}\NormalTok{statistic) }\SpecialCharTok{\textgreater{}=}
                \FunctionTok{abs}\NormalTok{(.}\SpecialCharTok{$}\NormalTok{new\_statistic[j]))}
\NormalTok{            )}
\NormalTok{          \}}
\NormalTok{        )}
\NormalTok{    \} }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{term, .data}\SpecialCharTok{$}\NormalTok{delta) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}
      \AttributeTok{power =} \FunctionTok{mean}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{p.value }\SpecialCharTok{\textless{}=}\NormalTok{ level),}
      \AttributeTok{.groups =} \StringTok{"drop"}
\NormalTok{    )}
\NormalTok{\}}

\DocumentationTok{\#\#\#\#\# EVALUATE Min. Detectable Effect \#\#\#\#\#}

\NormalTok{evaluate\_mde }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}
\NormalTok{    data,}
    \AttributeTok{delta\_range =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \AttributeTok{how\_granular =} \FloatTok{0.01}\NormalTok{,}
    \AttributeTok{level =} \FloatTok{0.05}\NormalTok{,}
    \AttributeTok{min\_power =} \FloatTok{0.8}\NormalTok{) \{}
\NormalTok{  eval }\OtherTok{\textless{}{-}} \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{data =}\NormalTok{ data,}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(delta\_range[}\DecValTok{1}\NormalTok{], delta\_range[}\DecValTok{2}\NormalTok{], how\_granular),}
    \AttributeTok{level =}\NormalTok{ level}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(}
\NormalTok{      .data}\SpecialCharTok{$}\NormalTok{term}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{summarize}\NormalTok{(}
      \AttributeTok{MDE =} \FunctionTok{min}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{delta[.data}\SpecialCharTok{$}\NormalTok{power }\SpecialCharTok{\textgreater{}=}\NormalTok{ min\_power]),}
      \AttributeTok{.groups =} \StringTok{"drop"}
\NormalTok{    )}
  \FunctionTok{return}\NormalTok{(eval)}
\NormalTok{\}}

\DocumentationTok{\#\#\#\#\# EVALUATE Bias \#\#\#\#\#}

\NormalTok{evaluate\_bias }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}
\NormalTok{    data,}
    \AttributeTok{ATE =} \DecValTok{0}\NormalTok{) \{}
  \CommentTok{\# require(magrittr)}
\NormalTok{  smry }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{ATE =} \FunctionTok{rep}\NormalTok{(ATE, }\AttributeTok{len =} \FunctionTok{n}\NormalTok{())}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(}
\NormalTok{      .data}\SpecialCharTok{$}\NormalTok{term}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{summarize}\NormalTok{(}
      \StringTok{"True ATE"} \OtherTok{=} \FunctionTok{unique}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{ATE),}
      \StringTok{"Mean Estimate"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{estimate),}
      \AttributeTok{Bias =} \FunctionTok{mean}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{estimate }\SpecialCharTok{{-}}\NormalTok{ .data}\SpecialCharTok{$}\NormalTok{ATE),}
      \AttributeTok{MSE =} \FunctionTok{mean}\NormalTok{((.data}\SpecialCharTok{$}\NormalTok{estimate }\SpecialCharTok{{-}}\NormalTok{ .data}\SpecialCharTok{$}\NormalTok{ATE)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
      \AttributeTok{Covarage =} \FunctionTok{mean}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{conf.low }\SpecialCharTok{\textless{}=}\NormalTok{ .data}\SpecialCharTok{$}\NormalTok{ATE }\SpecialCharTok{\&}
\NormalTok{        .data}\SpecialCharTok{$}\NormalTok{conf.high }\SpecialCharTok{\textgreater{}=}\NormalTok{ .data}\SpecialCharTok{$}\NormalTok{ATE),}
      \StringTok{"SD of Estimates"} \OtherTok{=} \FunctionTok{sd}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{estimate),}
      \StringTok{"Mean SE"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{std.error),}
      \AttributeTok{Power =} \FunctionTok{mean}\NormalTok{(.data}\SpecialCharTok{$}\NormalTok{p.value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{),}
      \AttributeTok{.groups =} \StringTok{"drop"}
\NormalTok{    )}
  \FunctionTok{return}\NormalTok{(smry)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{d }\OtherTok{\textless{}{-}} \FloatTok{0.2}

\NormalTok{power\_data }\OtherTok{\textless{}{-}}
  \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{d =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{),}
    \AttributeTok{power =} \FunctionTok{power.t.test}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{delta =}\NormalTok{ d)}\SpecialCharTok{$}\NormalTok{power}
\NormalTok{  )}

\CommentTok{\# save plot; later add simulation results}
\NormalTok{g }\OtherTok{\textless{}{-}}
  \FunctionTok{ggplot}\NormalTok{(power\_data) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(d, power, }\AttributeTok{linetype =} \StringTok{"power.t.test()"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(delta),}
    \AttributeTok{y =} \StringTok{"Power"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Power for Simple Difference in Means Test"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}
    \AttributeTok{n.breaks =} \DecValTok{6}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}
    \AttributeTok{yintercept =} \FloatTok{0.8}\NormalTok{,}
    \AttributeTok{col =} \StringTok{"grey25"}\NormalTok{,}
    \AttributeTok{alpha =} \DecValTok{08}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  ggridges}\SpecialCharTok{::}\FunctionTok{theme\_ridges}\NormalTok{(}
    \AttributeTok{center\_axis\_labels =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{font\_size =} \DecValTok{10}
\NormalTok{  )}

\CommentTok{\# Add results from simulation to compare}

\NormalTok{sim\_power\_data }\OtherTok{\textless{}{-}}
  \FunctionTok{replicate\_design}\NormalTok{(}
    \AttributeTok{N =}\NormalTok{ n,}
    \AttributeTok{y =} \FunctionTok{rnorm}\NormalTok{(N),}
    \AttributeTok{x =}\NormalTok{ randomizr}\SpecialCharTok{::}\FunctionTok{complete\_ra}\NormalTok{(}
\NormalTok{      N,}
      \AttributeTok{m =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{estimate}\NormalTok{(}
    \AttributeTok{form =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{vars =} \StringTok{"x"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{  )}

\NormalTok{g }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}
    \AttributeTok{data =}\NormalTok{ sim\_power\_data,}
    \FunctionTok{aes}\NormalTok{(delta, power, }\AttributeTok{linetype =} \StringTok{"simulation"}\NormalTok{),}
    \AttributeTok{color =} \StringTok{"grey25"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{linetype =} \StringTok{"Method:"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"bottom"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/powersimvsanalytic-1}

Figure 1. Off-the-shelf versus simulation power estimates

We produce these computational estimates using some helpful tools
currently housed in OES's GitHub
\href{https://github.com/gsa-oes/code_library/blob/master/power_simulation/power_simulation_tools.R}{code
library} and in the chunk above.

These tools are designed around a simple workflow, and remove some of
the programming required to calculate power computationally.

These tools are centered around the following workflow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replicate
\item
  Estimate\\
\item
  Evaluate
\end{enumerate}

The first step in the workflow, \emph{Replicate}, entails designing a
data-generating process (which may include only an outcome variable and
treatment assignment) and simulating this process multiple times to
create randomly drawn datasets from a population. Each of these is a
\emph{sample replicate}.

The next step, \emph{Estimate}, entails estimating effects for select
treatments under the null hypothesis for each sample replicate. This
provides a distribution of test statistics under the null hypothesis.

Finally, the last step, \emph{Evaluate}, entails evaluating power to
detect an effect over a range of alternative effect sizes.

This workflow is supported by three functions:
\texttt{replicate\_design()}, \texttt{estimate()}, and
\texttt{evaluate\_power()}. Here's the script used to generate the
computational estimates shown in Figure 1:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1. Replicate:}

\NormalTok{rep }\OtherTok{\textless{}{-}} \FunctionTok{replicate\_design}\NormalTok{(}
  \AttributeTok{R =} \DecValTok{200}\NormalTok{, }\CommentTok{\# Number of sample replicates}
  \AttributeTok{N =} \DecValTok{1000}\NormalTok{, }\CommentTok{\# Sample size of each replicate}
  \AttributeTok{y =} \FunctionTok{rnorm}\NormalTok{(N), }\CommentTok{\# Normally distributed response}
  \AttributeTok{x =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\CommentTok{\# Binary treatment indicator}
\NormalTok{)}

\CommentTok{\# 2. Estimate:}

\NormalTok{est }\OtherTok{\textless{}{-}} \FunctionTok{estimate}\NormalTok{(}
\NormalTok{  y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x,}
  \AttributeTok{vars =} \StringTok{"x"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ rep}
\NormalTok{)}

\CommentTok{\# 3. Evaluate:}

\NormalTok{pwr\_eval\_sim }\OtherTok{\textless{}{-}} \FunctionTok{evaluate\_power}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ est,}
  \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The final product of this approach, the object \texttt{pwr\_eval\_sim},
reports the power for each of the user-specified effect sizes
(\texttt{delta}) for each of the model terms specified by the vars
command in the \texttt{estimate()} function. The output can be used to
plot power curves or to compute minimum detectable effects.

This approach makes computational power analysis vastly more efficient
from a programming perspective, while also providing ample room for
flexibility in both design and estimation strategy. For example,
\texttt{replicate\_design()} is a wrapper for \texttt{fabricate()} in
the \href{https://declaredesign.org/r/fabricatr/}{fabricatr} package.
This gives users the ability to generate multi-level or nested
data-generating processes, specify covariates, or determine whether
treatment randomization is done within blocks or by clusters.
Additionally, by default, estimates are returned using
\texttt{lm\_robust()} from the
\href{https://declaredesign.org/r/estimatr/}{estimatr} package, but
alternative estimators can be specified. Say, for example, you have a
binary response and a set of covariates and your design calls for using
logistic regression. You can generate estimates for such a design as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logit }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(...) \{}
  \FunctionTok{glm}\NormalTok{(..., }\AttributeTok{family =}\NormalTok{ binomial)}
\NormalTok{\}}
\NormalTok{est }\OtherTok{\textless{}{-}} \FunctionTok{estimate}\NormalTok{(}
\NormalTok{  y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ z1 }\SpecialCharTok{+}\NormalTok{ z2,}
  \AttributeTok{data =}\NormalTok{ rep, }\AttributeTok{estimator =}\NormalTok{ logit}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

These tools, in short, while imposing a particular workflow, provide
significant latitude in terms of design and estimation. However, other
tools exist as well.
\href{https://declaredesign.org/r/declaredesign/articles/DeclareDesign_101.html}{DeclareDesign}
provides useful tools, for example. And there is no shortage of
simulation examples online of a variety of research designs.

\hypertarget{when-to-use-which-approach}{%
\section{When to use which approach}\label{when-to-use-which-approach}}

Of course, for a simple difference in means test, the programming
required for an analytical solution is much much less involved than the
computational solution. When is the latter worth the extra investment?

In cases where we're interested in the power to detect a simple
difference in means, or a difference in proportions for binary
responses, it is probably sufficient to use \texttt{power.t.test()} (for
means) or \texttt{power.prop.test()} (for proportions).

However, OES projects often involve design features or analytic
strategies that are difficult to account for using off-the-shelf tools.
For example, we often include covariates in our statistical models when
we analyze outcomes in order to enhance the precision of our estimates
of treatment effects. If the gain in precision is small, then it might
not be important to account for this in power calculations in the design
phase of the project. However, if we expect a substantial gain in
precision due to including covariates, then we probably want to account
for this in our design. The natural way to do this is by simulation,
where we can include the covariates in the ``replicate'' and
``estimate'' steps. Accounting for covariates in this way is especially
useful if we can use real historical or pre-treatment data that
represent the correlations we expect to see between covariates and
outcomes in our later analysis of the trial data.

More complex design features or analytic strategies may make investing
in the simulation approach even more worthwhile, or downright necessary.
Examples include heterogeneity in treatment effects, a multi-arm or
factorial design, or block randomization with differing probabilities of
treatment between blocks -- none of which can practically be accounted
for with off-the-shelf tools. In the next section, we provide some
additional examples of simulations for more complex design features or
analytic strategies.

\hypertarget{additional-examples-of-the-simulation-approach}{%
\section{Additional examples of the simulation
approach}\label{additional-examples-of-the-simulation-approach}}

Here we provide two examples of research designs where simulation is
well worth the extra effort. Attendant R code is included in the
discussion to illustrate how to use tools in the code library to
streamline the approach.

\hypertarget{a-two-by-two-design-with-interaction}{%
\subsection{A two-by-two design with
interaction}\label{a-two-by-two-design-with-interaction}}

One instance where computational power analysis may be worth the
investment is in assessing power for a two-by-two factorial design with
an interaction. In such a design, the goal is to assess not only the
power to detect main effects (the average effect of each individual
treatment), but also power to detect a non-zero interaction effect
between the treatments.

Say we have a design with 1,000 observations and we would like to know
the effect of two treatments on a binary outcome with a baseline of
0.25. Each treatment is assigned to \(M = 500\) individuals at random,
resulting in four roughly equal sized groups of observations after
randomization: (1) a control group, (2) those assigned to treatment 1
but not treatment 2, (3) those assigned to treatment 2 but not treatment
1, and (4) those assigned to both treatment 1 and 2.

We can easily calculate power to detect the main effect of each
treatment, in addition to their interaction, using replication,
estimation, and evaluation as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{two\_by\_two }\OtherTok{\textless{}{-}}
  \CommentTok{\# Replicate a 2x2 design}
  \FunctionTok{replicate\_design}\NormalTok{(}
    \AttributeTok{N =} \DecValTok{1000}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
    \AttributeTok{x1 =} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\CommentTok{\# center treatment indicators}
    \AttributeTok{x2 =} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{/} \DecValTok{2}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# Estimate main and interaction effects}
  \FunctionTok{estimate}\NormalTok{(}
    \AttributeTok{form =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x1}\SpecialCharTok{:}\NormalTok{x2,}
    \AttributeTok{vars =} \FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x1:x2"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# Evaluate power}
  \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Using the output reported in the object \texttt{two\_by\_two}, we can
easily plot the power curves for each of the main effects and the
interaction effect, as shown in Figure 2.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(two\_by\_two) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(delta, power, }\AttributeTok{linetype =}\NormalTok{ term)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}
    \AttributeTok{yintercept =} \FloatTok{0.8}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"grey25"}\NormalTok{,}
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}
    \AttributeTok{n.breaks =} \DecValTok{6}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(delta),}
    \AttributeTok{y =} \StringTok{"Power"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Power for a 2x2 Design"}\NormalTok{,}
    \AttributeTok{linetype =} \StringTok{"Effect for..."}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  ggridges}\SpecialCharTok{::}\FunctionTok{theme\_ridges}\NormalTok{(}
    \AttributeTok{font\_size =} \DecValTok{10}\NormalTok{,}
    \AttributeTok{center\_axis\_labels =} \ConstantTok{TRUE}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"bottom"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Figure 2. Computational power analysis for a \(2\times 2\) design.

Of course, we could have relied on some reasonable analytical
assumptions to arrive at these estimates without resorting to simulation
(see a helpful discussion
\href{https://statmodeling.stat.columbia.edu/2018/03/15/need-16-times-sample-size-estimate-interaction-estimate-main-effect/}{here}),
but running a simulation saves us the trouble.

\hypertarget{covariate-adjustment-with-the-lin-estimator}{%
\subsection{Covariate adjustment with the Lin
estimator}\label{covariate-adjustment-with-the-lin-estimator}}

Another scenario where computational power analysis is worth the
investment is if a design calls for covariate adjustment. This is common
in OES projects, and, in several instances, the
\citet{lin_agnostic_2013} saturated estimator is the analytical solution
employed.

Devising an off-the-shelf method to calculate power for such a study is
possible, but would likely require investing time doing background
research to ensure its accuracy. Alternatively, we could simply
replicate, estimate, and evaluate such a design computationally. The
results will be just as accurate, without the added hassle of
programming the appropriate analytical solution.

Suppose we have a sample of 1,000 observations and a continuous outcome
variable. We wish to assess the effect of some policy intervention on
this continuous outcome. Our design calls for randomly assigning
\(M = 250\) individuals to receive the intervention, and the rest to
control.

In addition to having data on the outcome and on treatment assignment,
say that we also anticipate obtaining a dataset of covariates for our
1,000 observations. This data contains two variables that are prognostic
of the outcome. We'll call these \texttt{z1} and \texttt{z2}. The first
is a continuous measure; the latter a binary indicator. Our design calls
for adjusting for these covariates via the Lin estimator to improve the
precision of our estimated treatment effect. We can simulate such a
design, and further justify covariate adjustment, using the following
replication, estimation, and evaluation.

We begin by replicating the data-generating process:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rep\_data }\OtherTok{\textless{}{-}}
  \FunctionTok{replicate\_design}\NormalTok{(}
    \AttributeTok{N =} \DecValTok{1000}\NormalTok{,}
    \AttributeTok{z1 =} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{sd =} \DecValTok{3}\NormalTok{), }\CommentTok{\# continuous covariate}
    \AttributeTok{z2 =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, }\FloatTok{0.25}\NormalTok{), }\CommentTok{\# binary covariate}
    \AttributeTok{cz1 =}\NormalTok{ z1 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(z1), }\CommentTok{\# make mean centered versions of the covariates}
    \AttributeTok{cz2 =}\NormalTok{ z2 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(z2),}
    \AttributeTok{y =} \FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ z1 }\SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{*}\NormalTok{ z2 }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(N), }\CommentTok{\# simulate the data{-}generating process}
    \AttributeTok{x =} \FunctionTok{complete\_ra}\NormalTok{(N, }\AttributeTok{m =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{4}\NormalTok{) }\CommentTok{\# randomly assign 25\% of obs. to treatment}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We then estimate and evaluate. For comparison, power is computed both
with covariate adjustment via the Lin estimator and without covariate
adjustment:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# With the Lin Estimator}
\NormalTok{lin\_adjust }\OtherTok{\textless{}{-}}
\NormalTok{  rep\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{estimate}\NormalTok{(}
    \AttributeTok{form =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ z1 }\SpecialCharTok{+}\NormalTok{ z2 }\SpecialCharTok{+}\NormalTok{ x}\SpecialCharTok{:}\NormalTok{cz1 }\SpecialCharTok{+}\NormalTok{ x}\SpecialCharTok{:}\NormalTok{cz2,}
    \AttributeTok{vars =} \StringTok{"x"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{  )}

\CommentTok{\# With no Covariate Adjustment}
\NormalTok{no\_adjust }\OtherTok{\textless{}{-}}
\NormalTok{  rep\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{estimate}\NormalTok{(}
    \AttributeTok{form =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x,}
    \AttributeTok{vars =} \StringTok{"x"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We can now easily compare results under these alternative empirical
strategies. Figure 3 shows the power curves for each approach. As is
clear, the Lin estimator provides substantial improvements in power.
With covariate adjustment, we're powered to detect an effect nearly 40\%
the size of the MDE without controlling for \texttt{z1} and \texttt{z2}.
And it only took a few lines of code to get this result.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bind\_rows}\NormalTok{(}
\NormalTok{  lin\_adjust }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Method =} \StringTok{"Lin"}\NormalTok{),}
\NormalTok{  no\_adjust }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Method =} \StringTok{"No Covariates"}\NormalTok{)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(delta, power, }\AttributeTok{linetype =}\NormalTok{ Method)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}
    \AttributeTok{yintercept =} \FloatTok{0.8}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"grey25"}\NormalTok{,}
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}
    \AttributeTok{n.breaks =} \DecValTok{6}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(delta),}
    \AttributeTok{y =} \StringTok{"Power"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Power with Lin Adjustment"}\NormalTok{,}
    \AttributeTok{linetype =} \StringTok{"Method:"}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  ggridges}\SpecialCharTok{::}\FunctionTok{theme\_ridges}\NormalTok{(}
    \AttributeTok{font\_size =} \DecValTok{10}\NormalTok{,}
    \AttributeTok{center\_axis\_labels =} \ConstantTok{TRUE}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"bottom"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/unnamed-chunk-30-1}

Figure 3. Simulating power with the Lin estimator.

\hypertarget{incorporating-declaredesign-into-oes-power-tools}{%
\subsection{Incorporating DeclareDesign into OES Power
Tools}\label{incorporating-declaredesign-into-oes-power-tools}}

We can also use \texttt{DeclareDesign} within the \emph{Replicate},
\emph{Estimate}, \emph{Evaluate} framework. This involves using
\texttt{DeclareDesign} to draw estimates, and then feeding the results
into the OES \texttt{evaluate\_power()} function. We compare the
\texttt{DeclareDesign} approach to the OES \texttt{Replicate} and
\texttt{Estimate} steps below.

First, we simulate a simple design with the OES tools:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eval }\OtherTok{\textless{}{-}}
  \FunctionTok{replicate\_design}\NormalTok{(}
    \AttributeTok{R =} \DecValTok{1000}\NormalTok{,}
    \AttributeTok{N =} \DecValTok{100}\NormalTok{,}
    \AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N),}
    \AttributeTok{Z =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{estimate}\NormalTok{(}
    \AttributeTok{form =}\NormalTok{ Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{vars =} \StringTok{"Z"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\AttributeTok{len =} \DecValTok{10}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Then, we do the same with \texttt{DeclareDesign}, declaring a
population, potential outcomes, assignments, a target quantity of
interest, and an estimator:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\OtherTok{\textless{}{-}} \FunctionTok{declare\_population}\NormalTok{(}
  \AttributeTok{N =} \DecValTok{100}\NormalTok{,}
  \AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N)}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_potential\_outcomes}\NormalTok{(}
\NormalTok{    Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{complete\_ra}\NormalTok{(N,}
    \AttributeTok{prob =} \FloatTok{0.5}
\NormalTok{  )) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+}
  \FunctionTok{declare\_measurement}\NormalTok{(}\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(}
\NormalTok{    Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z,}
    \AttributeTok{inquiry =} \StringTok{"ATE"}\NormalTok{,}
    \AttributeTok{model =}\NormalTok{ lm\_robust}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We then use draws from this design within the OES tools:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dd\_eval }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}
  \AttributeTok{n =} \DecValTok{1000}\NormalTok{,}
  \AttributeTok{expr =} \FunctionTok{draw\_estimates}\NormalTok{(design) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{list}\NormalTok{()}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{evaluate\_power}\NormalTok{(}
    \AttributeTok{delta =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\AttributeTok{len =} \DecValTok{10}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We show the similarity between the two approaches to generating the
simulated data in the figure below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bind\_rows}\NormalTok{(}
\NormalTok{  eval }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{method =} \StringTok{"OES Power Tools"}\NormalTok{),}
\NormalTok{  dd\_eval }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{method =} \StringTok{"DeclareDesign"}\NormalTok{)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(delta, power, }\AttributeTok{linetype =}\NormalTok{ method)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(delta),}
    \AttributeTok{y =} \StringTok{"Power"}\NormalTok{,}
    \AttributeTok{linetype =} \ConstantTok{NULL}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}
    \AttributeTok{n.breaks =} \DecValTok{6}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}
    \AttributeTok{yintercept =} \FloatTok{0.8}\NormalTok{,}
    \AttributeTok{col =} \StringTok{"grey25"}\NormalTok{,}
    \AttributeTok{size =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  ggridges}\SpecialCharTok{::}\FunctionTok{theme\_ridges}\NormalTok{(}
    \AttributeTok{center\_axis\_labels =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{font\_size =} \DecValTok{10}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"bottom"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=.9\textwidth]{OES_SOP_files/figure-latex/unnamed-chunk-34-1}

\hypertarget{working-with-data}{%
\chapter{Working with data}\label{working-with-data}}

Our team works with administrative data, data not collected specifically
for the purpose of evaluating the impact of new policy ideas. This means
that we, and our agency collaborators, spend a \textbf{ton} of time
cleaning, merging, and checking data. Here, we describe some standard
practices that we have developed over time.

\hypertarget{general-questions-we-ask-of-a-data-set}{%
\section{General questions we ask of a data
set}\label{general-questions-we-ask-of-a-data-set}}

\begin{itemize}
\tightlist
\item
  Are there any duplicated observations? (This mostly means rows in a
  rectangular data set).
\item
  If there is an ID variable, are there duplicated IDs?
\item
  Are there missing data on outcomes? Why are outcomes missing?
\item
  Are there missing data on our record of treatment assignment? Why
  might we not know whether or not a given unit was assigned the new
  policy intervention?
\end{itemize}

\hypertarget{glossary-of-terms}{%
\chapter{\texorpdfstring{\protect\hyperlink{glossary}{Glossary of
Terms}}{Glossary of Terms}}\label{glossary-of-terms}}

Average treatment effect \protect\hyperlink{ATE}{ATE}

\hypertarget{appendix}{%
\chapter{\texorpdfstring{\protect\hyperlink{appendix}{Appendix}}{Appendix}}\label{appendix}}

\backmatter
  \bibliography{sop.bib,packages.bib}

\end{document}
