
# Working with data

Our team works with administrative data, data not collected specifically for the purpose of evaluating the impact of new policy ideas. This means that we, and our agency collaborators, spend a **ton** of time cleaning, merging, and checking data. Here, we describe some standard practices that we have developed over time.

## General questions we ask of a data set

 - Are there any duplicated observations? (This mostly means rows in a rectangular data set).
  - If there is an ID variable, are there duplicated IDs? 
 - Are there missing data on outcomes? Why are outcomes missing?
 - Are there missing data on our record of treatment assignment? Why might we not know whether or not a given unit was assigned the new policy intervention?

## Missing data

<!-- Thinking through ideas for a missing data simulation -->

```{r, eval = F, echo = F}
## Basic example data
eg_dat <- read.csv("dat1.csv")

## Get vector of cov names
covs <- colnames(eg_dat)[grepl("cov", colnames(eg_dat))]

## Which appear to be correlated with Y?
lapply(covs, function(.x) {
  
  reformulate(.x, response = "Y", intercept = T) %>%
    lm(data = eg_dat) %>%
    tidy() %>%
    filter(term != "(Intercept)") %>%
    select(term, estimate, p.value)
  }) %>%
  
  bind_rows() %>%
  
  mutate(p.value = round(p.value, 4))
```

